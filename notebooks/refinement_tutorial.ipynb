{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crystal Cell Parameter Refinement Tutorial\n",
    "\n",
    "This notebook demonstrates how to use nanoBragg's differentiable simulator to refine crystal parameters against a target diffraction pattern.\n",
    "\n",
    "**What you'll learn:**\n",
    "1. Setting up the simulator (Crystal, Detector, Beam)\n",
    "2. Generating synthetic diffraction patterns\n",
    "3. Visualizing diffraction images\n",
    "4. Running gradient-based refinement\n",
    "5. Monitoring convergence\n",
    "6. Verifying gradients with finite differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"NANOBRAGG_DISABLE_COMPILE\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import nanoBragg Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanobrag_torch.simulator import Simulator\n",
    "from nanobrag_torch.config import (\n",
    "    CrystalConfig, DetectorConfig, BeamConfig, DetectorConvention\n",
    ")\n",
    "from nanobrag_torch.models.crystal import Crystal\n",
    "from nanobrag_torch.models.detector import Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_CELL_A = 100.0  # Ground truth\n",
    "\n",
    "crystal_config = CrystalConfig(\n",
    "    cell_a=TRUE_CELL_A, cell_b=100.0, cell_c=100.0,\n",
    "    cell_alpha=90.0, cell_beta=90.0, cell_gamma=90.0,\n",
    "    N_cells=(5, 5, 5), default_F=100.0\n",
    ")\n",
    "\n",
    "detector_config = DetectorConfig(\n",
    "    distance_mm=100.0, pixel_size_mm=0.1,\n",
    "    spixels=256, fpixels=256,\n",
    "    detector_convention=DetectorConvention.MOSFLM\n",
    ")\n",
    "\n",
    "beam_config = BeamConfig(wavelength_A=1.5)\n",
    "\n",
    "print(f\"Crystal: {crystal_config.cell_a} x {crystal_config.cell_b} x {crystal_config.cell_c} Å\")\n",
    "print(f\"Detector: {detector_config.spixels} x {detector_config.fpixels} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Components and Generate Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal = Crystal(crystal_config, device=device, dtype=dtype)\n",
    "detector = Detector(detector_config, device=device, dtype=dtype)\n",
    "\n",
    "simulator = Simulator(crystal=crystal, detector=detector, beam_config=beam_config)\n",
    "with torch.no_grad():\n",
    "    target = simulator.run()\n",
    "\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Intensity range: [{target.min():.2e}, {target.max():.2e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Target Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pattern(pattern, title=\"\", log_scale=True, ax=None):\n",
    "    if isinstance(pattern, torch.Tensor):\n",
    "        img = pattern.detach().cpu().numpy()\n",
    "    else:\n",
    "        img = pattern\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    if log_scale:\n",
    "        img = np.log10(img + 1e-10)\n",
    "    im = ax.imshow(img, origin='lower', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "    return ax\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_pattern(target, \"Target (log scale)\", log_scale=True, ax=axes[0])\n",
    "plot_pattern(target, \"Target (linear)\", log_scale=False, ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up Refinement (5% Initial Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_CELL_A = 95.0\n",
    "\n",
    "# Create learnable parameter\n",
    "cell_a = torch.tensor(INIT_CELL_A, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# Update crystal in-place (efficient!)\n",
    "crystal.cell_a = cell_a\n",
    "\n",
    "print(f\"Initial: {cell_a.item():.2f} Å\")\n",
    "print(f\"Target:  {TRUE_CELL_A:.2f} Å\")\n",
    "print(f\"Error:   {abs(cell_a.item() - TRUE_CELL_A):.2f} Å ({abs(cell_a.item() - TRUE_CELL_A)/TRUE_CELL_A*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Initial vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_init = Simulator(crystal=crystal, detector=detector, beam_config=beam_config)\n",
    "with torch.no_grad():\n",
    "    initial_pattern = sim_init.run()\n",
    "\n",
    "initial_mse = torch.mean((initial_pattern - target) ** 2).item()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "plot_pattern(target, f\"Target (cell_a={TRUE_CELL_A})\", ax=axes[0])\n",
    "plot_pattern(initial_pattern, f\"Initial (cell_a={INIT_CELL_A})\", ax=axes[1])\n",
    "\n",
    "diff = (initial_pattern - target).cpu().numpy()\n",
    "im = axes[2].imshow(diff, origin='lower', cmap='RdBu_r', vmin=-abs(diff).max(), vmax=abs(diff).max())\n",
    "axes[2].set_title(f'Difference (MSE={initial_mse:.3f})')\n",
    "plt.colorbar(im, ax=axes[2], shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([cell_a], lr=0.5)\n",
    "history = {'cell_a': [], 'loss': []}\n",
    "\n",
    "print(f\"Refining: {INIT_CELL_A:.1f} → {TRUE_CELL_A:.1f} Å\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for step in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    sim = Simulator(crystal=crystal, detector=detector, beam_config=beam_config)\n",
    "    pattern = sim.run()\n",
    "    loss = torch.mean((pattern - target) ** 2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    history['cell_a'].append(cell_a.item())\n",
    "    history['loss'].append(loss.item())\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        print(f\"Step {step:2d}: cell_a={cell_a.item():.3f} Å, loss={loss.item():.2e}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(f\"Final: cell_a={cell_a.item():.3f} Å (error: {abs(cell_a.item()-TRUE_CELL_A):.3f} Å)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['cell_a'], 'b-o', markersize=3)\n",
    "axes[0].axhline(TRUE_CELL_A, color='g', linestyle='--', label=f'True: {TRUE_CELL_A}')\n",
    "axes[0].set_xlabel('Step'); axes[0].set_ylabel('cell_a (Å)')\n",
    "axes[0].legend(); axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].semilogy(history['loss'], 'r-o', markersize=3)\n",
    "axes[1].set_xlabel('Step'); axes[1].set_ylabel('MSE Loss')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Gradient Verification\n",
    "\n",
    "When developing differentiable code, verify analytical gradients match numerical (finite difference) gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(cell_a_val):\n",
    "    \"\"\"Compute loss for a given cell_a value.\"\"\"\n",
    "    cfg = CrystalConfig(\n",
    "        cell_a=float(cell_a_val), cell_b=100.0, cell_c=100.0,\n",
    "        cell_alpha=90.0, cell_beta=90.0, cell_gamma=90.0,\n",
    "        N_cells=(5, 5, 5), default_F=100.0\n",
    "    )\n",
    "    crys = Crystal(cfg, device=device, dtype=dtype)\n",
    "    sim = Simulator(crystal=crys, detector=detector, beam_config=beam_config)\n",
    "    with torch.no_grad():\n",
    "        pat = sim.run()\n",
    "    return torch.mean((pat - target) ** 2).item()\n",
    "\n",
    "# Finite difference gradient\n",
    "test_val = 98.0\n",
    "eps = 0.01\n",
    "numerical_grad = (compute_loss(test_val + eps) - compute_loss(test_val - eps)) / (2 * eps)\n",
    "\n",
    "# Analytical gradient\n",
    "cell_a_test = torch.tensor(test_val, device=device, dtype=dtype, requires_grad=True)\n",
    "crystal.cell_a = cell_a_test\n",
    "sim = Simulator(crystal=crystal, detector=detector, beam_config=beam_config)\n",
    "loss = torch.mean((sim.run() - target) ** 2)\n",
    "loss.backward()\n",
    "analytical_grad = cell_a_test.grad.item()\n",
    "\n",
    "print(\"Gradient Comparison\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Numerical (finite diff): {numerical_grad:.6f}\")\n",
    "print(f\"Analytical (autograd):   {analytical_grad:.6f}\")\n",
    "rel_err = abs(analytical_grad - numerical_grad) / (abs(numerical_grad) + 1e-10)\n",
    "print(f\"Relative error:          {rel_err:.2e}\")\n",
    "print(f\"Status: {'PASS' if rel_err < 0.05 else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Using torch.autograd.gradcheck\n",
    "\n",
    "For rigorous verification, use `gradcheck` with float64 precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "\n",
    "# Small detector for speed, float64 for precision\n",
    "det_small = Detector(\n",
    "    DetectorConfig(distance_mm=100.0, pixel_size_mm=0.1, spixels=32, fpixels=32,\n",
    "                   detector_convention=DetectorConvention.MOSFLM),\n",
    "    device=device, dtype=torch.float64\n",
    ")\n",
    "\n",
    "def loss_fn(cell_a_in):\n",
    "    cfg = CrystalConfig(cell_a=100.0, cell_b=100.0, cell_c=100.0,\n",
    "                        cell_alpha=90.0, cell_beta=90.0, cell_gamma=90.0,\n",
    "                        N_cells=(5, 5, 5), default_F=100.0)\n",
    "    crys = Crystal(cfg, device=device, dtype=torch.float64)\n",
    "    crys.cell_a = cell_a_in\n",
    "    sim = Simulator(crystal=crys, detector=det_small, beam_config=beam_config)\n",
    "    return sim.run().sum().unsqueeze(0)\n",
    "\n",
    "inp = torch.tensor([98.0], device=device, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "print(\"Running gradcheck...\")\n",
    "try:\n",
    "    gradcheck(loss_fn, inp, eps=1e-4, atol=1e-4, rtol=1e-3, raise_exception=True)\n",
    "    print(\"gradcheck PASSED\")\n",
    "except Exception as e:\n",
    "    print(f\"gradcheck FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Simulator setup** - Crystal, Detector, Beam configurations\n",
    "2. **Pattern generation** - `simulator.run()` returns differentiable 2D tensor\n",
    "3. **In-place updates** - Update `crystal.cell_a` directly without reallocation\n",
    "4. **Gradient refinement** - Adam optimizer minimizes MSE loss\n",
    "5. **Gradient verification** - Manual finite differences and `gradcheck`\n",
    "\n",
    "The simulator is **fully differentiable** - gradients flow from loss through the entire physics simulation back to crystal parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
