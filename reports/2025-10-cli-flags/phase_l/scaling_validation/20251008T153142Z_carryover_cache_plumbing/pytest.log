F                                                                        [100%]
=================================== FAILURES ===================================
______________ TestScalingParity.test_I_before_scaling_matches_c _______________

self = <tests.test_cli_scaling_parity.TestScalingParity object at 0x79ec9c37bd90>

    def test_I_before_scaling_matches_c(self):
        """
        Verify that PyTorch scaling chain matches C reference for target pixel.
    
        This test validates that when using phi_carryover_mode='c-parity' (which
        emulates the C code's φ=0 vector carryover bug), the PyTorch implementation
        produces F_cell, F_latt, and I_before_scaling values that match the C trace
        within ≤1e-6 relative tolerance.
    
        Expected Values (from C trace at pixel 685,1039, φ_tic=0):
        - F_cell: 190.27 (HKL nearest-neighbor lookup)
        - F_latt: -2.383196653 (lattice factor)
        - I_before_scaling: 943654.809 (pre-polarization intensity)
    
        Phase: CLI-FLAGS-003 M2 (Fix φ=0 carryover parity)
        Reference: reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log
        Bug: docs/bugs/verified_c_bugs.md (C-PARITY-001)
        """
        from nanobrag_torch.models.crystal import Crystal, CrystalConfig
        from nanobrag_torch.models.detector import Detector, DetectorConfig
        from nanobrag_torch.config import BeamConfig, DetectorConvention
        from nanobrag_torch.io.mosflm import read_mosflm_matrix
        from nanobrag_torch.simulator import Simulator
    
        # Check prerequisites
        mat_file = Path('A.mat')
        hkl_file = Path('scaled.hkl')
        if not mat_file.exists():
            pytest.skip("A.mat not found (required for supervisor command reproduction)")
        if not hkl_file.exists():
            pytest.skip("scaled.hkl not found (required for supervisor command reproduction)")
    
        # Device and dtype (float64 per test guidance for precision)
        device = torch.device('cpu')
        dtype = torch.float64
    
        # Beam configuration
        wavelength_A = 0.976800
        beam_config = BeamConfig(wavelength_A=wavelength_A)
    
        # Load MOSFLM matrix
        a_star, b_star, c_star = read_mosflm_matrix(str(mat_file), wavelength_A)
    
        # Crystal configuration (supervisor command)
        crystal_config = CrystalConfig(
            cell_a=100.0,  # placeholder (overridden by MOSFLM)
            cell_b=100.0,
            cell_c=100.0,
            cell_alpha=90.0,
            cell_beta=90.0,
            cell_gamma=90.0,
            N_cells=(36, 47, 29),
            mosflm_a_star=a_star,
            mosflm_b_star=b_star,
            mosflm_c_star=c_star,
            phi_start_deg=0.0,
            osc_range_deg=0.1,
            phi_steps=10,
            mosaic_domains=1,
            misset_deg=[0.0, 0.0, 0.0],
            spindle_axis=[-1.0, 0.0, 0.0],  # supervisor command convention
            # CRITICAL: Use c-parity mode to emulate C bug
            phi_carryover_mode="c-parity"
        )
    
        # Detector configuration (supervisor command)
        # CRITICAL: Must use CUSTOM convention with custom vectors to match C trace
        # Per trace_harness.py lines 79-99 and subagent analysis
        detector_config = DetectorConfig(
            distance_mm=231.274660,
            pixel_size_mm=0.172,
            spixels=2527,  # Corrected from 2463 - matches C trace dimensions
            fpixels=2463,  # Corrected from 2527
            detector_convention=DetectorConvention.CUSTOM,  # Changed from MOSFLM
            # Match supervisor command beam center
            beam_center_f=217.742295,
            beam_center_s=213.907080,
            oversample=1,
            # Custom detector vectors (from trace_harness.py lines 93-99)
            custom_fdet_vector=(0.999982, -0.005998, -0.000118),
            custom_sdet_vector=(-0.005998, -0.999970, -0.004913),
            custom_odet_vector=(-0.000088, 0.004914, -0.999988),
            custom_beam_vector=(0.00051387949, 0.0, -0.99999986),
            # Custom pix0 override (mm→m conversion from trace_harness.py line 98)
            pix0_override_m=(-0.216336293, 0.215205512, -0.230200866)
        )
    
        # Instantiate models
        crystal = Crystal(crystal_config, beam_config=beam_config, device=device, dtype=dtype)
        detector = Detector(detector_config, device=device, dtype=dtype)
    
        # Load HKL data
        crystal.load_hkl(str(hkl_file))
    
        # Create simulator with trace enabled for target pixel
        simulator = Simulator(
            crystal=crystal,
            detector=detector,
            beam_config=beam_config,
            device=device,
            dtype=dtype,
            debug_config={'trace_pixel': [685, 1039]}  # Enable trace for target pixel
        )
    
        # Run simulation and capture trace output
        # The trace output will go to stdout, so we capture it
        old_stdout = sys.stdout
        sys.stdout = captured_output = io.StringIO()
    
        try:
            # Run simulation
>           image = simulator.run()
                    ^^^^^^^^^^^^^^^

tests/test_cli_scaling_parity.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <nanobrag_torch.simulator.Simulator object at 0x79ec7ec21010>
pixel_batch_size = None, override_a_star = None, oversample = 1
oversample_omega = False, oversample_polar = False, oversample_thick = False

    def run(
        self,
        pixel_batch_size: Optional[int] = None,
        override_a_star: Optional[torch.Tensor] = None,
        oversample: Optional[int] = None,
        oversample_omega: Optional[bool] = None,
        oversample_polar: Optional[bool] = None,
        oversample_thick: Optional[bool] = None,
    ) -> torch.Tensor:
        """
        Run the diffraction simulation with crystal rotation and mosaicity.
    
        This method vectorizes the simulation over all detector pixels, phi angles,
        and mosaic domains. It integrates contributions from all crystal orientations
        to produce the final diffraction pattern.
    
        Important: This implementation uses the full Miller indices (h, k, l) for the
        lattice shape factor calculation, not the fractional part (h-h0). This correctly
        models the crystal shape transform and is consistent with the physics of
        diffraction from a finite crystal.
    
        C-Code Implementation Reference (from nanoBragg.c, lines 2993-3151):
        The vectorized implementation replaces these nested loops. The outer `source`
        loop is future work for handling beam divergence and dispersion.
    
        ```c
                        /* loop over sources now */
                        for(source=0;source<sources;++source){
    
                            /* retrieve stuff from cache */
                            incident[1] = -source_X[source];
                            incident[2] = -source_Y[source];
                            incident[3] = -source_Z[source];
                            lambda = source_lambda[source];
    
                            /* ... scattering vector calculation ... */
    
                            /* sweep over phi angles */
                            for(phi_tic = 0; phi_tic < phisteps; ++phi_tic)
                            {
                                /* ... crystal rotation ... */
    
                                /* enumerate mosaic domains */
                                for(mos_tic=0;mos_tic<mosaic_domains;++mos_tic)
                                {
                                    /* ... mosaic rotation ... */
                                    /* ... h,k,l calculation ... */
                                    /* ... F_cell and F_latt calculation ... */
    
                                    /* convert amplitudes into intensity (photons per steradian) */
                                    I += F_cell*F_cell*F_latt*F_latt;
                                }
                            }
                        }
        ```
    
        Args:
            pixel_batch_size: Optional batching for memory management.
            override_a_star: Optional override for the a_star vector for testing.
            oversample: Number of subpixel samples per axis. Defaults to detector config.
            oversample_omega: Apply solid angle per subpixel. Defaults to detector config.
            oversample_polar: Apply polarization per subpixel. Defaults to detector config.
            oversample_thick: Apply absorption per subpixel. Defaults to detector config.
    
        Returns:
            torch.Tensor: Final diffraction image with shape (spixels, fpixels).
        """
        # Phase M2g: Initialize c-parity cache if needed
        # C-PARITY-001 emulation uses pixel-indexed cache (opt-in mode only)
        # C-Code Reference (nanoBragg.c:2797-2800): OpenMP firstprivate(ap,bp,cp,...)
        # provides thread-local persistence; PyTorch uses explicit pixel-indexed cache.
        # See: reports/2025-10-cli-flags/phase_l/scaling_validation/phi_carryover_diagnosis.md
        if self.crystal.config.phi_carryover_mode == "c-parity":
            self.crystal.initialize_phi_cache(
                self.detector.spixels,
                self.detector.fpixels
            )
    
        # Unified vectorization path (both spec and c-parity modes)
        # Note: c-parity cache application happens inside get_rotated_real_vectors when enabled
        # Get oversampling parameters from detector config if not provided
        if oversample is None:
            oversample = self.detector.config.oversample
        if oversample_omega is None:
            oversample_omega = self.detector.config.oversample_omega
        if oversample_polar is None:
            oversample_polar = self.detector.config.oversample_polar
        if oversample_thick is None:
            oversample_thick = self.detector.config.oversample_thick
    
        # Auto-select oversample if set to -1 (matches C behavior)
        if oversample == -1:
            # Calculate maximum crystal dimension in meters
            xtalsize_max = max(
                abs(self.crystal.config.cell_a * 1e-10 * self.crystal.config.N_cells[0]),  # a*Na in meters
                abs(self.crystal.config.cell_b * 1e-10 * self.crystal.config.N_cells[1]),  # b*Nb in meters
                abs(self.crystal.config.cell_c * 1e-10 * self.crystal.config.N_cells[2])   # c*Nc in meters
            )
    
            # Calculate reciprocal pixel size in meters
            # reciprocal_pixel_size = λ * distance / pixel_size (all in meters)
            wavelength_m = self.wavelength * 1e-10  # Convert from Angstroms to meters
            distance_m = self.detector.config.distance_mm / 1000.0  # Convert from mm to meters
            pixel_size_m = self.detector.config.pixel_size_mm / 1000.0  # Convert from mm to meters
            reciprocal_pixel_size = wavelength_m * distance_m / pixel_size_m
    
            # Calculate recommended oversample using C formula
            import math
            recommended_oversample = math.ceil(3.0 * xtalsize_max / reciprocal_pixel_size)
    
            # Ensure at least 1
            if recommended_oversample <= 0:
                recommended_oversample = 1
    
            oversample = recommended_oversample
            print(f"auto-selected {oversample}-fold oversampling")
    
        # For now, we'll implement the base case without oversampling for this test
        # The full subpixel implementation will come later
        # This matches the current implementation which doesn't yet have subpixel sampling
    
        # PERF-PYTORCH-004 P3.4: Use cached ROI mask instead of rebuilding every run
        roi_mask = self._cached_roi_mask
    
        # PERF-PYTORCH-004 P3.4: Use cached pixel coordinates instead of fetching/converting every run
        pixel_coords_meters = self._cached_pixel_coords_meters
    
        # Get rotated lattice vectors for all phi steps and mosaic domains
        # Shape: (N_phi, N_mos, 3)
        # PERF-PYTORCH-006: Convert crystal vectors to correct device/dtype
        if override_a_star is None:
            (rot_a, rot_b, rot_c), (rot_a_star, rot_b_star, rot_c_star) = (
                self.crystal.get_rotated_real_vectors(self.crystal.config)
            )
            # Convert to correct dtype/device
            rot_a = rot_a.to(device=self.device, dtype=self.dtype)
            rot_b = rot_b.to(device=self.device, dtype=self.dtype)
            rot_c = rot_c.to(device=self.device, dtype=self.dtype)
            rot_a_star = rot_a_star.to(device=self.device, dtype=self.dtype)
            rot_b_star = rot_b_star.to(device=self.device, dtype=self.dtype)
            rot_c_star = rot_c_star.to(device=self.device, dtype=self.dtype)
            # Cache rotated reciprocal vectors for GAUSS/TOPHAT shape models
            self._rot_a_star = rot_a_star
            self._rot_b_star = rot_b_star
            self._rot_c_star = rot_c_star
        else:
            # For gradient testing with override, use single orientation
            rot_a = override_a_star.view(1, 1, 3)
            rot_b = self.crystal.b.view(1, 1, 3)
            rot_c = self.crystal.c.view(1, 1, 3)
            rot_a_star = override_a_star.view(1, 1, 3)
            rot_b_star = self.crystal.b_star.view(1, 1, 3)
            rot_c_star = self.crystal.c_star.view(1, 1, 3)
            # Cache for shape models
            self._rot_a_star = rot_a_star
            self._rot_b_star = rot_b_star
            self._rot_c_star = rot_c_star
    
        # PERF-PYTORCH-004 P1.2: Use pre-normalized source tensors from __init__
        # Tensors were already moved to correct device/dtype during initialization
        if self._source_directions is not None:
            n_sources = len(self._source_directions)
            source_directions = self._source_directions
            source_wavelengths_A = self._source_wavelengths_A
            source_weights = self._source_weights
        else:
            # No explicit sources, use single beam configuration
            n_sources = 1
            source_directions = None
            source_wavelengths_A = None
            source_weights = None
    
        # Calculate normalization factor (steps)
        # Per spec AT-SAM-001: "Final per-pixel scale SHALL divide by steps"
        # PERF-PYTORCH-004 P3.0c: Per AT-SRC-001 "steps = sources; intensity contributions SHALL sum with per-source λ and weight, then divide by steps"
        # The divisor SHALL be the COUNT of sources, not the SUM of weights.
        # Weights are applied during accumulation (inside compute_physics_for_position), then we normalize by count.
        phi_steps = self.crystal.config.phi_steps
        mosaic_domains = self.crystal.config.mosaic_domains
        source_norm = n_sources
    
        steps = source_norm * phi_steps * mosaic_domains * oversample * oversample  # Include sources and oversample^2
    
        # Apply physical scaling factors (from nanoBragg.c ~line 3050)
        # Solid angle correction, converting all units to meters for calculation
    
        # Check if we're doing subpixel sampling
        if oversample > 1:
            # VECTORIZED IMPLEMENTATION: Process all subpixels in parallel
            # Generate subpixel offsets (centered on pixel center)
            # Per spec: "Compute detector-plane coordinates (meters): Fdet and Sdet at subpixel centers."
            # Create offsets in fractional pixel units
            subpixel_step = 1.0 / oversample
            offset_start = -0.5 + subpixel_step / 2.0
    
            # Use manual arithmetic to preserve gradients (avoid torch.linspace)
            subpixel_offsets = offset_start + torch.arange(
                oversample, device=self.device, dtype=self.dtype
            ) * subpixel_step
    
            # Create grid of subpixel offsets
            sub_s, sub_f = torch.meshgrid(subpixel_offsets, subpixel_offsets, indexing='ij')
            # Flatten the grid for vectorized processing
            # Shape: (oversample*oversample,)
            sub_s_flat = sub_s.flatten()
            sub_f_flat = sub_f.flatten()
    
            # Get detector basis vectors for proper coordinate transformation
            f_axis = self.detector.fdet_vec  # Shape: [3]
            s_axis = self.detector.sdet_vec  # Shape: [3]
            S, F = pixel_coords_meters.shape[:2]
    
            # VECTORIZED: Create all subpixel positions at once
            # Shape: (oversample*oversample, 3)
            # Convert detector properties to tensors with correct device/dtype (AT-PERF-DEVICE-001)
            # Use as_tensor to avoid warnings when value might already be a tensor
            pixel_size_m_tensor = torch.as_tensor(self.detector.pixel_size, device=pixel_coords_meters.device, dtype=pixel_coords_meters.dtype)
            delta_s_all = sub_s_flat * pixel_size_m_tensor
            delta_f_all = sub_f_flat * pixel_size_m_tensor
    
            # Shape: (oversample*oversample, 3)
            offset_vectors = delta_s_all.unsqueeze(-1) * s_axis + delta_f_all.unsqueeze(-1) * f_axis
    
            # Expand pixel_coords for all subpixels
            # Shape: (S, F, oversample*oversample, 3)
            pixel_coords_expanded = pixel_coords_meters.unsqueeze(2).expand(S, F, oversample*oversample, 3)
            offset_vectors_expanded = offset_vectors.unsqueeze(0).unsqueeze(0).expand(S, F, oversample*oversample, 3)
    
            # All subpixel coordinates at once
            # Shape: (S, F, oversample*oversample, 3)
            subpixel_coords_all = pixel_coords_expanded + offset_vectors_expanded
    
            # Convert to Angstroms for physics
            subpixel_coords_ang_all = subpixel_coords_all * 1e10
    
            # VECTORIZED PHYSICS: Process all subpixels at once
            # Reshape to (S*F*oversample^2, 3) for physics calculation
            # Use .contiguous() to avoid CUDA graphs tensor reuse errors
            batch_shape = subpixel_coords_ang_all.shape[:-1]
            coords_reshaped = subpixel_coords_ang_all.reshape(-1, 3).contiguous()
    
            # Compute physics for all subpixels and sources (VECTORIZED)
            if n_sources > 1:
                # VECTORIZED Multi-source case: batch all sources together
                # Note: source_directions point FROM sample TO source
                # Incident beam direction should be FROM source TO sample (negated)
                incident_dirs_batched = -source_directions  # Shape: (n_sources, 3)
                wavelengths_batched = source_wavelengths_A  # Shape: (n_sources,)
    
                # Single batched call for all sources
                # This replaces the Python loop and enables torch.compile optimization
                # CLI-FLAGS-003 Phase M1: Unpack both post-polar and pre-polar intensities
                physics_intensity_flat, physics_intensity_pre_polar_flat = self._compute_physics_for_position(
                    coords_reshaped, rot_a, rot_b, rot_c, rot_a_star, rot_b_star, rot_c_star,
                    incident_beam_direction=incident_dirs_batched,
                    wavelength=wavelengths_batched,
                    source_weights=source_weights
                )
    
                # Reshape back to (S, F, oversample*oversample)
                # The weighted sum over sources is done inside _compute_physics_for_position
                subpixel_physics_intensity_all = physics_intensity_flat.reshape(batch_shape)
            else:
                # Single source case: use default beam parameters
                # CLI-FLAGS-003 Phase M1: Unpack both post-polar and pre-polar intensities
                physics_intensity_flat, physics_intensity_pre_polar_flat = self._compute_physics_for_position(
                    coords_reshaped, rot_a, rot_b, rot_c, rot_a_star, rot_b_star, rot_c_star
                )
    
                # Reshape back to (S, F, oversample*oversample)
                subpixel_physics_intensity_all = physics_intensity_flat.reshape(batch_shape)
    
            # Normalize by the total number of steps
            subpixel_physics_intensity_all = subpixel_physics_intensity_all / steps
    
            # PERF-PYTORCH-004 P3.0b: Polarization is now applied per-source inside compute_physics_for_position
            # Only omega needs to be applied here for subpixel oversampling
    
            # VECTORIZED AIRPATH AND OMEGA: Calculate for all subpixels
            sub_squared_all = torch.sum(subpixel_coords_ang_all * subpixel_coords_ang_all, dim=-1)
            # PERF-PYTORCH-004 Phase 1: Use clamp_min instead of torch.maximum to avoid allocating tensors inside compiled graph
            sub_squared_all = sub_squared_all.clamp_min(1e-20)
            sub_magnitudes_all = torch.sqrt(sub_squared_all)
            airpath_m_all = sub_magnitudes_all * 1e-10
    
            # Get close_distance from detector (computed during init)
            # Convert detector properties to tensors with correct device/dtype (AT-PERF-DEVICE-001)
            # Use as_tensor to avoid warnings when value might already be a tensor
            close_distance_m = torch.as_tensor(self.detector.close_distance, device=airpath_m_all.device, dtype=airpath_m_all.dtype)
            pixel_size_m = torch.as_tensor(self.detector.pixel_size, device=airpath_m_all.device, dtype=airpath_m_all.dtype)
    
            # Calculate solid angle (omega) for all subpixels
            # Shape: (S, F, oversample*oversample)
            if self.detector.config.point_pixel:
                omega_all = 1.0 / (airpath_m_all * airpath_m_all)
            else:
                omega_all = (
                    (pixel_size_m * pixel_size_m)
                    / (airpath_m_all * airpath_m_all)
                    * close_distance_m
                    / airpath_m_all
                )
    
            # Apply omega based on oversample flags
            intensity_all = subpixel_physics_intensity_all.clone()
    
            if oversample_omega:
                # Apply omega per subpixel
                intensity_all = intensity_all * omega_all
    
            # Sum over all subpixels to get final intensity
            # Shape: (S, F)
            accumulated_intensity = torch.sum(intensity_all, dim=2)
    
            # Save pre-normalization intensity for trace (before last-value multiplication)
            I_before_normalization = accumulated_intensity.clone()
    
            # Apply last-value semantics if omega flag is not set
            if not oversample_omega:
                # Get the last subpixel's omega (last in flattened order)
                last_omega = omega_all[:, :, -1]  # Shape: (S, F)
                accumulated_intensity = accumulated_intensity * last_omega
    
            # Use accumulated intensity
            normalized_intensity = accumulated_intensity
        else:
            # No subpixel sampling - compute physics once for pixel centers
    
            # Phase M2g.4: Row-wise batch processing for c-parity mode (Option B)
            # This enables per-pixel φ carryover cache access while maintaining vectorization
            use_row_batching = (self.crystal.config.phi_carryover_mode == "c-parity"
>                              and self._phi_cache_initialized)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'Simulator' object has no attribute '_phi_cache_initialized'

src/nanobrag_torch/simulator.py:1025: AttributeError
=========================== short test summary info ============================
FAILED tests/test_cli_scaling_parity.py::TestScalingParity::test_I_before_scaling_matches_c
1 failed in 2.61s
