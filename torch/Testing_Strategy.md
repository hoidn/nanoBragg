# nanoBragg PyTorch Testing Strategy

**Version:** 1.0  
**Date:** 2023-10-27  
**Owner:** [Your Name/Team]

## 1. Introduction & Philosophy

This document outlines the comprehensive testing strategy for the PyTorch implementation of `nanoBragg`. The primary goal is to ensure that the new application is a **correct, verifiable, and trustworthy** scientific tool.

Our testing philosophy is a **three-tiered hybrid approach**, designed to build confidence layer by layer:
1.  **Tier 1: Translation Correctness:** We first prove that the PyTorch code is a faithful, numerically precise reimplementation of the original C code's physical model. The C code is treated as the "ground truth" specification.
2.  **Tier 2: Gradient Correctness:** We then prove that the new differentiable capabilities are mathematically sound, as this is a core feature not present in the original.
3.  **Tier 3: Scientific Validation:** Finally, we validate the model against objective physical principles and community standards to protect against any potential flaws in the original model and to establish scientific credibility.

All tests will be implemented using the **PyTest framework**.

## 2. Incorporating and Superseding the Legacy Testing Approach

The original `nanoBragg.c` implementation relies on an implicit, manual testing strategy common in scientific software:

*   **Example-Based Validation:** Running a series of well-understood examples from the `README.md`.
*   **Visual Inspection:** Manually viewing the output images to confirm they "look correct."
*   **Scientific Plausibility:** Checking that the output conforms to known physical principles.

While effective for initial development, this manual approach is not scalable, repeatable, or sufficient for a robust, maintainable software project.

Our new testing strategy is designed to **formalize, automate, and extend** this legacy approach.

*   **Formalizing Example-Based Validation:** The "Golden Suite" (Section 3) is the formal, automated version of the `README` examples. Instead of a human checking if the program runs, our integration tests check that the output is bit-for-bit identical to a trusted result. This makes the process objective and instantaneous.

*   **Formalizing Scientific Plausibility:** The manual check for physical correctness is captured and automated in the **Tier 3: Scientific Validation** tests. These tests programmatically check for adherence to Bragg's law and polarization principles, removing human subjectivity.

*   **Addressing Visual Inspection:** We acknowledge that automated tests cannot fully replace the intuition gained from visual inspection. However, by validating the PyTorch implementation against the C code's "golden" visual output, we ensure that no visual regressions occur. The primary role of visual inspection is now shifted to the validation of *new features* rather than the verification of existing ones.

By implementing this tiered, automated strategy, we retain the scientific spirit of the original validation methods while making them rigorous, repeatable, and capable of guarding against future regressions.

## 3. Ground Truth Establishment: The "Golden Suite"

The foundation of our testing strategy is a "Golden Suite" of test data generated from the original, trusted C code.

### 3.1 Instrumenting the C Code

The `nanoBragg.c` source will be modified to include a new command-line flag: `-dump_pixel <fpixel> <spixel>`. When run with this flag, the program will execute normally but will also write a detailed log file (`<test_case_name>.log`) containing key intermediate variables for the specified pixel at every step of the innermost simulation loops. This provides the ground truth for component-level testing.

### 3.2 Golden Test Cases

The following test cases will be defined and run using the instrumented C code to generate a set of golden output images and debug logs.

| Test Case Name | Description | Purpose |
| :--- | :--- | :--- |
| `simple_cubic` | A 100Ã… cubic cell, single wavelength, no mosaicity, no oscillation. | The "hello world" test for basic geometry and spot calculation. |
| `triclinic_complex` | A low-symmetry triclinic cell. | To stress-test the reciprocal space and geometry calculations. |
| `with_mosaicity` | The `simple_cubic` case with a 0.5-degree mosaic spread. | To test the mosaic domain implementation. |
| `with_oscillation` | The `simple_cubic` case with a 1-degree oscillation over 10 phi steps. | To test the spindle rotation logic. |
| `full_features` | A complex case with all major features enabled (divergence, dispersion, mosaicity, oscillation, etc.). | The final, comprehensive integration test case. |

These golden files (`.img`, `.log`) will be committed to the repository and will not be changed.

### 3.3 Golden Suite Generation

The "Golden Suite" data is generated by a specially instrumented version of the original `nanoBragg.c` code.

*   **Source Location:** The instrumented C source code, which includes the `-dump_pixel` flag, and a corresponding `Makefile` are located in the `golden_suite_generator/` directory of this repository.
*   **Generation Command:** The entire suite can be regenerated by running `make -C golden_suite_generator/ all`.

## 4. Tier 1: Translation Correctness Testing

**Goal:** To prove the PyTorch code is a faithful port of the C code.

### 4.1 Unit Tests (`tests/test_utils.py`)

*   **Target:** Functions in `utils/geometry.py` and `utils/physics.py`.
*   **Methodology:** For each function, create a PyTest test that provides a hard-coded input. The expected output will be taken directly from the golden debug logs or calculated manually. Comparison will be done using `torch.allclose()`.
*   **Requirement:** All utility functions must have at least one corresponding unit test.

### 4.2 Component Tests (`tests/test_models.py`)

*   **Target:** The `Detector` and `Crystal` classes in `models/`.
*   **Methodology:**
    *   **`test_detector_geometry`:** Instantiate the `Detector` class using the configuration from a golden test case. Assert that its calculated basis vectors (`fdet_vec`, etc.) and the 3D coordinates of the dumped pixel match the values in the corresponding `.log` file.
    *   **`test_crystal_geometry`:** Instantiate the `Crystal` class. Assert that its initial reciprocal vectors match the golden log.
    *   **`test_crystal_rotation`:** Call the `crystal.get_rotated_reciprocal_vectors()` method with `phi` and mosaic matrix values taken from a specific step in the golden log. Assert that the output vectors match the C code's rotated vectors for that step.
*   **Requirement:** Both `Detector` and `Crystal` classes must pass these component tests for at least the `simple_cubic` and `triclinic_complex` cases.

### 4.3 Integration Tests (`tests/test_simulator.py`)

*   **Target:** The end-to-end `Simulator.run()` method.
*   **Methodology:** For each test case in the Golden Suite, create a test function that:
    1.  Configures and runs the PyTorch `Simulator`.
    2.  Loads the corresponding golden output image (`.img` file).
    3.  Asserts that the entire output image tensor is numerically close to the golden image tensor using `torch.allclose(rtol=1e-5, atol=1e-5)`.
*   **Requirement:** The simulator must pass integration tests for **all** cases in the Golden Suite.

**Note on Precision:** All tests in this tier will be run with PyTorch's default dtype set to `torch.float64` to match the `double` precision of the C code and minimize floating-point discrepancies.

## 5. Tier 2: Gradient Correctness Testing

**Goal:** To prove that the automatic differentiation capabilities are mathematically correct.

### 5.1 Gradient Checks (`tests/test_gradients.py`)

*   **Target:** All parameters intended for refinement.
*   **Methodology:** We will use PyTorch's built-in numerical gradient checker, `torch.autograd.gradcheck`. For each parameter, a test will be created that:
    1.  Sets up a minimal, fast-to-run simulation scenario.
    2.  Defines a function that takes the parameter tensor as input and returns a scalar loss.
    3.  Calls `gradcheck` on this function and its input.
*   **Requirement:** The following parameters (at a minimum) must pass `gradcheck`:
    *   **Crystal:** `cell_a`, `cell_gamma`, `misset_rot_x`
    *   **Detector:** `distance_mm`, `Fbeam_mm`
    *   **Beam:** `lambda_A`
    *   **Model:** `mosaic_spread_rad`, `fluence`

## 6. Tier 3: Scientific Validation Testing

**Goal:** To validate the model against objective physical principles, independent of the original C code.

### 6.1 First Principles Tests (`tests/test_validation.py`)

*   **Target:** The fundamental geometry and physics of the simulation.
*   **Methodology:**
    *   **`test_bragg_spot_position`:**
        1.  Configure a simple case: cubic cell, beam along Z, detector on XY plane, no rotations.
        2.  Analytically calculate the exact (x,y) position of a low-index reflection (e.g., (1,0,0)) using the Bragg equation and simple trigonometry.
        3.  Run the simulation.
        4.  Find the coordinates of the brightest pixel in the output image using `torch.argmax`.
        5.  Assert that the simulated spot position is within one pixel of the analytically calculated position.
    *   **`test_polarization_limits`:**
        1.  Configure a reflection to be at exactly 90 degrees 2-theta.
        2.  Run the simulation with polarization set to horizontal. Assert the spot intensity is near maximum.
        3.  Run again with polarization set to vertical. Assert the spot intensity is near zero.

### 6.2 Cross-Validation Test (Optional but Recommended)

*   **Target:** High-level agreement with community standards.
*   **Methodology:**
    1.  Choose a simple, common-denominator scenario (e.g., the `simple_cubic` case).
    2.  Configure and run a simulation using an independent, trusted software package (e.g., `cctbx.xfel`).
    3.  Run the PyTorch simulation.
    4.  Compare the **positions** of the brightest spots in both images. A direct intensity comparison is not required, as models may differ.
*   **Requirement:** The spot positions should agree to within a reasonable tolerance, confirming that our coordinate system and geometric conventions are not fundamentally flawed.