Already up to date.
Waiting for expected_actor=galph...
Already up to date.
[sync] state: actor=galph status=complete iter=115
To github.com:hoidn/nanoBragg.git
   7c6dfef..fedb25f  HEAD -> feature/spec-based-2
$ codex exec -m gpt-5-codex -c model_reasoning_effort=high --dangerously-bypass-approvals-and-sandbox
[2025-10-07T22:09:37] OpenAI Codex v0.38.0 (research preview)
--------
workdir: /Users/ollie/Documents/nanoBragg3
model: gpt-5-codex
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: high
reasoning summaries: auto
--------
[2025-10-07T22:09:37] User instructions:
<role>
planning, review and analysis. do not make implementation code changes.
</role>
<current long-term goals>
in order of decreasing priority:
<1>
run a successful parallel test of pytorch nanobragg against nanobragg c with this command:

nanoBragg  -mat A.mat -floatfile img.bin -hkl scaled.hkl  -nonoise  -nointerpolate -oversample 1  -exposure 1  -flux 1e18 -beamsize 1.0  -spindle_axis -1 0 0 -Xbeam 217.742295 -Ybeam 213.907080  -distance 231.274660 -lambda 0.976800 -pixel 0.172 -detpixels_x 2463 -detpixels_y 2527 -odet_vector -0.000088 0.004914 -0.999988 -sdet_vector -0.005998 -0.999970 -0.004913 -fdet_vector 0.999982 -0.005998 -0.000118 -pix0_vector_mm -216.336293 215.205512 -230.200866  -beam_vector 0.00051387949 0.0 -0.99999986  -Na 36  -Nb 47 -Nc 29 -osc 0.1 -phi 0 -phisteps 10 -detector_rotx 0 -detector_roty 0 -detector_rotz 0 -twotheta 0

this will require first adding support for the following cli params to pytorch nanobragg:
-nonoise
-pix0_vector_mm

</1>
<2>
review docs/bugs/verified_c_bugs.md and specs/. Make sure that the phi 0 carryover C implementation bug wasnt propagated to the specs. Update the specs (if needed) and pytorch implementation to fix this bug, if it was propagated.
</2>
<3>
review and firm up if needed plans/active/vectorization.md. then implement it (or rather, delegate its implementation to ralph), starting with the tricubic interpolation vectorization 
</3>
</current long-term goals>
</past long term goals>
(just for archival / reference purposes):
- error-correcting the engineer agent 
- profiling pytorch nanobragg to find performance bottlenecks. analyzing to understand the CRITICAL slowness of the pytorch implementation compared to reference C, which persists after our recent improvement attempts
- finding performance issues in the PyTorch reimplementation of nanobragg (originally a C code) and speeding it up. It should be efficiently vectorized and faster than C nanobragg, but currently it's slower 
- ensuring that the pytorch implementation uses fp32 (not fp64) by default 
- understanding why pytorch is slower than C in the warm condition at 4096x4096 resolution and fixing the underlying performance issue, if one is found. THIS IS A CRITICAL PERFORMANCE ISSUE.
- once all the above are taken care of: building a user-facing showcase of autodiff-based parameter refinement, with plots / visuals

</past long-term goals>
<task>
You are galph, a planner / supervisor agent. you are overseeing the work of an agent (ralph) that is running prompts/main.md in a loop, using docs/fix_plan.md as its instruction set and long term memory. 

You will get invoked repeatedly, for multiple iterations. Use galph_memory.md to communicate with your future self. You'll plans under plans/, when needed, to help steer multi-turn efforts by the coder agent (ralph). Those plans will be cross referenced from docs/fix_plan.md so that ralph can find / read them. 

At the start of every invocation:
- Run `timeout 30 git pull --rebase` with a hard 30-second timeout  to sync with origin before reviewing context. If the command times out, immediately abort any partial rebase (`git rebase --abort`) and fall back to a normal merge via `git pull --no-rebase`. Whatever path you take, resolve resulting conflicts (docs/fix_plan.md is a frequent hotspot) and document key decisions in galph_memory.md. If the pull reports conflicts:
  * Run `git status --short` to list conflicted files.
  * Fix each file (remove conflict markers, keep the intended content) and stage it with `git add`.
  * When the index is clean, resume with `timeout 30 git rebase --continue --no-edit`. IMPORTANT: NEVER RUN THIS COMMAND WITHOUT TIMEOUT
- After resolving any conflicts, read the latest galph_memory.md entry (and any linked plan files) so you do not lose past context.
- Prune or summarize older entries when they become stale or redundant.

During the main, central phase of invocation you will be doing essentially three things:
<main analysis step 1> 
An initial analysis pass in which you gather and review information in order to choose a <focus issue> for the turn, corresponding to <instructions> steps <0> through <3>. This will involve a multi-category selection process. You will choose both a <focus issue> and an associated <Action type> for the remainder of the iteration. The available <Action type>s are the following:
<Action type> list:
<1>
<Evidence collection> (i.e. Evidence task)
No full pytest runs. Allowed: non-mutating probes and CLI validation tools (e.g., scripts/validation/*, nb-compare, pixel trace); pytest --collect-only to validate selectors; and in TDD mode only, a single targeted pytest run to confirm the newly authored test fails. Do not change production code. This gate applies only to galph. Ralph is exempt. Do not include any Phase label in input.md.

Evidence collection includes the following subtype:
    Callchain Tracing (Evidence subtype)
    - When to use: before code edits when the pipeline/factor order relevant to the current issue is unclear; when onboarding a new surface; or upon parity failures where the locus is unknown.
    - Directive: first, emit descriptions for the following things:
       - <analysis_question> (required): Free‑text description of the behavior/bug/perf issue to investigate. This will be closely related to <focus issue>, but viewed from the point of view of relevant code execution paths and their entry points.
       - <initiative_id> and <scope_hints> 

    - Directive: then read and carefully follow the instructions in `prompts/callchain.md` with the question‑driven invocation (<analysis_question>) and produce standardized artifacts under `reports/<initiative_id>/`.
    - Example invocation variables (fill at run time):
      analysis_question: "<what are we trying to understand or fix?>"
      initiative_id: "<short‑slug>"
      scope_hints: ["CLI flags", "normalization", "scaling"]
      roi_hint: "<minimal input/ROI>"
      namespace_filter: "<project primary package>"
      time_budget_minutes: 30
    - Expected outputs:
      - `reports/<initiative_id>/callchain/static.md` (entry→sink with file:line anchors)
      - `reports/<initiative_id>/callgraph/dynamic.txt` (optional, module‑filtered)
      - `reports/<initiative_id>/trace/tap_points.md` (proposed numeric taps with owners)
      - `reports/<initiative_id>/summary.md` (question‑oriented narrative + next steps)
      - `reports/<initiative_id>/env/trace_env.json`
    - Guardrails: evidence‑only (no prod edits), module/device/dtype neutrality, small ROI, respect Protected Assets, stable key names in traces.
</Evidence collection>
</1>
<2>
<Debug> i.e. Debugging — Hypothesis + Triage (initial pass):
- pairs with <focus issue>s that are related to debugging or parity analysis.
<steps>
- Formulate 1–3 plausible hypotheses for the observed gap/issue.
- Triage each with checks appropriate to scope using existing artifacts or quick, documented reproductions; this triage may constitute the primary work for the iteration. Record outcomes succinctly in the evidence.
- For the top hypothesis, state confidence and the single confirming step to run next. Deliver 1–3 ranked hypotheses with supporting evidence, artifact paths, and the next confirming step.
</steps>
</Debug>
</2>
<3>
<Planning>
- we will be calling the plan topic the <focus issue> of this turn.
- based on which long term <goal> and sub-goal is that effort / plan? 
- Which existing docs/fix_plan.md items does it (i.e. the <focus issue>) relate to? 
- Documentation review for <focus issue>: Using `docs/index.md` as the map, identify and read the specific documents relevant to the chosen <focus issue> (e.g., component contracts, architecture ADRs, parity/testing strategy). List the file paths you will rely on (with a one‑line rationale each) before drafting or updating the plan.
- think deeply. draft / redraft the plan and save it to a .md under plans/active/. Structure the write-up as a phased implementation document (see `plans/archive/general-detector-geometry/implementation.md` for tone/shape): begin with context + phase overviews, then outline each phase’s intent, prerequisites, and exit criteria. When a phase benefits from explicit tracking, embed a checklist table using the `ID | Task Description | State | How/Why & Guidance` format (with `[ ]`, `[P]`, `[D]` markers) inside that phase section.
  • Include reproduction commands, owners (if known), and decision rules in the guidance column.
  • Favor narrative flow first; layer checklists only where they clarify verification steps or deliverables.
  • Mini-template to crib when drafting:
    ```md
    ## Context
    - Initiative: <initiative>
    - Phase Goal: <outcome>
    - Dependencies: <docs/tests>

    ### Phase A — <short title>
    Goal: <what this phase proves or delivers>
    Prereqs: <artifacts or measurements required before starting>
    Exit Criteria: <verifiable completion signal>

    | ID | Task Description | State | How/Why & Guidance (including API / document / artifact / source file references) |
    | --- | --- | --- | --- |
    | A1 | <Key diagnostic or implementation step> | [ ] | Run `<command>`; capture results under `reports/<date>/...`. |
    | A2 | <Follow-up validation> | [ ] | Compare against `<artifact>`; stop if deviation > threshold. |
    ```
- When refreshing an existing plan, retrofit it to this phased format before adding or editing tasks.
- review docs/fix_plan.md. edit if needed. cross reference the new plans .md so that ralph can find it.
</Planning>
</3>

<4>
<Review or housekeeping>
- Review and evaluate ralph's work. Scrutinize the commit history. Look at the diffs. 
- Are the docs/fix_plan.md contents and priorities sane? things to consider:
  - if docs/fix_plan.md is longer than 1000 lines it should be housecleaned. If it's disorganized and / or internally inconsistent, consider how this could be addressed. 
- after considering the above, you have enough information to choose a <focus issue> for this turn. do so. Consider the nature of the <focus issue>:
    - Do we need a new docs/fix_plan item to put ralph back on course, fix one of his mistakes, or instruct him to do something that he overlooked? If so, draft it and add it to docs/fix_plans
    - does the <focus issue> involve identified issues in docs/fix_plan.md? If so, fix them. If you decide to shorten docs/fix_plan.md, the least relevant portions should be moved to archive/fix_plan_archive.md (with summary + archive cross reference if appropriate)
</Review or housekeeping>
</4>

In addition to selecting an <Action type> and <focus issue> you will choose a <Mode> flag. 
 - Mode flags are combinable and refine execution, and are applicable to both the supervisor (you) and ralph; do not include any Phase label in input.md.
 - available modes: <TDD | Parity | Perf | Docs | none>
<mode descriptions>
TDD mode (supervisor-scoped): When operating in supervisor evidence mode, author/update a single minimal failing test that encodes the acceptance criterion. Confirm it fails via a targeted pytest selector; record the selector and expected failure text in input.md. Do not change production code, and do not include any Phase label in input.md.
</mode descriptions>

</main analysis step 1>

<main analysis step 2>
Here you will do a deep analysis. You will follow the guidelines of the selected <Mode> and <Action type>, applying them to the selected <focus issue>. This corresponds to <instructions> step <3.2>.


</main analysis step 2>

<main analysis step 3>
Here you synthesize the analysis findings into output files (<instructions> steps <3.5> to <4>)
</main analysis step 3>


Before concluding each invocation:
- Append a concise update to galph_memory.md capturing key findings, decisions, and open questions (reference file paths or plan names).
- Note any follow-up actions you expect Ralph to take.
- If no substantial update is needed, explicitly log that fact so future runs know context was reviewed.
</task>

<instructions>
<0>
READ the following files:
- Index of project documentation: `./docs/index.md`
- $SPECS: `./specs/spec-a.md`
- $ARCH: `./arch.md` (ADR-backed implementation architecture; reconcile design with spec, surface conflicts)
- docs/development/c_to_pytorch_config_map.md — C↔Py config parity and implicit rules
-- docs/debugging/debugging.md — Parallel trace-driven debugging SOP
- $PLAN: `./fix_plan.md` (living, prioritized to‑do; keep it up to date)
- $TESTS: `./docs/development/testing_strategy.md` (testing philosophy, tiers, seeds/tolerances, commands)
- Set `AUTHORITATIVE_CMDS_DOC=./docs/development/testing_strategy.md` (or project‑specific path) and consult it for authoritative reference commands and test discovery.
<0>
<1>
do a deep analysis of the codebase in light of the <current long term goals>. What are some current issues / gaps and possible approaches to resolving them? Review docs/fix_plan.md and plans/active/, as previous iterations of you may have already done some legwork.
 
At this point, you can do a premature <Callchain tracing> action ahead of time, if it helps you gather information needed for this analysis.
</1>
<2>
flip a coin using python. if it comes up <heads>:
review ralph's work over the last N (~10 but can be more or less - you decide) iterations. Check the commit history. Has the work been productive? Have there been regressions? Do we need to provide any feedback / course-correction?
</heads>
if it comes up <tails>: proceed to step <3>
</2>
<3>
Given your findings in <1> and <2>, think about whether there's any need for a multi-turn planning effort -- i.e. ralph can't see the forest for the trees and may struggle with major refactorings and multi-turn implementation efforts unless they are coordinated by you. Is there a need for such planning *right now*? If such a plan is already spoken for (plans/active/ or wherever else past galph might have saved to), does that plan require updates or is it up to date / high quality and simply pending? IFF you determine the need for a new plan or modification of an existing one:
<yes case>
This plan-related work is now your <focus issue>.
You will be following the <Planning> <Action type> instructions. Think about what this will entail but don't execute the <Planning> instructions yet.
</yes case>
</no case>
Since you are not <Planning>, you must select one of the other <Action type>s and an associated <focus issue> based on what you think is the most productive work increment for this iteration. Think about the associated work, but don't execute it yet.
</no case>
</3>
<3.2>
- Documentation review for <focus issue>: From `docs/index.md`, enumerate and read the documents that are most relevant to the chosen <focus issue>`; note the key file paths you will rely on for the impending analysis.
- Then carefully follow the guidelines of the selected <Mode> and <Action type>, applying them to the selected <focus issue>. Complete the task that you selected in step <3>.
</3.2>
<3.5>
Render and write ./input.md (supervisor→engineer steering memo). Overwrite the entire file every invocation. Keep length ~100–200 lines. Include these sections in order:
Header:
- Summary: <one‑sentence goal for this loop>
 - Mode: <TDD | Parity | Perf | Docs | none>
- Focus: <plan item ID/title from docs/fix_plan.md>
- Branch: <expected branch>
- Mapped tests: <validated list | none — evidence‑only>
- Artifacts: <key paths to produce under reports/>
- Do Now: 1 line naming the exact docs/fix_plan.md item (ID and title) to execute this loop, plus the exact pytest command/env to reproduce it (only when an authoritative mapping exists). If no such test exists, the Do Now MUST be to author the minimal targeted test first and then run it. If you intend to delegate the choice, write “Do Now: delegate” and provide decision guidance below.
  - Note: If operating in supervisor <Evidence collection> (internal-only), do not run the full suite. Allowed: pytest --collect-only to validate selectors; in TDD mode only, run one targeted selector to confirm a new failing test. All other test execution is deferred to Ralph. Do not include any Phase label in input.md.
<Do Now guidelines>
Verification scripts: You may run nb-compare and scripts/validation/* to collect metrics and artifacts (no code changes). Record outputs under reports/.
Mapped tests under supervisor evidence mode: Include exact selectors in input.md; validate with --collect-only; do not run them (except the TDD failure confirmation). Do not include any Phase label in input.md.
Command Sourcing (tests): Only include an exact pytest command in Do Now when sourced from an authoritative mapping (e.g., docs/development/testing_strategy.md) or an existing, known test file/identifier. If no authoritative mapping exists, set the Do Now task to author the minimal targeted test first; do not guess at a pytest selector here.
Implementation: refer to phased plans, checklists, and all associated artifacts
</Do Now guidelines>
- If Blocked: fallback action (what to run/capture, how to record it in Attempts History).
- Priorities & Rationale: 3–6 bullets with file pointers (specs/arch/tests/plan) justifying the Do Now.
- How-To Map: exact commands (pytest, nb-compare), env vars, ROI/thresholds, and where to store artifacts; prefer using `scripts/validation/*` when available.
- Pitfalls To Avoid: 5–10 crisp do/don’t reminders (device/dtype neutrality, vectorization, Protected Assets, two‑message loop policy, no ad‑hoc scripts).
- Pointers: file paths with line anchors to the most relevant spec/arch/testing_strategy/fix_plan entries for this loop.
- Next Up (optional): 1–2 candidates Ralph may choose next loop if he finishes early (still one thing per loop).

 Rules:
 - Ralph must not edit input.md. You (galph) are the single writer.
 - If input.md’s Do Now conflicts with an existing in_progress selection in fix_plan.md, Ralph is allowed to switch; he must record the change in Attempts History.
- Do not instruct Ralph to run the full test suite more than once per turn. Require targeted tests first; run the full suite once at the end only if code changed. For prompt/docs‑only loops, require `pytest --collect-only -q` instead.
- Prefer referencing reusable scripts under `scripts/validation/` from Do Now when available.
- Commit input.md each run as part of step <4> (commit only if the content changed).
 </3.5>

<4>
Before finishing the loop, enforce git hygiene:
- Run `git status --short` to inspect new or modified files that appeared during this invocation.
- Review diffs for each change; revert only if you created it this loop and it was accidental.
- Stage intentional updates with `git add -A` and commit via `git commit -m "SUPERVISOR: <scope> - <tests or rationale>"`, noting any tests run (use `tests: not run` when you skip them).
- After committing, run `git push` to share the updates. If the push is rejected, `timeout 30 git pull --rebase`, resolve conflicts (capture decisions—especially for docs/fix_plan.md—in galph_memory.md), then push again.
- If you deliberately leave the tree dirty, document the rationale in galph_memory.md so the next invocation knows why.
</4>
</instructions>
<notes>
- ignore 'routing violations'. these are out of scope.
- ignore AT parallel 012-related items for now
</notes>
Now carefully and exhaustively follow your <instructions>, while keeping in mind the <task> directives.


[2025-10-07T22:09:39] thinking

**Preparing to update repository**
[2025-10-07T22:09:41] exec bash -lc 'timeout 30 git pull --rebase' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:09:43] bash -lc 'timeout 30 git pull --rebase' succeeded in 2.30s:
Already up to date.
[2025-10-07T22:09:43] tokens used: 14,037

[2025-10-07T22:09:45] thinking

**Reviewing galph_memory.md file**
[2025-10-07T22:09:46] exec bash -lc 'cat galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:09:47] bash -lc 'cat galph_memory.md' succeeded in 697ms:
## 2025-09-30 (loops 1-4 summary)
- Established parity backlog: AT-020/021/022/024 failing; created first supervisor plan for AT-021 and enforced prompts/debug.md routing.
- Diagnosed AT-024 random misset cap mismatch (π/2 vs 90 radians) and opened dedicated plan; insisted Ralph stop verification-only loops.
- Flagged torch.compile warm-up overhead (per-instance compilation, inline tensor factories) and opened AT-012 rotation parity plan (Phases A–E).
- Documented performance hotspots (`_compute_physics_for_position` guard tensors, `Crystal.compute_cell_tensors` clamps) and chronic dirty worktree artifacts blocking `git pull --rebase`.

## 2025-09-30 (loops 5-10 summary)
- Authored repo hygiene checklist (REPO-HYGIENE-002) to undo accidental `golden_suite_generator/nanoBragg.c` churn and purge stray reports.
- Created PERF-PYTORCH-004 plan to hoist constants, introduce compile caching, and remove Dynamo graph breaks; reiterated need for prompts/debug.md while parity fails.
- Repeatedly documented routing violations from Ralph and emphasized restoring Core Rule #13 metric duality after WIP commit 058986f swapped `V_actual` for formula volume.
- Noted that `_compute_physics_for_position` still recompiles each Simulator and that benchmarks in `reports/benchmarks/20250930-004916/` show ≥200× slowdown vs C for small detectors.

## 2025-09-30 (ralph debugging loop — AT-012 float32 regression)
- **Context**: AT-PARALLEL-012 test_simple_cubic_correlation failing (43/50 peaks matched, need ≥95%) after DTYPE-DEFAULT-001 (commit 8c2ceb4) switched simulator to native float32.
- **Investigation**:
  * Reproduced: 43/50 peaks matched (86%), corr≈1.0 (perfect physics) ✅
  * Parity matrix test: PASSES perfectly ✅ (live C↔Py comparison with current float32)
  * **Root cause identified**: PyTorch float32 produces 7× more unique values (4901 vs C's 669) in hot pixels, fragmenting intensity plateaus. Peak detection algorithm (scipy.ndimage.maximum_filter) is sensitive to plateau structure.
  * Parallel comparison: C float32 beam center (20×20 ROI) has 91 unique values; PyTorch has 331 (3.6× fragmentation). Max absolute diff tiny (0.0017).
  * **First Divergence**: Numerical accumulation patterns differ (likely FMA, compiler opts, vectorized accumulation order, or torch.compile kernel fusion) → perfect correlation but incompatible plateau structure.
[2025-10-07T22:09:47] tokens used: 14,260

[2025-10-07T22:09:51] thinking

**Preparing to review documentation**
[2025-10-07T22:09:52] exec bash -lc "sed -n '1,160p' docs/index.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:09:52] bash -lc "sed -n '1,160p' docs/index.md" succeeded in 722ms:
# Project Documentation Index

Welcome to the central index for all `nanoBragg-PyTorch` project documentation. This guide provides a map to the key technical specifications, development processes, and historical records that define the project.

---

## 🏛️ Permanent Documentation

These are the core, living documents that guide the project.

### Core Project Guides
### PyTorch Guardrails
* **[PyTorch Runtime Checklist](./development/pytorch_runtime_checklist.md)** – quick do/don’t list for vectorization and device placement. Always review before editing simulator code.
* **[PyTorch Design](./architecture/pytorch_design.md#vectorization-strategy)** – detailed explanation of the required broadcast shapes and batched flows.
* **[Testing Strategy §1.4](./development/testing_strategy.md#14-pytorch-device--dtype-discipline)** – required CPU/GPU smoke tests and compile checks.

* **[CLAUDE.md](../CLAUDE.md)** - The primary instruction set for the AI agent.
* **[README.md](../README.md)** - The main project entry point.
* **[README_PYTORCH.md](../README_PYTORCH.md)** - Comprehensive user guide for the PyTorch implementation, including CLI usage, parallel comparison tools, and visualization.
* **[PROJECT_STATUS.md](../PROJECT_STATUS.md)** - Tracks the current active development initiative.
[2025-10-07T22:09:52] tokens used: 17,386

[2025-10-07T22:09:54] thinking

**Preparing to inspect spec file**
[2025-10-07T22:09:55] exec bash -lc "sed -n '1,160p' specs/spec-a.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:09:56] bash -lc "sed -n '1,160p' specs/spec-a.md" succeeded in 713ms:
# nanoBragg Spec A — Sharded Specification

Spec A is now organized across multiple shards. Read them together for the full normative contract.

- [spec-a-core.md](spec-a-core.md): Core physics, geometry, sampling, data, and associated acceptance tests.
- [spec-a-cli.md](spec-a-cli.md): CLI surface area, precedence rules, and CLI-focused acceptance tests.
- [spec-a-parallel.md](spec-a-parallel.md): Conformance profiles, parallel validation suites, and developer tooling requirements.

Each shard cross-references the others; updates must keep them consistent.
[2025-10-07T22:09:56] tokens used: 19,822

[2025-10-07T22:09:58] thinking

**Noting spec-a-core for later**
[2025-10-07T22:09:58] exec bash -lc "sed -n '1,160p' arch.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:09:59] bash -lc "sed -n '1,160p' arch.md" succeeded in 709ms:
# nanoBragg PyTorch — Implementation Architecture

Document version: 1.0 (aligned with specs/spec-a.md)
Target spec: specs/spec-a.md (single-file normative spec)
Implementation target: Python (>=3.11) + PyTorch (float32 default). Type blocks may use TypeScript-style for clarity; implement with Python dataclasses and torch tensors.

## Running The CLI

- Install (recommended):
  - `pip install -e .` from repo root (provides `nanoBragg` console script).
- Run (installed):
  - `nanoBragg -hkl P1.hkl -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -floatfile out.bin`
- Run (without install):
  - `PYTHONPATH=src python -m nanobrag_torch -hkl P1.hkl -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -floatfile out.bin`
- Minimal quick test (no HKL):
  - `nanoBragg -default_F 1 -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -detpixels 128 -pgmfile test.pgm`

Notes
- Entry point: `src/nanobrag_torch/__main__.py` (module runner `python -m nanobrag_torch`).
- Required inputs: provide `-hkl` (or existing `Fdump.bin`) or set `-default_F > 0`, and either `-mat` (MOSFLM A*) or `-cell`.
[2025-10-07T22:09:59] tokens used: 20,253

[2025-10-07T22:10:01] thinking

**Preparing to read configuration mapping docs**
[2025-10-07T22:10:02] exec bash -lc "sed -n '1,160p' docs/development/c_to_pytorch_config_map.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:02] bash -lc "sed -n '1,160p' docs/development/c_to_pytorch_config_map.md" succeeded in 715ms:
# C-CLI to PyTorch Configuration Map

## Critical Importance Notice

**This document is the authoritative source of truth for configuration parity between nanoBragg.c and the PyTorch implementation.**

Before writing any test or implementation that involves C-code validation, you **MUST** consult this document. Failure to ensure 1:1 configuration parity is the most common source of bugs, particularly with:
- Implicit pivot mode logic
- Convention-dependent beam center calculations
- Rotation axis defaults
- Unit conversions

## Quick Reference Table

### Crystal Parameters

| C-CLI Flag | PyTorch Config Field | C Variable | Units/Convention | Critical Notes |
|------------|---------------------|------------|------------------|----------------|
| `-cell a b c al be ga` | `CrystalConfig.cell_a/b/c/alpha/beta/gamma` | `a[0], b[0], c[0], alpha, beta, gamma` | Å and degrees → radians | Must convert degrees to radians internally |
| `-N <val>` | `CrystalConfig.N_cells` | `Na, Nb, Nc` | Number of unit cells | Sets all three axes to same value |
[2025-10-07T22:10:02] tokens used: 42,105

[2025-10-07T22:10:04] thinking

**Moving to debugging documentation**
[2025-10-07T22:10:05] exec bash -lc "sed -n '1,160p' docs/debugging/debugging.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:05] bash -lc "sed -n '1,160p' docs/debugging/debugging.md" succeeded in 751ms:
# nanoBragg PyTorch Debugging Guidelines

**Version:** 1.1  
**Date:** 2024-07-25  
**Owner:** PyTorch Development Team

## Overview

This document outlines the debugging methodology and tools for the nanoBragg PyTorch implementation. The debugging approach is built around a parallel trace comparison between the C code and the PyTorch implementation to ensure correctness and facilitate rapid issue resolution.

## Core Debugging Philosophy

### Parallel Trace Comparison Rule

**CRITICAL:** All debugging of physics discrepancies MUST begin with a parallel trace comparison. This involves:
1. Generating a detailed, step-by-step log of intermediate variables from the original C code for a specific pixel (the "Golden Trace").
2. Generating an identical log from the PyTorch implementation using `scripts/debug_pixel_trace.py`.
3. Comparing these two logs line-by-line to find the first point of divergence.

This methodology is mandatory to avoid guesswork and ensure bugs are found deterministically.
[2025-10-07T22:10:05] tokens used: 46,697

[2025-10-07T22:10:08] thinking

**Beginning review of large fix_plan.md**
[2025-10-07T22:10:08] exec bash -lc "sed -n '1,200p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:09] bash -lc "sed -n '1,200p' docs/fix_plan.md" succeeded in 738ms:
# Fix Plan Ledger

**Last Updated:** 2025-10-22 (ralph loop #103)
**Active Focus:**
- ROUTING: Close the reopened guard plan by capturing a fresh regression audit referencing commit `c49e3be` and re-confirming the guarded `loop.sh` flow (`plans/active/routing-loop-guard/plan.md` Phases A–C) before automation resumes.
- ROUTING-SUPERVISOR: Launch Phase A of `plans/active/supervisor-loop-guard/plan.md`, then drive Phase B guard work (B2–B4) and new task B5 to add `supervisor.sh` to docs/index.md so Protected-Asset policy covers the script before automation runs again.
- AT-012: Plan archived (`plans/archive/at-parallel-012-plateau-regression/plan.md`); monitor for regressions using `reports/2025-10-AT012-regression/phase_c_validation/` artifacts and re-open only if peak matches drop below spec.
- GRADIENT: Execute `plans/active/gradcheck-tier2-completion/plan.md` Phase A (A1–A3 baseline audit + env alignment) before adding misset/beam gradchecks from Phases B/C; once pass logs exist, close `[AT-TIER2-GRADCHECK]` with Phase D documentation updates.
- DTYPE: ✅ Complete. Plan archived to `plans/archive/dtype-default-fp32/`. All phases (A-D) finished; float32 defaults documented in arch.md, pytorch_runtime_checklist.md, CLAUDE.md, prompts/debug.md.
- PERF: Land plan task B7 (benchmark env toggle fix), rerun Phase B6 ten-process reproducibility with the new compile metadata, capture the weighted-source parity memo feeding C5, then execute Phase C diagnostics (C1/C2 plus C8/C9 pixel-grid & rotated-vector cost probes, and new C10 mosaic RNG timing) ahead of Phase D caching work (D5/D6/D7) and detector-scalar hoisting (D8).

## Index
| ID | Title | Priority | Status |
| --- | --- | --- | --- |
| [PROTECTED-ASSETS-001](#protected-assets-001-docsindexmd-safeguard) | Protect docs/index.md assets | Medium | in_progress |
| [REPO-HYGIENE-002](#repo-hygiene-002-restore-canonical-nanobraggc) | Restore canonical nanoBragg.c | Medium | in_progress |
| [PERF-PYTORCH-004](#perf-pytorch-004-fuse-physics-kernels) | Fuse physics kernels | High | in_progress |
| [AT-TIER2-GRADCHECK](#at-tier2-gradcheck-implement-tier-2-gradient-correctness-tests) | Implement Tier 2 gradient correctness tests | High | in_progress |
| [VECTOR-TRICUBIC-001](#vector-tricubic-001-vectorize-tricubic-interpolation-and-detector-absorption) | Vectorize tricubic interpolation and detector absorption | High | in_progress |
| [ABS-OVERSAMPLE-001](#abs-oversample-001-fix-oversample_thick-subpixel-absorption) | Fix -oversample_thick subpixel absorption | High | in_planning |
[2025-10-07T22:10:09] tokens used: 48,749

[2025-10-07T22:10:12] thinking

**Identifying relevant documentation sections**
[2025-10-07T22:10:13] exec bash -lc "sed -n '1,160p' docs/development/testing_strategy.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:13] bash -lc "sed -n '1,160p' docs/development/testing_strategy.md" succeeded in 698ms:
# nanoBragg PyTorch Testing Strategy

**Version:** 1.1  
**Date:** 2024-07-25  
**Owner:** [Your Name/Team]

## 1. Introduction & Philosophy

This document outlines the comprehensive testing strategy for the PyTorch implementation of nanoBragg. The primary goal is to ensure that the new application is a correct, verifiable, and trustworthy scientific tool.
Our testing philosophy is a three-tiered hybrid approach, designed to build confidence layer by layer:

1. **Tier 1: Translation Correctness:** We first prove that the PyTorch code is a faithful, numerically precise reimplementation of the original C code's physical model. The C code is treated as the "ground truth" specification.
2. **Tier 2: Gradient Correctness:** We then prove that the new differentiable capabilities are mathematically sound.
3. **Tier 3: Scientific Validation:** Finally, we validate the model against objective physical principles.

All tests will be implemented using the PyTest framework.

### 1.4 PyTorch Device & Dtype Discipline

- **Device-neutral code:** Every PyTorch path MUST operate correctly on both CPU and CUDA tensors and across supported dtypes. Do not hard-code `.cpu()`/`.cuda()` calls, create CPU-only constants, or assume float64 execution when the caller may supply float32/half tensors.
[2025-10-07T22:10:13] tokens used: 51,826

[2025-10-07T22:10:16] thinking

**Inspecting active plans for CLI flags**
[2025-10-07T22:10:17] exec bash -lc "sed -n '1,200p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:18] bash -lc "sed -n '1,200p' plans/active/cli-noise-pix0/plan.md" succeeded in 689ms:
## Context
- Initiative: CLI Parity for nanoBragg PyTorch vs C (supports long-term goal in prompts/supervisor.md)
- Phase Goal: Accept `-nonoise` and `-pix0_vector_mm` flags with C-equivalent semantics so the parallel comparison command in prompts/supervisor.md executes end-to-end.
- Dependencies: specs/spec-a-cli.md §§3.2–3.4, docs/architecture/detector.md §5, docs/development/c_to_pytorch_config_map.md (detector pivot + noise), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860 (flag behavior), docs/debugging/detector_geometry_checklist.md (pix0 validation), docs/development/testing_strategy.md §2 (CLI parity tests).
- Spec alignment note (2025-11-26): `specs/spec-a-core.md:211-214` states φ sampling SHALL follow `phi = phi0 + phistep * tic` with no state carryover. Keep the C-side defect recorded in `docs/bugs/verified_c_bugs.md:166-204` (§C-PARITY-001) quarantined to parity harnesses; do not promote it to the normative spec or default PyTorch behavior. Track that `src/nanobrag_torch/models/crystal.py:1097-1198` currently caches `_phi_last_cache` to emulate C; the remediation plan must either remove or gate this behavior behind an explicit parity toggle once CLI validation is unblocked.
- Gap snapshot update (2025-11-23 PM): Attempt #109 regenerated the TRACE_C_PHI log under `reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/` and re-ran `compare_per_phi_traces.py`; Δk now measures 1.8116e-2 at φ_tic=0 while φ≥1 stay within 2.85e-5, confirming the carryover mismatch and leaving VG-1 blocked until the remediation lands.
- Gap snapshot update (2025-11-26): Attempts #111 and #113 produced per-φ traces with max Δk=2.845e-05. This still exceeds the VG-1 gate (Δk, Δb_y ≤ 1e-6). Treat those commits as partial progress until fresh traces prove the tighter tolerance.
- Current gap snapshot (2025-10-18 refresh): Phase H4 parity landed (Attempt #25) with pix0 deltas < 2e-8 m and regression tolerances tightened; the remaining blocker before executing the supervisor command end-to-end is Phase I polarization alignment.
- Gap snapshot refresh (2025-10-07 08:41): Attempt #101 activated TRACE_C_PHI (C instrumentation) and captured matching Py per-φ traces. Divergence isolated to φ_tic=0 (Δk≈1.81e-2) while φ>0 steps remain within 3e-5. Phase L3k.3 moves to φ=0 initialization parity (L3k.3c) plus ROI/nb-compare follow-ups.
- Gap snapshot update (2025-10-19): Attempt #27 parity run reveals 1.24538e5× intensity scaling mismatch despite polarization fix; Phases J–L track the normalization diagnosis, fix, and closure required before long-term Goal #1 completes.
- Gap snapshot refresh (2025-10-22): Attempt #31 restored C precedence for custom detector vectors (pix0 override now gated again). Outstanding work: H5c PyTorch traces and Phase K normalization to eliminate the `F_latt`-driven intensity gap.
- Gap snapshot update (2025-10-24): Attempt #35 reran the PyTorch trace harness post-unit-fix; metrics still show |Δpix0| ≈ 1.145 mm, so a fresh diagnostics phase is required before resuming normalization work.
- Gap snapshot refresh (2025-10-26): Attempt #40 completed Phase H6f — custom detector vectors now force SAMPLE pivot parity, parity visuals relocated under `reports/2025-10-cli-flags/phase_h6/visuals/`, and targeted regression tests cover pivot selection. Outstanding work at that point: Phase H6g trace rerun to confirm |Δpix0| < 5e-5 m before returning to Phase K scalings.
- Gap snapshot update (2025-10-27): Attempt #41 validated Phase H6g — SAMPLE pivot parity holds with pix0 deltas ≤2.85 µm, beam center deltas 0.0, and supporting artifacts under `reports/2025-10-cli-flags/phase_h6/post_fix/`. Remaining blockers: rerun the scaling chain (Phase K2), execute the scaling regression + doc updates (Phase K3), then resume Phase L parity once normalization matches C.
- Gap snapshot refresh (2025-11-09): Attempt #49 closed Phase K3g3 — `tests/test_cli_scaling.py::test_f_latt_square_matches_c` now passes after isolating the HKL cache, but the full supervisor command still shows correlation ≈ 0.9965 and sum_ratio ≈ 1.26×10⁵. Need fresh HKL/normalization parity evidence (Phase L) before rerunning nb-compare.
- Gap snapshot refresh (2025-11-10): Attempt #56 (evidence loop) proved the existing `TRACE_PY` path prints placeholder scaling data (`capture_fraction 1`, `polar 1.0`, `steps`=φ-steps only). Without exposing the real per-pixel factors computed in `Simulator.run`, Phase L2b cannot produce a trustworthy PyTorch trace. Instrumentation must pull actual values from `_apply_detector_absorption`, polarization kernels, and total-step calculation before rerunning the harness.
- Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
- Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
- Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
[2025-10-07T22:10:18] tokens used: 54,470

[2025-10-07T22:10:22] thinking

**Reviewing long-term goals and fix_plan status**

I'm diving into the user's long-term goals and starting by examining the fix_plan item CLI-FLAGS-003 to understand its current status and how it relates to key tasks like supporting specific command flags and verifying important bug fixes. I'll search the fix_plan for relevant details to align next steps carefully.
[2025-10-07T22:10:23] exec bash -lc 'rg "CLI-FLAGS-003" -n docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:24] bash -lc 'rg "CLI-FLAGS-003" -n docs/fix_plan.md' succeeded in 689ms:
22:| [CLI-FLAGS-003](#cli-flags-003-handle-nonoise-and-pix0_vector_mm) | Handle -nonoise and -pix0_vector_mm | High | in_progress |
450:## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
513:      - **Recommended path forward**: Keep current C-parity implementation to complete CLI-FLAGS-003 validation; post-cleanup, introduce `--c-parity-mode` flag and default to spec-compliant behavior
688:      - C trace evidence indicates state carryover within the reference implementation. Until we either patch the C code or emulate this behavior, PyTorch must conform to the reference output to unblock CLI-FLAGS-003.
2049:  * [2025-11-23] Attempt #111 (ralph loop, CLI-FLAGS-003 L3k.3c.4) — Result: **SUCCESS** (VG-1 validation COMPLETE). **Per-φ parity achieved; all 10 φ steps match C within tolerance.**
[2025-10-07T22:10:24] tokens used: 58,119

[2025-10-07T22:10:26] thinking

**Checking specific code lines**
[2025-10-07T22:10:26] exec bash -lc "sed -n '450,750p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:27] bash -lc "sed -n '450,750p' docs/fix_plan.md" succeeded in 741ms:
## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
- Spec/AT: specs/spec-a-cli.md flag catalogue, docs/architecture/detector.md §5 (pix0 workflow), docs/development/c_to_pytorch_config_map.md (pivot rules), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860
- Priority: High
- Status: in_progress (Phases A–H complete; K3a/K3b/K3d landed via Attempts #43–44, pending per-φ evidence + normalization closure)
- Owner/Date: ralph/2025-10-05
- Plan Reference: `plans/active/cli-noise-pix0/plan.md`
- Reproduction (C & PyTorch):
  * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
  * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C's trace records `F_cell=190.27`. **Phase L3b (Attempt #76) proved the data exists (scaled.hkl contains F=190.27 for this reflection); root cause is configuration/loading, NOT missing coverage.**
- Next Actions (2025-11-26 refresh → galph loop i=112):
1. **Phase L3k.3c.3 still failing** — Attempts #111/#113 improved gradients but Δk remains 2.845e-05 (>1e-6) and `test_k_frac_phi0_matches_c` stays red. Regenerate per-φ traces after fixing the cache so both Δk and Δb_y ≤1e-6 (CPU+CUDA), then update `comparison_summary.md`, `delta_metrics.json`, and the VG-1 checklist before proceeding.
2. **Phase L3k.3c.4 documentation** — Capture a short memo (reports/…/diagnosis.md) citing `specs/spec-a-core.md:211-214` (normative φ-step rotation) and `docs/bugs/verified_c_bugs.md:166-204` (C PARITY bug) to clarify the spec-mandated behavior (no carryover) versus the C reference defect. Call out that `src/nanobrag_torch/models/crystal.py:1097-1198` currently caches the previous φ slice (`_phi_last_cache`) to emulate C. The memo must recommend how PyTorch will deliver spec-compliant defaults with an explicit parity shim or guard to keep CLI comparisons unblocked, and link the artifact in this fix-plan entry.
3. Phase L3k.3d — Resolve the nb-compare ROI anomaly (C sum≈0) before repeating VG-3/VG-4; capture the corrected summary.json/logs under `nb_compare_phi_fix/` once correlation ≥0.9995 and sum_ratio 0.99–1.01. After VG-1/VG-3/VG-4 pass, proceed to L3k.3e → L3k.4 documentation and fix_plan logging ahead of the Phase L4 supervisor-command rerun.
4. Phase L3k.3e — Once VG-1/VG-3/VG-4 are green, close out documentation/checklist chores (VG-5) and log the implementation Attempt before moving to the Phase L4 supervisor command rerun.
- Attempts History:
  * [2025-11-21] Attempt #95 (galph supervisor loop) — Result: **PLANNING UPDATE** (Phase L3k added). **No code changes.**
    Metrics: Planning-only (no tests executed).
    Artifacts:
      - `plans/active/cli-noise-pix0/plan.md` — New Phase L3k section outlining implementation gates.
[2025-10-07T22:10:27] tokens used: 58,557

[2025-10-07T22:10:31] thinking

**Assessing project goals and plans**

I'm reviewing the current status of key long-term goals like command support with specific flags, phi carryover and normalization issues blocking progress, and plans to avoid bugs in specs versus C code. I'm also checking vectorization plans to align ongoing work with these objectives.
[2025-10-07T22:10:32] exec bash -lc 'ls plans/active' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:33] bash -lc 'ls plans/active' succeeded in 679ms:
cli-noise-pix0
gradcheck-tier2-completion
oversample-thick-subpixel.md
perf-pytorch-compile-refactor
routing-loop-guard
source-weight-normalization.md
supervisor-loop-guard
unification.md
vectorization.md
[2025-10-07T22:10:33] tokens used: 61,837

[2025-10-07T22:10:36] thinking

**Opening vectorization plan**
[2025-10-07T22:10:36] exec bash -lc "sed -n '1,200p' plans/active/vectorization.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:37] bash -lc "sed -n '1,200p' plans/active/vectorization.md" succeeded in 680ms:
## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.

### Phase A — Evidence & Baseline Capture
Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.
Prereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.
Exit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [D] | ✅ Completed 2025-10-06 (`reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`). Re-run only if dependencies change or new warnings appear. |
| A2 | Measure current tricubic runtime | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/tricubic_baseline.py` created; CPU & CUDA baselines captured in `phase_a/tricubic_baseline.md` and `phase_a/tricubic_baseline_results.json`). Key finding: scalar-only implementation @ ~1.4 ms/call (CPU), ~5.5 ms/call (CUDA). |
| A3 | Record detector absorption baseline | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/absorption_baseline.py` created; CPU & CUDA baselines captured in `phase_a/absorption_baseline.md` and `phase_a/absorption_baseline_results.json`). GPU shows 5.4× speedup for 512² detector. |

### Phase B — Tricubic Vectorization Design
Goal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.
[2025-10-07T22:10:37] tokens used: 62,104

[2025-10-07T22:10:39] thinking

**Initiating deep analysis phase**
[2025-10-07T22:10:40] exec bash -lc 'rg -n "phi" docs/bugs/verified_c_bugs.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:40] bash -lc 'rg -n "phi" docs/bugs/verified_c_bugs.md' succeeded in 703ms:
167:**Summary:** Inside the φ loop, the rotated vectors `ap/bp/cp` are only updated when `phi != 0.0`; otherwise, they retain the previous state (often from the prior pixel’s final φ step). This produces step-0 Miller fractions that mirror the previous pixel rather than the unrotated lattice.
173:  -phi 0 -osc 0.09 -phisteps 10 -trace_pixel 0 0 \
174:  -floatfile /tmp/phi_float.bin -intfile /tmp/phi_int.img -noisefile /tmp/phi_noise.img \
180:- `golden_suite_generator/nanoBragg.c:3042-3059` — rotation only applied when `phi != 0.0`; no reset path exists.
203:4. Reset `ap/bp/cp` when `phi == 0.0` so the first φ slice uses the unrotated lattice.
[2025-10-07T22:10:40] tokens used: 63,626

[2025-10-07T22:10:43] thinking

**Opening relevant section**
[2025-10-07T22:10:43] exec bash -lc "sed -n '150,220p' docs/bugs/verified_c_bugs.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:44] bash -lc "sed -n '150,220p' docs/bugs/verified_c_bugs.md" succeeded in 685ms:
  -nopgm -nonoise -noprogress > docs/bugs/artifacts/design-flaw-005-with-hkl.txt

# Second run: no -hkl, automatically reads the cache
./golden_suite_generator/nanoBragg -cell 70 70 70 90 90 90 -N 0 \
  -distance 100 -detpixels 2 -pixel 0.1 \
  -floatfile /tmp/cache2_float.bin -intfile /tmp/cache2_int.img -noisefile /tmp/cache2_noise.img \
  -nopgm -nonoise -noprogress > docs/bugs/artifacts/design-flaw-005-no-hkl.txt
```
The follow-up log contains `reading Fs from Fdump.bin`, demonstrating the implicit dependency.

**Relevant code:**
- `golden_suite_generator/nanoBragg.c:1297-1304` — attempts to open `Fdump.bin` whenever `-hkl` is absent.
- `golden_suite_generator/nanoBragg.c:2355-2368` — rehydrates the cached structure factors silently.

---

### C-PARITY-001 — φ=0 Uses Stale Crystal Vectors (Medium)
**Summary:** Inside the φ loop, the rotated vectors `ap/bp/cp` are only updated when `phi != 0.0`; otherwise, they retain the previous state (often from the prior pixel’s final φ step). This produces step-0 Miller fractions that mirror the previous pixel rather than the unrotated lattice.

**Reproduction:**
[2025-10-07T22:10:44] tokens used: 64,083

[2025-10-07T22:10:50] thinking

**Analyzing project goals and potential issues**
[2025-10-07T22:10:50] exec bash -lc 'rg -n "phi" specs/spec-a-core.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:51] bash -lc 'rg -n "phi" specs/spec-a-core.md' succeeded in 715ms:
211:                    - φ step: φ = φ0 + (step index)*phistep; rotate the reference cell (a0,b0,c0)
248:    - Define steps = (number of sources) · (number of mosaic domains) · (phisteps) · (oversample^2).
414:        - Steps = (#accepted divergence points) × dispsteps × mosaic_domains × phisteps ×
507:    - For each of horizontal divergence, vertical divergence, spectral dispersion, phi, and detector thickness sampling, missing combinations of count/range/step SHALL be resolved per the rules in “Sources, Divergence & Dispersion” and “Sampling & Accumulation”, resulting in:
575:    - Setup: sources=1; mosaic_domains=1; oversample=1; phisteps=2 with identical physics across steps (e.g., zero mosaic and symmetric phi so F_cell and F_latt identical); disable thickness/polar/omega oversample toggles.
[2025-10-07T22:10:51] tokens used: 65,491

[2025-10-07T22:10:54] thinking

**Scrolling for context**
[2025-10-07T22:10:56] exec bash -lc "sed -n '200,240p' specs/spec-a-core.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:10:56] bash -lc "sed -n '200,240p' specs/spec-a-core.md" succeeded in 664ms:
            - For each source:
                - Incident unit vector i = −source_dir (unitized); wavelength λ from source.
                - q = (d − i) / λ (m^-1). stol = 0.5·||q||.
                - If dmin > 0 and stol > 0 and dmin > 0.5/stol: skip this subpath.
                - Polarization factor (if enabled; Kahn model):
                    - cos(2θ) = i·d; sin^2(2θ) = 1 − cos^2(2θ).
                    - Construct B_in = unit(p × i), E_in = unit(i × B_in). Project d into this EB
plane: E_out = d·E_in, B_out = d·B_in. ψ = −atan2(B_out, E_out).
                    - Polarization factor = 0.5·(1 + cos^2(2θ) − K·cos(2ψ)·sin^2(2θ)), where K is
the Kahn factor from -polar.
                - Crystal orientation:
                    - φ step: φ = φ0 + (step index)*phistep; rotate the reference cell (a0,b0,c0)
about u by φ to get (ap,bp,cp).
                    - Mosaic: for each domain, apply the domain’s rotation to (ap,bp,cp) to get
(a,b,c).
                - Fractional Miller indices: h = a·q, k = b·q, l = c·q (dimensionless).
                - Nearest integer triplet: (h0, k0, l0) = round to nearest via ceil(x − 0.5).
                - Lattice factor F_latt:
                    - SQUARE (grating): F_latt = sincg(π·h, Na) · sincg(π·k, Nb) · sincg(π·l, Nc),
where
[2025-10-07T22:10:56] tokens used: 65,919

[2025-10-07T22:10:59] thinking

**Confirming specification clarity**
[2025-10-07T22:11:00] exec bash -lc "python - <<'PY'
import random
print(random.choice(['heads','tails']))
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:01] bash -lc "python - <<'PY'
import random
print(random.choice(['heads','tails']))
PY" succeeded in 733ms:
heads
[2025-10-07T22:11:01] tokens used: 67,038

[2025-10-07T22:11:03] thinking

**Inspecting recent commits**
[2025-10-07T22:11:04] exec bash -lc 'git log --oneline -n 12' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:04] bash -lc 'git log --oneline -n 12' succeeded in 731ms:
fedb25f [SYNC i=115] actor=galph status=running
7c6dfef [SYNC i=115] actor=ralph → next=galph status=ok ralph_commit=0856435
0856435 CLI-FLAGS-003 L3k.3c.4: Complete spec-vs-parity documentation memo
3339e88 [SYNC i=114] actor=ralph status=running
cd9774b [SYNC i=114] actor=galph → next=ralph status=ok galph_commit=0dfc46c
0dfc46c SUPERVISOR: φ spec memo log - tests: not run
10333c0 SUPERVISOR: CLI φ memo guidance - tests: not run
f584650 [SYNC i=114] actor=galph status=running
d93a4bd [SYNC i=114] actor=ralph → next=galph status=ok ralph_commit=0a75aab
0a75aab CLI-FLAGS-003 L3k.3c.4: Spec-vs-parity φ rotation analysis memo
5e8885b [SYNC i=113] actor=ralph status=running
98f3a8d [SYNC i=113] actor=galph → next=ralph status=ok galph_commit=91e882d
[2025-10-07T22:11:04] tokens used: 67,236

[2025-10-07T22:11:06] thinking

**Preparing to review specific commit**
[2025-10-07T22:11:07] exec bash -lc 'git show 0856435' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:07] bash -lc 'git show 0856435' succeeded in 731ms:
commit 08564355f41cbd42de88cdac32d8ae646f49cbde
Author: ollie <ohoidn>
Date:   Tue Oct 7 15:08:35 2025 -0700

    CLI-FLAGS-003 L3k.3c.4: Complete spec-vs-parity documentation memo
    
    docs/fix_plan.md Attempt #114 already logged (diagnosis.md refreshed with
    6-section analysis). This commit marks task L3k.3c.4 complete in the plan
    and captures the collect-only log.
    
    Test collection: 2 tests collected (test_rot_b_matches_c, test_k_frac_phi0_matches_c)
    
    Artifacts:
    - reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md:116-353 (6 sections)
    - reports/2025-10-cli-flags/phase_l/rot_vector/collect_only.log (2 tests)
    - plans/active/cli-noise-pix0/plan.md:310 (task marked [D])
    
    Next: Supervisor to review threshold relaxation vs strict parity per L3k.3c.4
    recommendation (spec-compliant default + optional --c-parity-mode flag).

[2025-10-07T22:11:07] tokens used: 67,725

[2025-10-07T22:11:11] thinking

**Reviewing recent documentation commits**
[2025-10-07T22:11:12] exec bash -lc 'git show 0a75aab' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:12] bash -lc 'git show 0a75aab' succeeded in 748ms:
commit 0a75aabc3504284ed7fd236cea91143f83f8af99
Author: ollie <ohoidn>
Date:   Tue Oct 7 15:00:14 2025 -0700

    CLI-FLAGS-003 L3k.3c.4: Spec-vs-parity φ rotation analysis memo
    
    Phase L3k.3c.4 documentation complete per input.md directive.
    
    Changes:
    - diagnosis.md: Added complete spec-vs-parity analysis with 6 sections:
      1. Normative spec behavior (specs/spec-a-core.md:211 quote)
      2. C-PARITY-001 bug evidence (docs/bugs/verified_c_bugs.md:166)
      3. Current PyTorch behavior (crystal.py:1115 cache mechanism)
      4. Compatibility plan (spec-compliant default vs C-parity shim)
      5. Verification checklist (5 VG gates + 4 documentation gates)
      6. References & next actions
    
    - Captured collect-only.log: 2 tests collected (test_rot_b_matches_c, test_k_frac_phi0_matches_c)
    - Updated fix_plan.md: Attempt #114 logged with artifacts and observations
    
[2025-10-07T22:11:12] tokens used: 70,793

[2025-10-07T22:11:23] thinking

**Evaluating plan status and completeness**

I'm reviewing the current plan’s state, focusing on CLI flags, phi bug specifications, and vectorization phases to determine if any updates or clarifications are needed. I'm carefully weighing the existing documentation against the instructions to see if the plan requires modification or further detail, especially around spec compliance and vectorization progress. I'll keep gathering information on the vectorization phases to better assess next steps.
[2025-10-07T22:11:24] exec bash -lc "sed -n '200,400p' plans/active/vectorization.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:25] bash -lc "sed -n '200,400p' plans/active/vectorization.md" succeeded in 694ms:

[2025-10-07T22:11:25] tokens used: 74,363

[2025-10-07T22:11:33] thinking

**Reviewing plan file length and completeness**

I'm checking whether the plan file is shorter than 200 lines since sed commands beyond line 200 return empty. It looks like the plan only includes Phases A-C and might be truncated or incomplete, possibly due to output suppression or formatting issues, so I’m verifying file length and content before deciding if a plan update is needed.
[2025-10-07T22:11:35] exec bash -lc 'wc -l plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:35] bash -lc 'wc -l plans/active/vectorization.md' succeeded in 712ms:
      90 plans/active/vectorization.md
[2025-10-07T22:11:35] tokens used: 75,037

[2025-10-07T22:11:38] thinking

**Confirming full file content**
[2025-10-07T22:11:39] exec bash -lc 'cat plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:39] bash -lc 'cat plans/active/vectorization.md' succeeded in 679ms:
## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.

### Phase A — Evidence & Baseline Capture
Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.
Prereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.
Exit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [D] | ✅ Completed 2025-10-06 (`reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`). Re-run only if dependencies change or new warnings appear. |
| A2 | Measure current tricubic runtime | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/tricubic_baseline.py` created; CPU & CUDA baselines captured in `phase_a/tricubic_baseline.md` and `phase_a/tricubic_baseline_results.json`). Key finding: scalar-only implementation @ ~1.4 ms/call (CPU), ~5.5 ms/call (CUDA). |
| A3 | Record detector absorption baseline | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/absorption_baseline.py` created; CPU & CUDA baselines captured in `phase_a/absorption_baseline.md` and `phase_a/absorption_baseline_results.json`). GPU shows 5.4× speedup for 512² detector. |

### Phase B — Tricubic Vectorization Design
Goal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.
[2025-10-07T22:11:39] tokens used: 75,178

[2025-10-07T22:11:43] thinking

**Investigating truncated file output**
[2025-10-07T22:11:44] exec bash -lc "python - <<'PY'
from pathlib import Path
text = Path('plans/active/vectorization.md').read_text()
print(repr(text))
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:44] bash -lc "python - <<'PY'
from pathlib import Path
text = Path('plans/active/vectorization.md').read_text()
print(repr(text))
PY" succeeded in 692ms:
'## Context\n- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.\n- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.\n- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.\n- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).\n- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.\n\n### Phase A — Evidence & Baseline Capture\nGoal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.\nPrereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.\nExit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| A1 | Re-run tricubic acceptance tests | [D] | ✅ Completed 2025-10-06 (`reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`). Re-run only if dependencies change or new warnings appear. |\n| A2 | Measure current tricubic runtime | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/tricubic_baseline.py` created; CPU & CUDA baselines captured in `phase_a/tricubic_baseline.md` and `phase_a/tricubic_baseline_results.json`). Key finding: scalar-only implementation @ ~1.4 ms/call (CPU), ~5.5 ms/call (CUDA). |\n| A3 | Record detector absorption baseline | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/absorption_baseline.py` created; CPU & CUDA baselines captured in `phase_a/absorption_baseline.md` and `phase_a/absorption_baseline_results.json`). GPU shows 5.4× speedup for 512² detector. |\n\n### Phase B — Tricubic Vectorization Design\nGoal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.\nPrereqs: Phase A artifacts uploaded and referenced in docs/fix_plan.md.\nExit Criteria: Design memo (`reports/2025-10-vectorization/phase_b/design_notes.md`) describing target shapes, indexing strategy, gradient expectations, and failure modes; docs/fix_plan.md updated with summary and link.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| B1 | Derive tensor shapes & broadcasting plan | [D] | ✅ Attempt #3 (2025-10-07) captured the `(B,4,4,4)` gather layout plus memory envelope; see `design_notes.md` §2 with diagrams + OOB masking guidance. |\n| B2 | Map C polin3 semantics to PyTorch ops | [D] | ✅ Attempt #3 recorded Lagrange polynomial translation and reuse strategy (design_notes §3, referencing `nanoBragg.c` lines 4021-4058). |\n| B3 | Gradient & dtype checklist | [D] | ✅ Attempt #3 consolidated differentiability/device rules (design_notes §4) aligning with `pytorch_runtime_checklist.md`; reuse table when authoring Phase E regression tests. |\n\n### Phase C — Implementation: Neighborhood Gather\nGoal: Replace scalar neighbor gathering with fully batched advanced indexing inside `Crystal._tricubic_interpolation` while keeping fallbacks for out-of-range queries.\nPrereqs: Phase B design finalized; create feature branch per SOP if needed.\nExit Criteria: Vectorized gather merged, unit tests covering neighborhood assembly added, and plan task C1–C3 marked done with artifact references.\nImplementation notes: capture all Phase C artifacts under `reports/2025-10-vectorization/phase_c/` (see table for filenames). Confirm every new test collects via `pytest --collect-only` before running the selector.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| C1 | Implement batched neighborhood gather | [D] | ✅ Completed 2025-10-17 (Attempt #5). Batched gather infrastructure validated; all tests passing. Artifacts: `reports/2025-10-vectorization/phase_c/{gather_notes.md, collect_log.txt, test_*.log, diff_snapshot.json, runtime_probe.json}`. Scalar path (B=1) uses existing polin3; batched path (B>1) falls back to nearest-neighbor pending Phase D. |\n| C2 | Preserve fallback semantics | [D] | ✅ Completed 2025-10-07 (Attempt #1). Authored `test_oob_warning_single_fire` capturing stdout to verify single-warning behavior; test asserts `_interpolation_warning_shown` flag state, `interpolate` disable, and `default_F` fallback on OOB queries. All tricubic tests pass (8/8). Artifacts: `reports/2025-10-vectorization/phase_c/{test_tricubic_vectorized.log, status_snapshot.txt}`; test code at `tests/test_tricubic_vectorized.py:199-314`. |\n| C3 | Add shape assertions & cache hooks | [D] | ✅ Completed 2025-10-07 (Attempt #6). Shape assertions added for `(B, 4, 4, 4)` neighborhoods and output shapes; device consistency checks ensure tensors stay on input device. No explicit caching present in tricubic path. All targeted tests passing (5 gather + 1 acceptance). Artifacts: `reports/2025-10-vectorization/phase_c/{test_tricubic_vectorized.log, test_at_str_002_phi.log, implementation_notes.md}`. Code refs: `crystal.py:414-427` (shape/device assertions), `crystal.py:440-447` (scalar output assertions), `crystal.py:461-462` (batched fallback assertions). |\n\n#### Phase C3 Verification Checklist\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| C3.1 | Assertion coverage | [D] | ✅ Completed. Added `assert sub_Fhkl.shape == (B, 4, 4, 4)`, `assert h_indices.shape == (B, 4)` (k,l similar), plus output assertions `F_cell.numel() == 1` (scalar) and `result.shape == original_shape` (both paths). Code refs: `crystal.py:414-420, 440-447, 461-462`. Documented in `implementation_notes.md` Phase C3 section. |\n| C3.2 | Device-aware caching audit | [D] | ✅ Completed. No caching exists in `_tricubic_interpolation`. Added device checks: `assert sub_Fhkl.device == h.device`, `assert h_indices.device == h.device`. Verified device propagation: offsets use `device=self.device`, grids inherit from inputs, `.to(dtype=)` preserves device. Code ref: `crystal.py:422-427`. Audit documented in `implementation_notes.md` §2. |\n| C3.3 | Targeted pytest evidence | [D] | ✅ Completed. Ran `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Logs stored: `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log` and `test_at_str_002_phi.log`. Total 6/6 tests passed; CPU + CUDA paths validated. |\n\n### Phase D — Implementation: Polynomial Evaluation\nGoal: Vectorize `polint`, `polin2`, and `polin3` so they consume batches from Phase C without Python loops.\nPrereqs: Phase C merged or staged with passing tests.\nExit Criteria: All polynomial helpers accept batched tensors, no Python loops over pixels remain, and helper-level unit tests exist.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| D1 | Vectorize `polint` | [ ] | Rewrite using tensor broadcasting; support trailing batch dims and ensure numerical stability matches C (consider Kahan-style compensation if necessary). Add regression test in `tests/test_tricubic_vectorized.py::test_polint_vectorized_matches_scalar`. |\n| D2 | Vectorize `polin2`/`polin3` | [ ] | Stack vectorized `polint` results instead of looping; maintain compatibility with scalar callers (if any). Capture proof-of-equivalence logs in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`. |\n| D3 | Audit differentiability | [ ] | Run `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_gradients.py::TestCrystal::test_tricubic_gradient -v` (add test if absent) to confirm gradients survive the refactor. |\n\n### Phase E — Validation & Performance Assessment\nGoal: Prove the new vectorized path matches legacy outputs, keeps gradients, and improves runtime on representative detector sizes.\nPrereqs: Phases C/D complete; baseline artifacts from Phase A available for comparison.\nExit Criteria: Validation summary in `reports/2025-10-vectorization/phase_e/summary.md` including parity metrics, perf deltas, and gradient results; docs/fix_plan.md attempts updated.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| E1 | Regression tests sweep | [ ] | `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_tricubic_vectorized.py -v` (CPU + CUDA when available). Log outputs under `phase_e/pytest.log`. |\n| E2 | Performance benchmark | [ ] | Reuse the Phase A harnesses (`tricubic_baseline.py`, `absorption_baseline.py`) in "baseline" vs "vectorized" modes; run CPU & CUDA sweeps with identical seeds and persist outputs to `phase_e/perf_results.json`. |\n| E3 | Parity against C reference | [ ] | Use `nb-compare --resample --outdir reports/2025-10-vectorization/phase_e/nb_compare -- -default_F ...` (match AT-STR-002 config) to ensure intensities align within tolerance. Summarize metrics in `phase_e/summary.md`. |\n\n### Phase F — Detector Absorption Vectorization\nGoal: Apply the same vectorization discipline to `_apply_detector_absorption`, eliminating Python loops over `thicksteps` while preserving physics.\nPrereqs: Phase E validated so tricubic changes are stable; absorption baseline from Phase A available.\nExit Criteria: Vectorized absorption path merged, tests updated, and performance improvements documented similar to tricubic work.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| F1 | Refresh design notes | [ ] | Append absorption section to `design_notes.md` describing tensor shapes (`(T,S,F)`), numerical stability considerations, and potential reuse of exponential precomputation. |\n| F2 | Implement vectorized absorption | [ ] | Modify `_apply_detector_absorption` to broadcast layer indices and parallax tensors as described; maintain differentiability and device neutrality. Record implementation notes in `phase_f/implementation.md`. |\n| F3 | Validate & benchmark | [ ] | `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_abs_001.py -v` plus microbenchmark update; capture results under `phase_f/summary.md` comparing against Phase A data. |\n\n### Phase G — Documentation & Closure\nGoal: Ensure documentation, plans, and fix_plan reflect the new vectorized behavior and that artifacts are archived.\nPrereqs: Phases A–F complete.\nExit Criteria: Plan archived or marked complete, docs updated, and fix_plan entry closed.\n\n| ID | Task Description | State | How/Why & Guidance |\n| --- | --- | --- | --- |\n| G1 | Update documentation | [ ] | Revise `docs/architecture/pytorch_design.md` (vectorization subsections) and `docs/development/pytorch_runtime_checklist.md` with the new expectations; note script locations in `docs/development/testing_strategy.md`. |\n| G2 | Close planning artifacts | [ ] | Move key reports to `reports/archive/` (retain relative paths), update docs/fix_plan.md Attempts with final metrics, and archive this plan per SOP. |\n'
[2025-10-07T22:11:44] tokens used: 76,771

[2025-10-07T22:11:53] thinking

**Preparing to update vectorization plan**

The existing plan seems truncated and incomplete, especially around Phase C, so I’m focusing on confirming the need to update the plan before proceeding. Since long-term goals emphasize firming up the vectorization plan—particularly tricubic vectorization—I'm gathering relevant documentation to inform a thorough plan revision. I’ll dive into key docs like `pytorch_design.md` to ensure I understand the vectorization strategy before drafting any updates.
[2025-10-07T22:11:55] exec bash -lc 'rg -n "tricubic" docs/architecture/pytorch_design.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:55] bash -lc 'rg -n "tricubic" docs/architecture/pytorch_design.md' exited 1 in 715ms:

[2025-10-07T22:11:55] tokens used: 79,006

[2025-10-07T22:11:57] thinking

**Searching documentation case-insensitively**
[2025-10-07T22:11:58] exec bash -lc 'rg -n "Tricubic" docs/architecture/pytorch_design.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:11:59] bash -lc 'rg -n "Tricubic" docs/architecture/pytorch_design.md' exited 1 in 710ms:

[2025-10-07T22:11:59] tokens used: 79,710

[2025-10-07T22:12:01] thinking

**Considering documentation accessibility**
[2025-10-07T22:12:01] exec bash -lc "sed -n '1,120p' docs/architecture/pytorch_design.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:02] bash -lc "sed -n '1,120p' docs/architecture/pytorch_design.md" succeeded in 723ms:
# nanoBragg PyTorch Architecture Design (Addendum)

## 1.2 Differentiability vs Performance

Principle: Differentiability is required; over-hardening is not. Prefer the minimal change that passes gradcheck and preserves vectorization.

- Minimal Differentiability Contract
  - Return analytic limits at removable singularities only when the raw op produces NaN/Inf or unacceptable relative error in tests.
  - Keep the nominal fast path branch-free (or mask-based) and fully vectorized.
  - Avoid speculative guards and extra branches unless backed by (a) a reproduced gradient failure or (b) a measured numerical/perf improvement.

- Branching Budget (Hot Helpers)
  - Per-element branching inside hot helpers (e.g., `sincg`, `sinc3`, polarization) must be justified with numbers (gradcheck evidence or microbenchmark delta).

- Mask vs Guard
  - Masks gate analytic limits; a single epsilon guard may backstop tiny denominators. If the mask tolerance renders guards redundant, prefer the mask alone.

- Precision Guidance
  - Default dev dtype: float64; default prod dtype: float32. Tolerances must state dtype assumptions and be tested in both where relevant.

[2025-10-07T22:12:02] tokens used: 80,506

[2025-10-07T22:12:05] thinking

**Planning to review specific docs**
[2025-10-07T22:12:05] exec bash -lc "sed -n '1,160p' docs/development/pytorch_runtime_checklist.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:06] bash -lc "sed -n '1,160p' docs/development/pytorch_runtime_checklist.md" succeeded in 703ms:
# PyTorch Runtime Checklist

Use this quick checklist before and after every PyTorch simulator edit. It distills the authoritative guidance from
`docs/architecture/pytorch_design.md`, `CLAUDE.md`, and the testing strategy.

1. **Vectorization**
   - Do not reintroduce Python loops that duplicate work already handled by batched tensor code.
   - When adding a new flow (sources, phi, mosaic, oversample), extend the existing broadcast shapes instead of looping.
   - Verify `_compute_physics_for_position` receives tensors with the expected batch dimensions.

2. **Device & Dtype Neutrality**
   - **Default dtype is float32** for performance and memory efficiency. Precision-critical operations (gradient checks, metric duality) explicitly override to float64 where required.
   - Materialize configuration tensors (beam, detector, crystal) on the execution device before the main loop.
   - Avoid per-iteration `.to()`, `.cpu()`, `.cuda()`, or tensor factories (`torch.tensor(...)`) inside compiled regions; cache constants once.
   - Run CPU **and** CUDA smoke commands (`pytest -v -m gpu_smoke`) when a GPU is available.

3. **torch.compile Hygiene**
   - Watch the console for Dynamo “graph break” warnings; treat them as blockers.
   - Benchmarks should reuse compiled functions; avoid changing shapes every call unless batching logic handles it.

[2025-10-07T22:12:06] tokens used: 81,151

[2025-10-07T22:12:09] thinking

**Investigating tricubic details in docs**
[2025-10-07T22:12:10] exec bash -lc 'rg -n "polin3" docs/architecture/c_code_overview.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:11] bash -lc 'rg -n "polin3" docs/architecture/c_code_overview.md' exited 1 in 751ms:

[2025-10-07T22:12:11] tokens used: 81,747

[2025-10-07T22:12:15] thinking

**Searching for C function documentation**
[2025-10-07T22:12:17] exec bash -lc 'rg -n "tricubic" docs/architecture/c_function_reference.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:18] bash -lc 'rg -n "tricubic" docs/architecture/c_function_reference.md' exited 1 in 839ms:

[2025-10-07T22:12:18] tokens used: 82,705

[2025-10-07T22:12:26] thinking

**Reviewing vectorization docs for planning**
[2025-10-07T22:12:27] exec bash -lc 'rg -n "VECTOR-TRICUBIC-001" -n docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:28] bash -lc 'rg -n "VECTOR-TRICUBIC-001" -n docs/fix_plan.md' succeeded in 737ms:
19:| [VECTOR-TRICUBIC-001](#vector-tricubic-001-vectorize-tricubic-interpolation-and-detector-absorption) | Vectorize tricubic interpolation and detector absorption | High | in_progress |
2194:## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
[2025-10-07T22:12:28] tokens used: 83,843

[2025-10-07T22:12:31] thinking

**Reviewing specific section**
[2025-10-07T22:12:32] exec bash -lc "sed -n '2194,2400p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:33] bash -lc "sed -n '2194,2400p' docs/fix_plan.md" succeeded in 689ms:
## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
- Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
- Priority: High
- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
- Owner/Date: galph/2025-10-17
- Plan Reference: `plans/active/vectorization.md`
- Reproduction (C & PyTorch):
  * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
  * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
- First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
- Next Actions (2025-11-23 refresh):
 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
- Attempts History:
  * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
    Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
    Artifacts:
      - `reports/2025-10-vectorization/phase_a/test_at_str_002.collect.log` — Test collection output confirming 3 tests collected
[2025-10-07T22:12:33] tokens used: 84,137

[2025-10-07T22:12:47] thinking

**Preparing comprehensive plan update**

I’m mapping out a thorough plan rewrite to extend through Phases D, E, F, and possibly beyond, integrating fix_plan's next actions and aligning with existing docs and reports. I’ll gather references to clearly document completed, ongoing, and pending tasks with detailed checklists and status tables.
[2025-10-07T22:12:48] exec bash -lc 'ls reports/2025-10-vectorization' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:49] bash -lc 'ls reports/2025-10-vectorization' succeeded in 1.02s:
phase_a
phase_b
phase_c
[2025-10-07T22:12:49] tokens used: 88,010

[2025-10-07T22:12:51] thinking

**Examining phase_c artifacts**
[2025-10-07T22:12:52] exec bash -lc 'ls reports/2025-10-vectorization/phase_c' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:53] bash -lc 'ls reports/2025-10-vectorization/phase_c' succeeded in 807ms:
collect_log.txt
diff_snapshot.json
gather_notes.md
gradient_smoke.log
implementation_notes.md
runtime_probe.json
status_snapshot.txt
test_at_str_002_phi.log
test_tricubic_interpolation_enabled.log
test_tricubic_out_of_bounds_fallback.log
test_tricubic_vectorized.log
[2025-10-07T22:12:53] tokens used: 88,150

[2025-10-07T22:12:55] thinking

**Checking implementation notes**
[2025-10-07T22:12:56] exec bash -lc "sed -n '1,120p' reports/2025-10-vectorization/phase_c/implementation_notes.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:12:57] bash -lc "sed -n '1,120p' reports/2025-10-vectorization/phase_c/implementation_notes.md" succeeded in 893ms:
# Phase C1 Implementation Notes: Batched Neighborhood Gather

**Date:** 2025-10-07
**Git SHA:** (to be recorded in fix_plan)
**Initiative:** VECTOR-TRICUBIC-001 (PERF-PYTORCH-004 backlog)
**Plan Reference:** `plans/active/vectorization.md` Phase C (tasks C1–C3)
**Design Reference:** `reports/2025-10-vectorization/phase_b/design_notes.md`

---

## Executive Summary

Successfully implemented batched neighborhood gather (Phase C1) in `Crystal._tricubic_interpolation`. The implementation constructs `(B, 4, 4, 4)` structure factor neighborhoods for batched Miller index queries using advanced PyTorch indexing, eliminating the need for Python loops over query points.

**Key Deliverable:** Infrastructure for vectorized tricubic interpolation is complete. Phase D (polynomial evaluation vectorization) can now consume the batched neighborhoods.

---

## Implementation Changes

[2025-10-07T22:12:57] tokens used: 88,466

[2025-10-07T22:13:20] thinking

**Outlining comprehensive plan rewrite**

I'm preparing a detailed, multi-phase plan covering completed and upcoming tasks with status markers, artifact references, checklists, and exit criteria. I'll include structured sections from context through phases A to F (and possibly G), carefully aligning existing fix_plan entries and incorporating instructions for documentation, verification, and artifact storage to ensure clarity and traceability.
[2025-10-07T22:13:44] exec bash -lc "python - <<'PY'
from pathlib import Path
plan = Path('plans/active/vectorization.md')
text = '''## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog supporting docs/fix_plan.md entry [VECTOR-TRICUBIC-001].
- Phase Goal: Deliver a production-ready batched tricubic interpolation pipeline (gather + polynomial evaluation) and subsequently vectorize detector absorption without regressing parity, gradients, or device/dtype neutrality.
- Dependencies:
  - specs/spec-a-core.md §4 (structure-factor sampling contract)
  - specs/spec-a-parallel.md §2.3 (tricubic acceptance tests + tolerances)
  - docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy, broadcast shapes)
  - docs/development/testing_strategy.md §§1.4–2 (test cadence, authoritative commands)
  - docs/development/pytorch_runtime_checklist.md (device/vectorization guardrails)
  - "'`nanoBragg.c` lines 2604–3278 (polin3/polin2/polint) & 3375–3450 (detector absorption loop)
  - Existing artifacts under `reports/2025-10-vectorization/phase_*/`
- Status Snapshot (2025-11-27): Phases A–C complete with gather vectorization merged (commit 12742e5). Polynomial helpers still scalar; detector absorption remains looped. Phase D is the active gate before parity/perf validation (Phase E) and absorption work (Phase F).
- Execution Notes: Store new evidence under `reports/2025-10-vectorization/phase_<letter>/` directories; every implementation task must quote the matching C snippet per CLAUDE Rule #11. Maintain CPU+CUDA parity and include `pytest --collect-only` proof before targeted runs.

### Phase A — Evidence & Baseline Capture
Goal: Record baseline behaviour/warnings/timings for tricubic interpolation and detector absorption prior to vectorization.
Prereqs: Editable install (`pip install -e .`), C binary available if parity comparisons are needed, `KMP_DUPLICATE_LIB_OK=TRUE` set.
Exit Criteria: Baseline pytest logs + benchmark metrics archived and referenced in fix_plan.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [D] | ✅ Attempt #1 (2025-10-06). Artifacts: `reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`. |
| A2 | Measure current tricubic runtime | [D] | ✅ Attempt #2 (2025-10-07). Harness: `scripts/benchmarks/tricubic_baseline.py`; metrics in `phase_a/tricubic_baseline.md` & `tricubic_baseline_results.json`. |
| A3 | Record detector absorption baseline | [D] | ✅ Attempt #2 (2025-10-07). Harness: `scripts/benchmarks/absorption_baseline.py`; metrics in `phase_a/absorption_baseline.md` & `absorption_baseline_results.json`. |

### Phase B — Tricubic Vectorization Design
Goal: Finalise tensor-shape, broadcasting, and differentiability design ahead of implementation.
Prereqs: Phase A evidence captured and logged.
Exit Criteria: Completed design memo plus grad/device checklist; fix_plan updated with references.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| B1 | Derive tensor shapes & broadcasting plan | [D] | ✅ Attempt #3 (2025-10-07). See `reports/2025-10-vectorization/phase_b/design_notes.md` §2. |
| B2 | Map C polin3 semantics to PyTorch ops | [D] | ✅ Attempt #3. Design notes §3 cites `nanoBragg.c:4021-4058`. |
| B3 | Gradient & dtype checklist | [D] | ✅ Attempt #3. Design notes §4 aligns with `pytorch_runtime_checklist.md`. |

### Phase C — Neighborhood Gather Implementation
Goal: Replace scalar neighbour gathering with vectorised indexing in `Crystal._tricubic_interpolation` while retaining OOB fallbacks and graph connectivity.
Prereqs: Phase B design complete; tests discoverable.
Exit Criteria: Batched gather merged, unit/regression tests passing on CPU+CUDA, plan/fix_plan updated with evidence.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| C1 | Implement batched neighbourhood gather | [D] | ✅ Attempt #15 (2025-10-07). Implementation notes: `reports/2025-10-vectorization/phase_c/implementation_notes.md`; code in `src/nanobrag_torch/models/crystal.py` (commit 12742e5). |
| C2 | Add gather-specific test suite | [D] | ✅ Attempt #15. `tests/test_tricubic_vectorized.py` + logs (`phase_c/test_tricubic_vectorized.log`, `gather_notes.md`). Includes CPU+CUDA device cases. |
| C3 | Regression + gradient/device smoke | [D] | ✅ Attempt #16 (2025-10-08). Artifacts: `phase_c/gradient_smoke.log`, `runtime_probe.json`, `status_snapshot.txt`; targeted pytest selectors recorded. |

### Phase D — Polynomial Evaluation Vectorization (Active Gate)
Goal: Batch the 1D/2D/3D polynomial interpolation helpers (`polint`, `polin2`, `polin3`) so batched gathers avoid nearest-neighbour fallback.
Prereqs: Phase C output confirmed; `design_notes.md` §3 ready; create `reports/2025-10-vectorization/phase_d/` directory.
Exit Criteria: Vectorised polynomial helpers integrated, CPU+CUDA tests passing, documentation + metrics captured.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| D1 | Draft polynomial validation worksheet | [ ] | Create `phase_d/polynomial_validation.md` capturing tensor-shape derivations, broadcast diagrams, and mapping to `nanoBragg.c` code. Include plan for tap points (scalar vs batched) and cite design_notes §3. |
| D2 | Implement batched `polint`/`polin2`/`polin3` | [ ] | Modify `utils/physics.py` (or dedicated helper) ensuring `(B,4)` inputs broadcast to `(B,)` outputs. Add C reference docstrings per CLAUDE Rule #11. Preserve differentiability (no `.detach()`/`.item()`). |
| D3 | Add polynomial regression tests | [ ] | Extend `tests/test_tricubic_vectorized.py` with `TestTricubicPoly` covering scalar vs batched equivalence, gradient flow (`torch.autograd.gradcheck` in float64), and device parametrisation. Capture `pytest --collect-only` in `phase_d/collect.log` before targeted runs. |
| D4 | Execute targeted pytest sweep | [ ] | Run `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v` on CPU and (if available) CUDA. Store logs under `phase_d/pytest_cpu.log` and `phase_d/pytest_cuda.log`; update `polynomial_validation.md` with timing deltas. |

### Phase E — Integration, Parity, and Performance Validation
Goal: Confirm the full tricubic interpolation path stays vectorised, maintains parity, and improves performance per PERF-PYTORCH-004 objectives.
Prereqs: Phase D tasks D1–D4 complete; nearest-neighbour fallback eliminated for batched queries.
Exit Criteria: Parity metrics (tests + nb-compare/ROI) pass, microbenchmarks show expected speedup, documentation + fix_plan updated.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| E1 | Verify acceptance & regression tests | [ ] | Re-run `tests/test_at_str_002.py`, `tests/test_tricubic_vectorized.py`, and any affected gradient suites. Capture CPU/CUDA logs under `phase_e/pytest_cpu.log` & `phase_e/pytest_cuda.log`. Ensure `pytest --collect-only` evidence stored (`phase_e/collect.log`). |
| E2 | Run microbenchmarks post-vectorization | [ ] | Execute `scripts/benchmarks/tricubic_baseline.py` with `--outdir reports/2025-10-vectorization/phase_e/perf` (before/after metrics). Summarise deltas in `phase_e/perf_summary.md` and update `benchmark_results.json`. |
| E3 | Document parity/perf summary | [ ] | Produce `phase_e/summary.md` noting corr/Δ metrics vs scalar path, reference nb-compare outputs if used, and record gradient/device neutrality confirmation. Update docs/fix_plan attempt with metrics + artifact links. |

### Phase F — Detector Absorption Vectorization
Goal: Batch detector absorption loops over `detector_thicksteps` and oversample dimensions, reusing the tricubic vectorization patterns while keeping physics parity.
Prereqs: Phase E exit criteria satisfied; confirm current absorption baseline artifacts (Phase A3) on hand.
Exit Criteria: Vectorised absorption in production path, tests/benchmarks passing, documentation updated.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| F1 | Author absorption vectorization design | [ ] | Draft `phase_f/design_notes.md` (tensor layout, broadcasting, device/dtype considerations). Cite `nanoBragg.c:3375-3450` and detector spec docs. |
| F2 | Implement batched absorption | [ ] | Update `_apply_detector_absorption` (or equivalent) to operate on broadcast tensors (slow×fast×thicksteps). Add C reference docstrings and ensure differentiability. |
| F3 | Add regression + perf tests | [ ] | Extend `tests/test_at_abs_001.py` with device parametrisation; add targeted benchmarks via `scripts/benchmarks/absorption_baseline.py --outdir .../phase_f/perf`. Capture CPU/CUDA logs. |
| F4 | Summarise results + update fix_plan | [ ] | Document outcomes in `phase_f/summary.md`, note parity evidence (nb-compare if applicable), and update docs/fix_plan attempt history. |

### Phase G — Documentation & Handoff
Goal: Ensure all vectorization changes are documented, reproducible, and integrated with performance guidance.
Prereqs: Phases D–F exit criteria met.
Exit Criteria: Architecture/runtime docs updated; fix_plan closed; supervisor input ready for performance initiative follow-ups.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| G1 | Update docs & checklists | [ ] | Refresh `docs/development/pytorch_runtime_checklist.md` (if needed), `docs/architecture/pytorch_design.md`, and add lessons learned note. Record changes in docs/fix_plan. |
| G2 | Final attempt log & closure | [ ] | Log concluding Attempt in docs/fix_plan.md, summarise metrics, and mark [VECTOR-TRICUBIC-001] as done. Coordinate with PERF-PYTORCH-004 benchmarks for follow-up perf tasks. |
'"'''
plan.write_text(text)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:13:45] bash -lc "python - <<'PY'
from pathlib import Path
plan = Path('plans/active/vectorization.md')
text = '''## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog supporting docs/fix_plan.md entry [VECTOR-TRICUBIC-001].
- Phase Goal: Deliver a production-ready batched tricubic interpolation pipeline (gather + polynomial evaluation) and subsequently vectorize detector absorption without regressing parity, gradients, or device/dtype neutrality.
- Dependencies:
  - specs/spec-a-core.md §4 (structure-factor sampling contract)
  - specs/spec-a-parallel.md §2.3 (tricubic acceptance tests + tolerances)
  - docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy, broadcast shapes)
  - docs/development/testing_strategy.md §§1.4–2 (test cadence, authoritative commands)
  - docs/development/pytorch_runtime_checklist.md (device/vectorization guardrails)
  - "'`nanoBragg.c` lines 2604–3278 (polin3/polin2/polint) & 3375–3450 (detector absorption loop)
  - Existing artifacts under `reports/2025-10-vectorization/phase_*/`
- Status Snapshot (2025-11-27): Phases A–C complete with gather vectorization merged (commit 12742e5). Polynomial helpers still scalar; detector absorption remains looped. Phase D is the active gate before parity/perf validation (Phase E) and absorption work (Phase F).
- Execution Notes: Store new evidence under `reports/2025-10-vectorization/phase_<letter>/` directories; every implementation task must quote the matching C snippet per CLAUDE Rule #11. Maintain CPU+CUDA parity and include `pytest --collect-only` proof before targeted runs.

### Phase A — Evidence & Baseline Capture
Goal: Record baseline behaviour/warnings/timings for tricubic interpolation and detector absorption prior to vectorization.
Prereqs: Editable install (`pip install -e .`), C binary available if parity comparisons are needed, `KMP_DUPLICATE_LIB_OK=TRUE` set.
Exit Criteria: Baseline pytest logs + benchmark metrics archived and referenced in fix_plan.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [D] | ✅ Attempt #1 (2025-10-06). Artifacts: `reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`. |
| A2 | Measure current tricubic runtime | [D] | ✅ Attempt #2 (2025-10-07). Harness: `scripts/benchmarks/tricubic_baseline.py`; metrics in `phase_a/tricubic_baseline.md` & `tricubic_baseline_results.json`. |
| A3 | Record detector absorption baseline | [D] | ✅ Attempt #2 (2025-10-07). Harness: `scripts/benchmarks/absorption_baseline.py`; metrics in `phase_a/absorption_baseline.md` & `absorption_baseline_results.json`. |

### Phase B — Tricubic Vectorization Design
Goal: Finalise tensor-shape, broadcasting, and differentiability design ahead of implementation.
Prereqs: Phase A evidence captured and logged.
Exit Criteria: Completed design memo plus grad/device checklist; fix_plan updated with references.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| B1 | Derive tensor shapes & broadcasting plan | [D] | ✅ Attempt #3 (2025-10-07). See `reports/2025-10-vectorization/phase_b/design_notes.md` §2. |
| B2 | Map C polin3 semantics to PyTorch ops | [D] | ✅ Attempt #3. Design notes §3 cites `nanoBragg.c:4021-4058`. |
| B3 | Gradient & dtype checklist | [D] | ✅ Attempt #3. Design notes §4 aligns with `pytorch_runtime_checklist.md`. |

### Phase C — Neighborhood Gather Implementation
Goal: Replace scalar neighbour gathering with vectorised indexing in `Crystal._tricubic_interpolation` while retaining OOB fallbacks and graph connectivity.
Prereqs: Phase B design complete; tests discoverable.
Exit Criteria: Batched gather merged, unit/regression tests passing on CPU+CUDA, plan/fix_plan updated with evidence.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| C1 | Implement batched neighbourhood gather | [D] | ✅ Attempt #15 (2025-10-07). Implementation notes: `reports/2025-10-vectorization/phase_c/implementation_notes.md`; code in `src/nanobrag_torch/models/crystal.py` (commit 12742e5). |
| C2 | Add gather-specific test suite | [D] | ✅ Attempt #15. `tests/test_tricubic_vectorized.py` + logs (`phase_c/test_tricubic_vectorized.log`, `gather_notes.md`). Includes CPU+CUDA device cases. |
| C3 | Regression + gradient/device smoke | [D] | ✅ Attempt #16 (2025-10-08). Artifacts: `phase_c/gradient_smoke.log`, `runtime_probe.json`, `status_snapshot.txt`; targeted pytest selectors recorded. |

### Phase D — Polynomial Evaluation Vectorization (Active Gate)
Goal: Batch the 1D/2D/3D polynomial interpolation helpers (`polint`, `polin2`, `polin3`) so batched gathers avoid nearest-neighbour fallback.
Prereqs: Phase C output confirmed; `design_notes.md` §3 ready; create `reports/2025-10-vectorization/phase_d/` directory.
Exit Criteria: Vectorised polynomial helpers integrated, CPU+CUDA tests passing, documentation + metrics captured.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| D1 | Draft polynomial validation worksheet | [ ] | Create `phase_d/polynomial_validation.md` capturing tensor-shape derivations, broadcast diagrams, and mapping to `nanoBragg.c` code. Include plan for tap points (scalar vs batched) and cite design_notes §3. |
| D2 | Implement batched `polint`/`polin2`/`polin3` | [ ] | Modify `utils/physics.py` (or dedicated helper) ensuring `(B,4)` inputs broadcast to `(B,)` outputs. Add C reference docstrings per CLAUDE Rule #11. Preserve differentiability (no `.detach()`/`.item()`). |
| D3 | Add polynomial regression tests | [ ] | Extend `tests/test_tricubic_vectorized.py` with `TestTricubicPoly` covering scalar vs batched equivalence, gradient flow (`torch.autograd.gradcheck` in float64), and device parametrisation. Capture `pytest --collect-only` in `phase_d/collect.log` before targeted runs. |
| D4 | Execute targeted pytest sweep | [ ] | Run `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v` on CPU and (if available) CUDA. Store logs under `phase_d/pytest_cpu.log` and `phase_d/pytest_cuda.log`; update `polynomial_validation.md` with timing deltas. |

### Phase E — Integration, Parity, and Performance Validation
Goal: Confirm the full tricubic interpolation path stays vectorised, maintains parity, and improves performance per PERF-PYTORCH-004 objectives.
Prereqs: Phase D tasks D1–D4 complete; nearest-neighbour fallback eliminated for batched queries.
Exit Criteria: Parity metrics (tests + nb-compare/ROI) pass, microbenchmarks show expected speedup, documentation + fix_plan updated.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| E1 | Verify acceptance & regression tests | [ ] | Re-run `tests/test_at_str_002.py`, `tests/test_tricubic_vectorized.py`, and any affected gradient suites. Capture CPU/CUDA logs under `phase_e/pytest_cpu.log` & `phase_e/pytest_cuda.log`. Ensure `pytest --collect-only` evidence stored (`phase_e/collect.log`). |
| E2 | Run microbenchmarks post-vectorization | [ ] | Execute `scripts/benchmarks/tricubic_baseline.py` with `--outdir reports/2025-10-vectorization/phase_e/perf` (before/after metrics). Summarise deltas in `phase_e/perf_summary.md` and update `benchmark_results.json`. |
| E3 | Document parity/perf summary | [ ] | Produce `phase_e/summary.md` noting corr/Δ metrics vs scalar path, reference nb-compare outputs if used, and record gradient/device neutrality confirmation. Update docs/fix_plan attempt with metrics + artifact links. |

### Phase F — Detector Absorption Vectorization
Goal: Batch detector absorption loops over `detector_thicksteps` and oversample dimensions, reusing the tricubic vectorization patterns while keeping physics parity.
Prereqs: Phase E exit criteria satisfied; confirm current absorption baseline artifacts (Phase A3) on hand.
Exit Criteria: Vectorised absorption in production path, tests/benchmarks passing, documentation updated.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| F1 | Author absorption vectorization design | [ ] | Draft `phase_f/design_notes.md` (tensor layout, broadcasting, device/dtype considerations). Cite `nanoBragg.c:3375-3450` and detector spec docs. |
| F2 | Implement batched absorption | [ ] | Update `_apply_detector_absorption` (or equivalent) to operate on broadcast tensors (slow×fast×thicksteps). Add C reference docstrings and ensure differentiability. |
| F3 | Add regression + perf tests | [ ] | Extend `tests/test_at_abs_001.py` with device parametrisation; add targeted benchmarks via `scripts/benchmarks/absorption_baseline.py --outdir .../phase_f/perf`. Capture CPU/CUDA logs. |
| F4 | Summarise results + update fix_plan | [ ] | Document outcomes in `phase_f/summary.md`, note parity evidence (nb-compare if applicable), and update docs/fix_plan attempt history. |

### Phase G — Documentation & Handoff
Goal: Ensure all vectorization changes are documented, reproducible, and integrated with performance guidance.
Prereqs: Phases D–F exit criteria met.
Exit Criteria: Architecture/runtime docs updated; fix_plan closed; supervisor input ready for performance initiative follow-ups.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| G1 | Update docs & checklists | [ ] | Refresh `docs/development/pytorch_runtime_checklist.md` (if needed), `docs/architecture/pytorch_design.md`, and add lessons learned note. Record changes in docs/fix_plan. |
| G2 | Final attempt log & closure | [ ] | Log concluding Attempt in docs/fix_plan.md, summarise metrics, and mark [VECTOR-TRICUBIC-001] as done. Coordinate with PERF-PYTORCH-004 benchmarks for follow-up perf tasks. |
'"'''
plan.write_text(text)
PY" succeeded in 1.09s:

[2025-10-07T22:13:45] tokens used: 94,378

[2025-10-07T22:14:00] thinking

**Updating fix_plan Next Actions section**

I’m working on aligning the Next Actions bullet list in `docs/fix_plan.md` with the updated plan for vectorization, adding phases D4 and E, updating the date, and including references to plan lines and paths. I’ll carefully replace just that bullet block using Python string replacement to keep everything precise.
[2025-10-07T22:14:10] exec bash -lc "python - <<'PY'
from pathlib import Path
path = Path('docs/fix_plan.md')
text = path.read_text()
old = \"- Next Actions (2025-11-23 refresh):\\n 1. Phase D1 — implement batched "'`polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.'"\\n 2. Phase D2 — extend the batched polynomial path to "'`polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.'"\\n 3. Phase D3 — run gradient + device regression sweep ("'`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.'"\\n\"
new = \"- Next Actions (2025-11-27 refresh → galph supervision):\\n  1. Phase D1 — Follow "'`plans/active/vectorization.md` (Phase D table) to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md` with tensor-shape derivations and C references before code edits. Include tap-point plan and cite design_notes §3.'"\\n  2. Phase D2 — Implement vectorised "'`polint`/`polin2`/`polin3` per plan guidance, adding CLAUDE Rule #11 docstrings and ensuring differentiability/device neutrality.'"\\n  3. Phase D3 — Extend "'`tests/test_tricubic_vectorized.py` with `TestTricubicPoly` and capture collect-only evidence under `phase_d/collect.log` prior to targeted pytest runs.'"\\n  4. Phase D4 — Execute CPU + CUDA sweeps ("'`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) storing logs under `phase_d/pytest_cpu.log` & `phase_d/pytest_cuda.log`; summarise timings in `polynomial_validation.md`.'"\\n  5. Phase E staging — After D1–D4 pass, prep "'`reports/2025-10-vectorization/phase_e/` (collect log, benchmark command templates) before launching E1–E3 validation tasks.'"\\n\"
if old not in text:
    raise SystemExit('target block not found')
path.write_text(text.replace(old, new))
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:14:11] bash -lc "python - <<'PY'
from pathlib import Path
path = Path('docs/fix_plan.md')
text = path.read_text()
old = \"- Next Actions (2025-11-23 refresh):\\n 1. Phase D1 — implement batched "'`polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.'"\\n 2. Phase D2 — extend the batched polynomial path to "'`polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.'"\\n 3. Phase D3 — run gradient + device regression sweep ("'`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.'"\\n\"
new = \"- Next Actions (2025-11-27 refresh → galph supervision):\\n  1. Phase D1 — Follow "'`plans/active/vectorization.md` (Phase D table) to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md` with tensor-shape derivations and C references before code edits. Include tap-point plan and cite design_notes §3.'"\\n  2. Phase D2 — Implement vectorised "'`polint`/`polin2`/`polin3` per plan guidance, adding CLAUDE Rule #11 docstrings and ensuring differentiability/device neutrality.'"\\n  3. Phase D3 — Extend "'`tests/test_tricubic_vectorized.py` with `TestTricubicPoly` and capture collect-only evidence under `phase_d/collect.log` prior to targeted pytest runs.'"\\n  4. Phase D4 — Execute CPU + CUDA sweeps ("'`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) storing logs under `phase_d/pytest_cpu.log` & `phase_d/pytest_cuda.log`; summarise timings in `polynomial_validation.md`.'"\\n  5. Phase E staging — After D1–D4 pass, prep "'`reports/2025-10-vectorization/phase_e/` (collect log, benchmark command templates) before launching E1–E3 validation tasks.'"\\n\"
if old not in text:
    raise SystemExit('target block not found')
path.write_text(text.replace(old, new))
PY" succeeded in 1.04s:

[2025-10-07T22:14:11] tokens used: 98,542

[2025-10-07T22:14:16] thinking

**Updating next actions plan**
[2025-10-07T22:14:17] exec bash -lc "sed -n '2194,2240p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:14:18] bash -lc "sed -n '2194,2240p' docs/fix_plan.md" succeeded in 843ms:
## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
- Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
- Priority: High
- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
- Owner/Date: galph/2025-10-17
- Plan Reference: `plans/active/vectorization.md`
- Reproduction (C & PyTorch):
  * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
  * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
- First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
- Next Actions (2025-11-27 refresh → galph supervision):
  1. Phase D1 — Follow `plans/active/vectorization.md` (Phase D table) to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md` with tensor-shape derivations and C references before code edits. Include tap-point plan and cite design_notes §3.
  2. Phase D2 — Implement vectorised `polint`/`polin2`/`polin3` per plan guidance, adding CLAUDE Rule #11 docstrings and ensuring differentiability/device neutrality.
  3. Phase D3 — Extend `tests/test_tricubic_vectorized.py` with `TestTricubicPoly` and capture collect-only evidence under `phase_d/collect.log` prior to targeted pytest runs.
  4. Phase D4 — Execute CPU + CUDA sweeps (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) storing logs under `phase_d/pytest_cpu.log` & `phase_d/pytest_cuda.log`; summarise timings in `polynomial_validation.md`.
  5. Phase E staging — After D1–D4 pass, prep `reports/2025-10-vectorization/phase_e/` (collect log, benchmark command templates) before launching E1–E3 validation tasks.
- Attempts History:
  * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
    Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
[2025-10-07T22:14:18] tokens used: 99,746

[2025-10-07T22:14:22] thinking

**Preparing planning documentation and updates**
[2025-10-07T22:14:23] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:14:24] bash -lc 'git status --short' succeeded in 891ms:
 M docs/fix_plan.md
 M plans/active/vectorization.md
[2025-10-07T22:14:24] tokens used: 101,641

[2025-10-07T22:14:38] thinking

**Preparing input.md for documentation phase**
[2025-10-07T22:14:39] exec bash -lc "nl -ba docs/fix_plan.md | sed -n '2194,2248p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:14:40] bash -lc "nl -ba docs/fix_plan.md | sed -n '2194,2248p'" succeeded in 1.08s:
  2194	## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
  2195	- Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
  2196	- Priority: High
  2197	- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
  2198	- Owner/Date: galph/2025-10-17
  2199	- Plan Reference: `plans/active/vectorization.md`
  2200	- Reproduction (C & PyTorch):
  2201	  * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
  2202	  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
  2203	  * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
  2204	- First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
  2205	- Next Actions (2025-11-27 refresh → galph supervision):
  2206	  1. Phase D1 — Follow `plans/active/vectorization.md` (Phase D table) to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md` with tensor-shape derivations and C references before code edits. Include tap-point plan and cite design_notes §3.
  2207	  2. Phase D2 — Implement vectorised `polint`/`polin2`/`polin3` per plan guidance, adding CLAUDE Rule #11 docstrings and ensuring differentiability/device neutrality.
  2208	  3. Phase D3 — Extend `tests/test_tricubic_vectorized.py` with `TestTricubicPoly` and capture collect-only evidence under `phase_d/collect.log` prior to targeted pytest runs.
  2209	  4. Phase D4 — Execute CPU + CUDA sweeps (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) storing logs under `phase_d/pytest_cpu.log` & `phase_d/pytest_cuda.log`; summarise timings in `polynomial_validation.md`.
  2210	  5. Phase E staging — After D1–D4 pass, prep `reports/2025-10-vectorization/phase_e/` (collect log, benchmark command templates) before launching E1–E3 validation tasks.
  2211	- Attempts History:
  2212	  * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
  2213	    Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
[2025-10-07T22:14:40] tokens used: 170,914

[2025-10-07T22:14:43] thinking

**Collecting plan file line numbers**
[2025-10-07T22:14:43] exec bash -lc 'nl -ba plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:14:44] bash -lc 'nl -ba plans/active/vectorization.md' succeeded in 840ms:
     1	## Context
     2	- Initiative: PERF-PYTORCH-004 vectorization backlog supporting docs/fix_plan.md entry [VECTOR-TRICUBIC-001].
     3	- Phase Goal: Deliver a production-ready batched tricubic interpolation pipeline (gather + polynomial evaluation) and subsequently vectorize detector absorption without regressing parity, gradients, or device/dtype neutrality.
     4	- Dependencies:
     5	  - specs/spec-a-core.md §4 (structure-factor sampling contract)
     6	  - specs/spec-a-parallel.md §2.3 (tricubic acceptance tests + tolerances)
     7	  - docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy, broadcast shapes)
     8	  - docs/development/testing_strategy.md §§1.4–2 (test cadence, authoritative commands)
     9	  - docs/development/pytorch_runtime_checklist.md (device/vectorization guardrails)
    10	  - `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint) & 3375–3450 (detector absorption loop)
    11	  - Existing artifacts under `reports/2025-10-vectorization/phase_*/`
    12	- Status Snapshot (2025-11-27): Phases A–C complete with gather vectorization merged (commit 12742e5). Polynomial helpers still scalar; detector absorption remains looped. Phase D is the active gate before parity/perf validation (Phase E) and absorption work (Phase F).
    13	- Execution Notes: Store new evidence under `reports/2025-10-vectorization/phase_<letter>/` directories; every implementation task must quote the matching C snippet per CLAUDE Rule #11. Maintain CPU+CUDA parity and include `pytest --collect-only` proof before targeted runs.
    14	
    15	### Phase A — Evidence & Baseline Capture
    16	Goal: Record baseline behaviour/warnings/timings for tricubic interpolation and detector absorption prior to vectorization.
    17	Prereqs: Editable install (`pip install -e .`), C binary available if parity comparisons are needed, `KMP_DUPLICATE_LIB_OK=TRUE` set.
    18	Exit Criteria: Baseline pytest logs + benchmark metrics archived and referenced in fix_plan.
    19	
    20	| ID | Task Description | State | How/Why & Guidance |
[2025-10-07T22:14:44] tokens used: 174,083

[2025-10-07T22:14:46] thinking

**Preparing to write input.md**
[2025-10-07T22:14:47] exec bash -lc 'git branch --show-current' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:14:47] bash -lc 'git branch --show-current' succeeded in 727ms:
feature/spec-based-2
[2025-10-07T22:14:47] tokens used: 175,740

[2025-10-07T22:14:54] thinking

**Composing detailed input.md content**

I'll create an input.md file for the feature/spec-based-2 branch with the specified sections, balancing detail and length around 100-200 lines. I'll include test collection commands, artifact lists, rationales with precise file references, commands for mapping, pitfalls, and pointers, carefully following instructions to keep it concise but comprehensive.
[2025-10-07T22:15:01] exec bash -lc "python - <<'PY'
from pathlib import Path
text = '''Summary: Capture Phase D1 design notes for tricubic polynomial vectorization
Mode: Docs
Focus: VECTOR-TRICUBIC-001 / Phase D1
Branch: feature/spec-based-2
Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log
Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run "'`pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
If Blocked: Capture notes in polynomial_validation.md explaining the blocker; rerun the collect-only command and log failure output in collect.log

Priorities & Rationale:
- plans/active/vectorization.md:48 — Phase D table makes polynomial vectorization the active gate
- docs/fix_plan.md:2194 — Next Actions require Phase D1 artefact before code changes
- docs/development/testing_strategy.md:74 — Collect-only proof mandated ahead of targeted pytest runs
- reports/2025-10-vectorization/phase_b/design_notes.md — Holds prior broadcast math that Phase D must extend
- docs/development/pytorch_runtime_checklist.md:1 — Vectorization/device guardrails to cite in the worksheet

How-To Map:
- export KMP_DUPLICATE_LIB_OK=TRUE
- mkdir -p reports/2025-10-vectorization/phase_d
- pytest --collect-only -q tests/test_tricubic_vectorized.py | tee reports/2025-10-vectorization/phase_d/collect.log
- Summarise tensor shapes, broadcast diagrams, tap points, and C references in reports/2025-10-vectorization/phase_d/polynomial_validation.md

Pitfalls To Avoid:
- Do not skip CLAUDE Rule #11 C-quote requirements for upcoming helper edits
- No code edits this loop; stay in documentation/design scope
- Keep device/dtype neutrality front of mind (note CPU+CUDA requirements in the plan)
- Don’t promise runtime gains without scheduling Phase E benchmarks
- Avoid inventing new command syntax; reuse scripts/benchmarks harnesses already referenced
- Ensure collect-only output is captured; supervisors need proof before implementations
- Keep references scoped to Protected Assets list (no file deletions)
- Note that torch.compile graph breaks must be documented if uncovered later

Pointers:
- plans/active/vectorization.md:48 — Phase D requirements
- docs/fix_plan.md:2194 — Active fix-plan entry for VECTOR-TRICUBIC-001
- docs/development/testing_strategy.md:70 — Supervisor loop testing cadence
- reports/2025-10-vectorization/phase_c/implementation_notes.md — Prior phase context for gather output shapes

Next Up: Phase D2 — implement batched polint/polin2/polin3 once D1 artefacts are signed off
'"'''
Path('input.md').write_text(text)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:15:02] bash -lc "python - <<'PY'
from pathlib import Path
text = '''Summary: Capture Phase D1 design notes for tricubic polynomial vectorization
Mode: Docs
Focus: VECTOR-TRICUBIC-001 / Phase D1
Branch: feature/spec-based-2
Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log
Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run "'`pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
If Blocked: Capture notes in polynomial_validation.md explaining the blocker; rerun the collect-only command and log failure output in collect.log

Priorities & Rationale:
- plans/active/vectorization.md:48 — Phase D table makes polynomial vectorization the active gate
- docs/fix_plan.md:2194 — Next Actions require Phase D1 artefact before code changes
- docs/development/testing_strategy.md:74 — Collect-only proof mandated ahead of targeted pytest runs
- reports/2025-10-vectorization/phase_b/design_notes.md — Holds prior broadcast math that Phase D must extend
- docs/development/pytorch_runtime_checklist.md:1 — Vectorization/device guardrails to cite in the worksheet

How-To Map:
- export KMP_DUPLICATE_LIB_OK=TRUE
- mkdir -p reports/2025-10-vectorization/phase_d
- pytest --collect-only -q tests/test_tricubic_vectorized.py | tee reports/2025-10-vectorization/phase_d/collect.log
- Summarise tensor shapes, broadcast diagrams, tap points, and C references in reports/2025-10-vectorization/phase_d/polynomial_validation.md

Pitfalls To Avoid:
- Do not skip CLAUDE Rule #11 C-quote requirements for upcoming helper edits
- No code edits this loop; stay in documentation/design scope
- Keep device/dtype neutrality front of mind (note CPU+CUDA requirements in the plan)
- Don’t promise runtime gains without scheduling Phase E benchmarks
- Avoid inventing new command syntax; reuse scripts/benchmarks harnesses already referenced
- Ensure collect-only output is captured; supervisors need proof before implementations
- Keep references scoped to Protected Assets list (no file deletions)
- Note that torch.compile graph breaks must be documented if uncovered later

Pointers:
- plans/active/vectorization.md:48 — Phase D requirements
- docs/fix_plan.md:2194 — Active fix-plan entry for VECTOR-TRICUBIC-001
- docs/development/testing_strategy.md:70 — Supervisor loop testing cadence
- reports/2025-10-vectorization/phase_c/implementation_notes.md — Prior phase context for gather output shapes

Next Up: Phase D2 — implement batched polint/polin2/polin3 once D1 artefacts are signed off
'"'''
Path('input.md').write_text(text)
PY" succeeded in 734ms:

[2025-10-07T22:15:02] tokens used: 176,931

[2025-10-07T22:15:06] thinking

**Checking input length requirements**
[2025-10-07T22:15:07] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:15:08] bash -lc 'wc -l input.md' succeeded in 722ms:
      39 input.md
[2025-10-07T22:15:08] tokens used: 178,749

[2025-10-07T22:15:12] thinking

**Planning detailed document expansion**

I’m aiming to rewrite the input.md to about 110 lines, adding richer detail and more bullet points across sections like Priorities, How-To Map, and Pitfalls. I’ll also consider adding new sections like Background and Deliverable Checklist to create a fuller, clearer guide.
[2025-10-07T22:15:27] exec bash -lc "python - <<'PY'
from pathlib import Path
text = '''Summary: Capture detailed Phase D1 blueprint so polynomial vectorization can proceed without surprises
Mode: Docs
Focus: VECTOR-TRICUBIC-001 / Phase D1
Branch: feature/spec-based-2
Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log; reports/2025-10-vectorization/phase_d/tap_points.md (if tap inventory grows)
Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run "'`pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
If Blocked: Capture blockers + hypotheses in polynomial_validation.md, rerun the collect-only command to confirm selectors still resolve, and park raw stderr/stdout in collect.log for supervisor triage

Background Notes:
- Current gather path (Phase C) produces (B,4,4,4) neighbourhood tensors but still falls back to scalar polynomial helpers when B>1
- Vectorizing polynomials unblocks the long-term goal of running the supervisor command with PyTorch CLI parity
- Detector absorption work (Phase F) depends on the lessons from Phase D — thorough documentation now prevents duplicated effort later

Priorities & Rationale:
- plans/active/vectorization.md:48 — Phase D is labelled the active gate; D1 documentation is prerequisite for every subsequent task
- plans/active/vectorization.md:49 — Highlights need to avoid nearest-neighbour fallback by batching polynomials
- docs/fix_plan.md:2194 — Fix-plan entry reiterates D1–D4 ordering and mandates artefact linkage
- docs/development/testing_strategy.md:70 — Supervisor loops require collect-only proof before running targeted tests
- docs/development/pytorch_runtime_checklist.md:1 — Guardrails around vectorization + device neutrality must be called out in the new worksheet
- reports/2025-10-vectorization/phase_b/design_notes.md:12 — Contains the broadcast equations D1 must extend
- reports/2025-10-vectorization/phase_c/implementation_notes.md:14 — Documents gather output shapes and constraints that the polynomial layer must accept
- nanoBragg.c:4021 — Reference implementation for polin3 coefficients; D1 should quote this per CLAUDE Rule #11
- docs/architecture/pytorch_design.md:15 — Differentiability guidance to restate when planning gradcheck coverage
- docs/index.md — Protected asset list; ensure any new script references live under scripts/validation or scripts/benchmarks per policy

Deliverable Checklist:
- [ ] Outline scalar vs batched input/output shapes for polint/polin2/polin3 (include diagrams)
- [ ] Identify tap points for instrumentation (pre/post polynomial evaluation) and record them in tap_points.md if needed
- [ ] Cite exact C code ranges for each helper and mark intended docstring insertion points
- [ ] Define gradient validation strategy (float64 gradcheck + float32 smoke) and record target tolerances
- [ ] Plan device coverage (cpu and cuda) noting fallback if CUDA unavailable
- [ ] Note performance measurement hooks (reuse scripts/benchmarks/tricubic_baseline.py with new flags)
- [ ] Summarise expected failure modes (OOB neighbourhoods, NaN handling) and mitigation strategies
- [ ] Enumerate any configuration knobs (dtype overrides, torch.compile caching) that need doc updates later

How-To Map:
- export KMP_DUPLICATE_LIB_OK=TRUE before invoking pytest or scripts
- mkdir -p reports/2025-10-vectorization/phase_d to keep artefacts organised alongside earlier phases
- pytest --collect-only -q tests/test_tricubic_vectorized.py | tee reports/2025-10-vectorization/phase_d/collect.log (aggregate proof for supervisor log)
- After collect-only, open reports/2025-10-vectorization/phase_b/design_notes.md and copy relevant equations into the new worksheet with updated batching commentary
- In polynomial_validation.md, structure sections as: Context, C references, Tensor shapes, Broadcast diagrams, Gradient plan, Device plan, Tap points, Pending questions
- If tap points become numerous, create reports/2025-10-vectorization/phase_d/tap_points.md summarising desired traces for future debugging scripts
- Reference docs/development/testing_strategy.md:70 within the worksheet to show compliance with testing SOPs
- Close the worksheet with clear exit criteria mapping directly to plan tasks D2–D4 so future loops know when D1 is satisfied

Pitfalls To Avoid:
- Do not edit production code or tests during this documentation loop; leave implementation for D2+
- Avoid vague shape descriptions — specify exact tensor dimensions with named axes
- Do not forget CLAUDE Rule #11: the worksheet must note the exact C snippet to paste into docstrings before implementation
- Keep device/dtype neutrality explicit; note how tensors stay on caller device without `.to()` churn
- Do not schedule benchmarks yet; Phase E will own quantitative comparisons
- Guard against slipping into implementation details without documenting validation strategy first
- Remember Protected Assets: no deletions or renames of docs/index.md entries or scripts referenced there
- Do not expand the plan into multiple files; all design notes stay under reports/2025-10-vectorization/phase_d/
- Avoid promising timelines; focus on requirements and exit criteria
- Refrain from editing docs outside the scoped artefacts unless absolutely necessary; changes to specs/arch docs come in Phase G

Pointers:
- plans/active/vectorization.md:1 — Context + dependency list; cite relevant docs inside worksheet
- plans/active/vectorization.md:48 — Phase D table for task sequencing and required artefacts
- docs/fix_plan.md:2194 — Active fix-plan entry providing supervisor expectations and reproduction commands
- docs/development/testing_strategy.md:70 — Collect-only guidance for documentation loops
- docs/development/pytorch_runtime_checklist.md:1 — Runtime guardrails to quote in validation plan
- reports/2025-10-vectorization/phase_b/design_notes.md — Prior broadcast design to extend
- reports/2025-10-vectorization/phase_c/gradient_smoke.log — Shows existing regression harness to reuse after D4

Next Up: Phase D2 — implement batched polint/polin2/polin3 once the worksheet (D1) is reviewed and accepted; ensure docstrings include the quoted C code before coding
'"'''
Path('input.md').write_text(text)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:15:28] bash -lc "python - <<'PY'
from pathlib import Path
text = '''Summary: Capture detailed Phase D1 blueprint so polynomial vectorization can proceed without surprises
Mode: Docs
Focus: VECTOR-TRICUBIC-001 / Phase D1
Branch: feature/spec-based-2
Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log; reports/2025-10-vectorization/phase_d/tap_points.md (if tap inventory grows)
Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run "'`pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
If Blocked: Capture blockers + hypotheses in polynomial_validation.md, rerun the collect-only command to confirm selectors still resolve, and park raw stderr/stdout in collect.log for supervisor triage

Background Notes:
- Current gather path (Phase C) produces (B,4,4,4) neighbourhood tensors but still falls back to scalar polynomial helpers when B>1
- Vectorizing polynomials unblocks the long-term goal of running the supervisor command with PyTorch CLI parity
- Detector absorption work (Phase F) depends on the lessons from Phase D — thorough documentation now prevents duplicated effort later

Priorities & Rationale:
- plans/active/vectorization.md:48 — Phase D is labelled the active gate; D1 documentation is prerequisite for every subsequent task
- plans/active/vectorization.md:49 — Highlights need to avoid nearest-neighbour fallback by batching polynomials
- docs/fix_plan.md:2194 — Fix-plan entry reiterates D1–D4 ordering and mandates artefact linkage
- docs/development/testing_strategy.md:70 — Supervisor loops require collect-only proof before running targeted tests
- docs/development/pytorch_runtime_checklist.md:1 — Guardrails around vectorization + device neutrality must be called out in the new worksheet
- reports/2025-10-vectorization/phase_b/design_notes.md:12 — Contains the broadcast equations D1 must extend
- reports/2025-10-vectorization/phase_c/implementation_notes.md:14 — Documents gather output shapes and constraints that the polynomial layer must accept
- nanoBragg.c:4021 — Reference implementation for polin3 coefficients; D1 should quote this per CLAUDE Rule #11
- docs/architecture/pytorch_design.md:15 — Differentiability guidance to restate when planning gradcheck coverage
- docs/index.md — Protected asset list; ensure any new script references live under scripts/validation or scripts/benchmarks per policy

Deliverable Checklist:
- [ ] Outline scalar vs batched input/output shapes for polint/polin2/polin3 (include diagrams)
- [ ] Identify tap points for instrumentation (pre/post polynomial evaluation) and record them in tap_points.md if needed
- [ ] Cite exact C code ranges for each helper and mark intended docstring insertion points
- [ ] Define gradient validation strategy (float64 gradcheck + float32 smoke) and record target tolerances
- [ ] Plan device coverage (cpu and cuda) noting fallback if CUDA unavailable
- [ ] Note performance measurement hooks (reuse scripts/benchmarks/tricubic_baseline.py with new flags)
- [ ] Summarise expected failure modes (OOB neighbourhoods, NaN handling) and mitigation strategies
- [ ] Enumerate any configuration knobs (dtype overrides, torch.compile caching) that need doc updates later

How-To Map:
- export KMP_DUPLICATE_LIB_OK=TRUE before invoking pytest or scripts
- mkdir -p reports/2025-10-vectorization/phase_d to keep artefacts organised alongside earlier phases
- pytest --collect-only -q tests/test_tricubic_vectorized.py | tee reports/2025-10-vectorization/phase_d/collect.log (aggregate proof for supervisor log)
- After collect-only, open reports/2025-10-vectorization/phase_b/design_notes.md and copy relevant equations into the new worksheet with updated batching commentary
- In polynomial_validation.md, structure sections as: Context, C references, Tensor shapes, Broadcast diagrams, Gradient plan, Device plan, Tap points, Pending questions
- If tap points become numerous, create reports/2025-10-vectorization/phase_d/tap_points.md summarising desired traces for future debugging scripts
- Reference docs/development/testing_strategy.md:70 within the worksheet to show compliance with testing SOPs
- Close the worksheet with clear exit criteria mapping directly to plan tasks D2–D4 so future loops know when D1 is satisfied

Pitfalls To Avoid:
- Do not edit production code or tests during this documentation loop; leave implementation for D2+
- Avoid vague shape descriptions — specify exact tensor dimensions with named axes
- Do not forget CLAUDE Rule #11: the worksheet must note the exact C snippet to paste into docstrings before implementation
- Keep device/dtype neutrality explicit; note how tensors stay on caller device without `.to()` churn
- Do not schedule benchmarks yet; Phase E will own quantitative comparisons
- Guard against slipping into implementation details without documenting validation strategy first
- Remember Protected Assets: no deletions or renames of docs/index.md entries or scripts referenced there
- Do not expand the plan into multiple files; all design notes stay under reports/2025-10-vectorization/phase_d/
- Avoid promising timelines; focus on requirements and exit criteria
- Refrain from editing docs outside the scoped artefacts unless absolutely necessary; changes to specs/arch docs come in Phase G

Pointers:
- plans/active/vectorization.md:1 — Context + dependency list; cite relevant docs inside worksheet
- plans/active/vectorization.md:48 — Phase D table for task sequencing and required artefacts
- docs/fix_plan.md:2194 — Active fix-plan entry providing supervisor expectations and reproduction commands
- docs/development/testing_strategy.md:70 — Collect-only guidance for documentation loops
- docs/development/pytorch_runtime_checklist.md:1 — Runtime guardrails to quote in validation plan
- reports/2025-10-vectorization/phase_b/design_notes.md — Prior broadcast design to extend
- reports/2025-10-vectorization/phase_c/gradient_smoke.log — Shows existing regression harness to reuse after D4

Next Up: Phase D2 — implement batched polint/polin2/polin3 once the worksheet (D1) is reviewed and accepted; ensure docstrings include the quoted C code before coding
'"'''
Path('input.md').write_text(text)
PY" succeeded in 966ms:

[2025-10-07T22:15:28] tokens used: 180,618

[2025-10-07T22:15:30] thinking

**Counting lines in the file**
[2025-10-07T22:15:31] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:15:31] bash -lc 'wc -l input.md' succeeded in 677ms:
      68 input.md
[2025-10-07T22:15:31] tokens used: 187,690

[2025-10-07T22:15:37] thinking

**Planning document expansion**
[2025-10-07T22:15:59] exec bash -lc "python - <<'PY'
from pathlib import Path
text = '''Summary: Capture detailed Phase D1 blueprint so polynomial vectorization can proceed without surprises
Mode: Docs
Focus: VECTOR-TRICUBIC-001 / Phase D1
Branch: feature/spec-based-2
Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log; reports/2025-10-vectorization/phase_d/tap_points.md (if tap inventory grows)
Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run "'`pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
If Blocked: Capture blockers + hypotheses in polynomial_validation.md, rerun the collect-only command to confirm selectors still resolve, and park raw stderr/stdout in collect.log for supervisor triage

Background Notes:
- Current gather path (Phase C) produces (B,4,4,4) neighbourhood tensors but still falls back to scalar polynomial helpers when B>1
- Vectorizing polynomials unblocks the long-term goal of running the supervisor command with PyTorch CLI parity without fallbacks
- Detector absorption work (Phase F) depends on the lessons from Phase D — thorough documentation now prevents duplicated effort later
- Prior perf studies (reports/benchmarks/20250930-165726-compile-cache/analysis.md) highlight polin3 as a hotspot once batching activates; note this in the worksheet

Context Reminders:
- Supervisor initiative currently prioritises CLI parity and vectorization; keep D1 scoped to enabling code work without actually modifying code
- Protected Assets rule applies; any new helper scripts must live beneath scripts/ and be referenced in docs/index.md if persistent
- The PyTorch runtime checklist mandates CPU + CUDA smoke for any new tensor path; plan for both devices even if CUDA unavailable locally
- Document how D1 interacts with future parity gating (nb-compare/Phase E) so we have a straight hand-off once implementation lands

Priorities & Rationale:
- plans/active/vectorization.md:1 — Context + dependency list; cite relevant docs inside worksheet to show full awareness
- plans/active/vectorization.md:48 — Phase D is labelled the active gate; D1 documentation is prerequisite for every subsequent task
- plans/active/vectorization.md:49 — Highlights need to avoid nearest-neighbour fallback by batching polynomials; reiterate the broadcast math
- plans/active/vectorization.md:54 — Table lists D4 test sweep requirements; note them in exit criteria
- docs/fix_plan.md:2194 — Fix-plan entry reiterates D1–D4 ordering and mandates artefact linkage
- docs/development/testing_strategy.md:70 — Supervisor loops require collect-only proof before running targeted tests; capture log once
- docs/development/pytorch_runtime_checklist.md:1 — Guardrails around vectorization + device neutrality must be called out in the new worksheet
- reports/2025-10-vectorization/phase_b/design_notes.md:12 — Contains the broadcast equations D1 must extend
- reports/2025-10-vectorization/phase_c/implementation_notes.md:14 — Documents gather output shapes and constraints that the polynomial layer must accept
- reports/2025-10-vectorization/phase_c/gradient_smoke.log — Shows existing regression harness to reuse post-implementation
- nanoBragg.c:4021 — Reference implementation for polin3 coefficients; D1 should quote this per CLAUDE Rule #11
- docs/architecture/pytorch_design.md:15 — Differentiability guidance to restate when planning gradcheck coverage
- docs/index.md — Protected asset list; ensure any new script references live under scripts/validation or scripts/benchmarks per policy

Diagnostic Questions To Answer:
- What tensor shapes enter each polynomial helper when batching B>1, and how do they reshape back to detector grids?
- How will out-of-range neighbourhoods propagate through batched polynomials, and what masking strategy will prevent NaNs?
- Which gradients must be preserved (w.r.t. Fhkl? lattice offsets?) and what gradcheck tolerances will we require in float64?
- Do we anticipate torch.compile graph breaks when swapping in batched helpers, and how will we detect/report them?
- What tap points are necessary to debug batched polynomial values if parity drifts (e.g., before/after each interpolation axis)?

Deliverable Checklist:
- [ ] Outline scalar vs batched input/output shapes for polint/polin2/polin3, including named axes and reshape rules
- [ ] Provide at least one worked example showing indices mapping from detector grid → flattened B → restored grid
- [ ] Identify tap points for instrumentation (pre/post polynomial evaluation, mask applications) and record them in tap_points.md if needed
- [ ] Cite exact C code ranges for each helper and mark intended docstring insertion points per CLAUDE Rule #11
- [ ] Define gradient validation strategy (float64 gradcheck + float32 smoke) and record target tolerances + command selectors
- [ ] Plan device coverage (cpu and cuda) noting fallback if CUDA unavailable; mention requirement to record `torch.cuda.is_available()` status
- [ ] Note performance measurement hooks (reuse scripts/benchmarks/tricubic_baseline.py with new flags) and expected metrics to compare
- [ ] Summarise expected failure modes (OOB neighbourhoods, NaN handling, dtype promotion) and mitigation strategies
- [ ] Enumerate configuration knobs (dtype overrides, torch.compile caching, environment flags) that need doc updates later
- [ ] Capture open questions for supervisor sign-off before D2 (e.g., handling complex HKL interpolation or caching of coefficients)

Quality Gates To Record:
- Explicit exit criteria for D1 completion (worksheet reviewed, tap list agreed, collect-only log captured)
- Blocking conditions that would prevent D2 start (missing C references, incomplete gradient plan, device ambiguity)
- Artefact directory hygiene expectations (only phase_d/ contains new files for this loop)
- Confirmation that future D2 commits must bundle docstring updates alongside code edits

How-To Map:
- export KMP_DUPLICATE_LIB_OK=TRUE before invoking pytest or scripts (avoid MKL duplicate-lib crash)
- mkdir -p reports/2025-10-vectorization/phase_d to keep artefacts organised alongside earlier phases
- pytest --collect-only -q tests/test_tricubic_vectorized.py | tee reports/2025-10-vectorization/phase_d/collect.log (aggregate proof for supervisor log)
- After collect-only, open reports/2025-10-vectorization/phase_b/design_notes.md and copy relevant equations into the new worksheet with updated batching commentary
- Structure polynomial_validation.md sections as: Context, C references, Tensor shapes, Broadcast diagrams, Masking & OOB plan, Gradient plan, Device plan, Tap points, Performance hooks, Open questions, Exit criteria
- If tap points become numerous, create reports/2025-10-vectorization/phase_d/tap_points.md summarising desired traces for future debugging scripts
- Reference docs/development/testing_strategy.md:70 within the worksheet to show compliance with testing SOPs
- Close the worksheet with clear exit criteria mapping directly to plan tasks D2–D4 so future loops know when D1 is satisfied
- Mention in the worksheet that Phase E will rerun benchmarks under scripts/benchmarks/tricubic_baseline.py and compare before/after metrics
- Annotate any assumptions about HKL tensor layout (contiguous/Fortran order) so implementation can validate them later

Pitfalls To Avoid:
- Do not edit production code or tests during this documentation loop; leave implementation for D2+
- Avoid vague shape descriptions — specify exact tensor dimensions with named axes and flattening order
- Do not forget CLAUDE Rule #11: the worksheet must note the exact C snippet to paste into docstrings before implementation
- Keep device/dtype neutrality explicit; note how tensors stay on caller device without `.to()` churn
- Do not schedule benchmarks yet; Phase E will own quantitative comparisons
- Guard against slipping into implementation details without documenting validation strategy first
- Remember Protected Assets: no deletions or renames of docs/index.md entries or scripts referenced there
- Do not expand the plan into multiple files; all design notes stay under reports/2025-10-vectorization/phase_d/
- Avoid promising timelines; focus on requirements and exit criteria only
- Refrain from editing docs outside the scoped artefacts unless absolutely necessary; changes to specs/arch docs come in Phase G
- Do not assume CUDA availability; explicitly document fallback steps if only CPU is reachable
- Avoid mixing float32/float64 inadvertently in examples—call out dtype expectations clearly

Pointers:
- plans/active/vectorization.md:1 — Context + dependency list; cite relevant docs inside worksheet
- plans/active/vectorization.md:48 — Phase D table for task sequencing and required artefacts
- docs/fix_plan.md:2194 — Active fix-plan entry providing supervisor expectations and reproduction commands
- docs/development/testing_strategy.md:70 — Collect-only guidance for documentation loops
- docs/development/pytorch_runtime_checklist.md:1 — Runtime guardrails to quote in validation plan
- reports/2025-10-vectorization/phase_b/design_notes.md — Prior broadcast design to extend
- reports/2025-10-vectorization/phase_c/gradient_smoke.log — Evidence of current regression harness to reuse
- reports/2025-10-vectorization/phase_c/implementation_notes.md — Gather implementation summary for reference
- docs/architecture/pytorch_design.md:1 — Differentiability + performance trade-offs to restate

Coordination Notes:
- Flag any discovered doc drift (spec vs arch) within polynomial_validation.md so Phase G can schedule updates
- If new scripts are required later, list them as TODOs rather than creating them now; supervisor will author follow-up plan entries
- Record any open questions for performance initiative owners (PERF-PYTORCH-004) regarding benchmark thresholds

Next Up: Phase D2 — implement batched polint/polin2/polin3 once the worksheet (D1) is reviewed and accepted; ensure docstrings include the quoted C code before coding
'"'''
Path('input.md').write_text(text)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:15:59] bash -lc "python - <<'PY'
from pathlib import Path
text = '''Summary: Capture detailed Phase D1 blueprint so polynomial vectorization can proceed without surprises
Mode: Docs
Focus: VECTOR-TRICUBIC-001 / Phase D1
Branch: feature/spec-based-2
Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log; reports/2025-10-vectorization/phase_d/tap_points.md (if tap inventory grows)
Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run "'`pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
If Blocked: Capture blockers + hypotheses in polynomial_validation.md, rerun the collect-only command to confirm selectors still resolve, and park raw stderr/stdout in collect.log for supervisor triage

Background Notes:
- Current gather path (Phase C) produces (B,4,4,4) neighbourhood tensors but still falls back to scalar polynomial helpers when B>1
- Vectorizing polynomials unblocks the long-term goal of running the supervisor command with PyTorch CLI parity without fallbacks
- Detector absorption work (Phase F) depends on the lessons from Phase D — thorough documentation now prevents duplicated effort later
- Prior perf studies (reports/benchmarks/20250930-165726-compile-cache/analysis.md) highlight polin3 as a hotspot once batching activates; note this in the worksheet

Context Reminders:
- Supervisor initiative currently prioritises CLI parity and vectorization; keep D1 scoped to enabling code work without actually modifying code
- Protected Assets rule applies; any new helper scripts must live beneath scripts/ and be referenced in docs/index.md if persistent
- The PyTorch runtime checklist mandates CPU + CUDA smoke for any new tensor path; plan for both devices even if CUDA unavailable locally
- Document how D1 interacts with future parity gating (nb-compare/Phase E) so we have a straight hand-off once implementation lands

Priorities & Rationale:
- plans/active/vectorization.md:1 — Context + dependency list; cite relevant docs inside worksheet to show full awareness
- plans/active/vectorization.md:48 — Phase D is labelled the active gate; D1 documentation is prerequisite for every subsequent task
- plans/active/vectorization.md:49 — Highlights need to avoid nearest-neighbour fallback by batching polynomials; reiterate the broadcast math
- plans/active/vectorization.md:54 — Table lists D4 test sweep requirements; note them in exit criteria
- docs/fix_plan.md:2194 — Fix-plan entry reiterates D1–D4 ordering and mandates artefact linkage
- docs/development/testing_strategy.md:70 — Supervisor loops require collect-only proof before running targeted tests; capture log once
- docs/development/pytorch_runtime_checklist.md:1 — Guardrails around vectorization + device neutrality must be called out in the new worksheet
- reports/2025-10-vectorization/phase_b/design_notes.md:12 — Contains the broadcast equations D1 must extend
- reports/2025-10-vectorization/phase_c/implementation_notes.md:14 — Documents gather output shapes and constraints that the polynomial layer must accept
- reports/2025-10-vectorization/phase_c/gradient_smoke.log — Shows existing regression harness to reuse post-implementation
- nanoBragg.c:4021 — Reference implementation for polin3 coefficients; D1 should quote this per CLAUDE Rule #11
- docs/architecture/pytorch_design.md:15 — Differentiability guidance to restate when planning gradcheck coverage
- docs/index.md — Protected asset list; ensure any new script references live under scripts/validation or scripts/benchmarks per policy

Diagnostic Questions To Answer:
- What tensor shapes enter each polynomial helper when batching B>1, and how do they reshape back to detector grids?
- How will out-of-range neighbourhoods propagate through batched polynomials, and what masking strategy will prevent NaNs?
- Which gradients must be preserved (w.r.t. Fhkl? lattice offsets?) and what gradcheck tolerances will we require in float64?
- Do we anticipate torch.compile graph breaks when swapping in batched helpers, and how will we detect/report them?
- What tap points are necessary to debug batched polynomial values if parity drifts (e.g., before/after each interpolation axis)?

Deliverable Checklist:
- [ ] Outline scalar vs batched input/output shapes for polint/polin2/polin3, including named axes and reshape rules
- [ ] Provide at least one worked example showing indices mapping from detector grid → flattened B → restored grid
- [ ] Identify tap points for instrumentation (pre/post polynomial evaluation, mask applications) and record them in tap_points.md if needed
- [ ] Cite exact C code ranges for each helper and mark intended docstring insertion points per CLAUDE Rule #11
- [ ] Define gradient validation strategy (float64 gradcheck + float32 smoke) and record target tolerances + command selectors
- [ ] Plan device coverage (cpu and cuda) noting fallback if CUDA unavailable; mention requirement to record `torch.cuda.is_available()` status
- [ ] Note performance measurement hooks (reuse scripts/benchmarks/tricubic_baseline.py with new flags) and expected metrics to compare
- [ ] Summarise expected failure modes (OOB neighbourhoods, NaN handling, dtype promotion) and mitigation strategies
- [ ] Enumerate configuration knobs (dtype overrides, torch.compile caching, environment flags) that need doc updates later
- [ ] Capture open questions for supervisor sign-off before D2 (e.g., handling complex HKL interpolation or caching of coefficients)

Quality Gates To Record:
- Explicit exit criteria for D1 completion (worksheet reviewed, tap list agreed, collect-only log captured)
- Blocking conditions that would prevent D2 start (missing C references, incomplete gradient plan, device ambiguity)
- Artefact directory hygiene expectations (only phase_d/ contains new files for this loop)
- Confirmation that future D2 commits must bundle docstring updates alongside code edits

How-To Map:
- export KMP_DUPLICATE_LIB_OK=TRUE before invoking pytest or scripts (avoid MKL duplicate-lib crash)
- mkdir -p reports/2025-10-vectorization/phase_d to keep artefacts organised alongside earlier phases
- pytest --collect-only -q tests/test_tricubic_vectorized.py | tee reports/2025-10-vectorization/phase_d/collect.log (aggregate proof for supervisor log)
- After collect-only, open reports/2025-10-vectorization/phase_b/design_notes.md and copy relevant equations into the new worksheet with updated batching commentary
- Structure polynomial_validation.md sections as: Context, C references, Tensor shapes, Broadcast diagrams, Masking & OOB plan, Gradient plan, Device plan, Tap points, Performance hooks, Open questions, Exit criteria
- If tap points become numerous, create reports/2025-10-vectorization/phase_d/tap_points.md summarising desired traces for future debugging scripts
- Reference docs/development/testing_strategy.md:70 within the worksheet to show compliance with testing SOPs
- Close the worksheet with clear exit criteria mapping directly to plan tasks D2–D4 so future loops know when D1 is satisfied
- Mention in the worksheet that Phase E will rerun benchmarks under scripts/benchmarks/tricubic_baseline.py and compare before/after metrics
- Annotate any assumptions about HKL tensor layout (contiguous/Fortran order) so implementation can validate them later

Pitfalls To Avoid:
- Do not edit production code or tests during this documentation loop; leave implementation for D2+
- Avoid vague shape descriptions — specify exact tensor dimensions with named axes and flattening order
- Do not forget CLAUDE Rule #11: the worksheet must note the exact C snippet to paste into docstrings before implementation
- Keep device/dtype neutrality explicit; note how tensors stay on caller device without `.to()` churn
- Do not schedule benchmarks yet; Phase E will own quantitative comparisons
- Guard against slipping into implementation details without documenting validation strategy first
- Remember Protected Assets: no deletions or renames of docs/index.md entries or scripts referenced there
- Do not expand the plan into multiple files; all design notes stay under reports/2025-10-vectorization/phase_d/
- Avoid promising timelines; focus on requirements and exit criteria only
- Refrain from editing docs outside the scoped artefacts unless absolutely necessary; changes to specs/arch docs come in Phase G
- Do not assume CUDA availability; explicitly document fallback steps if only CPU is reachable
- Avoid mixing float32/float64 inadvertently in examples—call out dtype expectations clearly

Pointers:
- plans/active/vectorization.md:1 — Context + dependency list; cite relevant docs inside worksheet
- plans/active/vectorization.md:48 — Phase D table for task sequencing and required artefacts
- docs/fix_plan.md:2194 — Active fix-plan entry providing supervisor expectations and reproduction commands
- docs/development/testing_strategy.md:70 — Collect-only guidance for documentation loops
- docs/development/pytorch_runtime_checklist.md:1 — Runtime guardrails to quote in validation plan
- reports/2025-10-vectorization/phase_b/design_notes.md — Prior broadcast design to extend
- reports/2025-10-vectorization/phase_c/gradient_smoke.log — Evidence of current regression harness to reuse
- reports/2025-10-vectorization/phase_c/implementation_notes.md — Gather implementation summary for reference
- docs/architecture/pytorch_design.md:1 — Differentiability + performance trade-offs to restate

Coordination Notes:
- Flag any discovered doc drift (spec vs arch) within polynomial_validation.md so Phase G can schedule updates
- If new scripts are required later, list them as TODOs rather than creating them now; supervisor will author follow-up plan entries
- Record any open questions for performance initiative owners (PERF-PYTORCH-004) regarding benchmark thresholds

Next Up: Phase D2 — implement batched polint/polin2/polin3 once the worksheet (D1) is reviewed and accepted; ensure docstrings include the quoted C code before coding
'"'''
Path('input.md').write_text(text)
PY" succeeded in 800ms:

[2025-10-07T22:15:59] tokens used: 191,891

[2025-10-07T22:16:01] thinking

**Counting lines in the file**
[2025-10-07T22:16:02] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:02] bash -lc 'wc -l input.md' succeeded in 691ms:
     104 input.md
[2025-10-07T22:16:02] tokens used: 195,141

[2025-10-07T22:16:05] thinking

**Preparing to commit changes**
[2025-10-07T22:16:06] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:07] bash -lc 'git status --short' succeeded in 767ms:
 M docs/fix_plan.md
 M input.md
 M plans/active/vectorization.md
[2025-10-07T22:16:07] tokens used: 195,274

[2025-10-07T22:16:13] thinking

**Updating galph_memory with summary**
[2025-10-07T22:16:17] exec bash -lc "python - <<'PY'
from datetime import datetime
from pathlib import Path
path = Path('galph_memory.md')
stamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')
entry = f\"\\n## {stamp} (galph loop — VECTOR-TRICUBIC-001 planning refresh)\\n- Rewrote "'`plans/active/vectorization.md` with phased structure (A–G) and explicit Phase D/F checklists; added D1–D4/D5 guidance and future absorption tasks.'"\\n- Updated "'`docs/fix_plan.md:2194-2210` Next Actions to align with the refreshed plan (Phase D1–D4 plus Phase E staging).'"\\n- Issued new "'`input.md` (Docs mode) directing Ralph to complete Phase D1 documentation, capture collect-only proof, and log tensor-shape/C-reference requirements.'"\\n- Follow-up: Ralph to author "'`reports/2025-10-vectorization/phase_d/polynomial_validation.md`, run collect-only selector, and prepare tap_points.md if needed before coding D2.'"\\n\"
text = path.read_text().rstrip() + \"\\n\" + entry + \"\\n\"
path.write_text(text)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:18] bash -lc "python - <<'PY'
from datetime import datetime
from pathlib import Path
path = Path('galph_memory.md')
stamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')
entry = f\"\\n## {stamp} (galph loop — VECTOR-TRICUBIC-001 planning refresh)\\n- Rewrote "'`plans/active/vectorization.md` with phased structure (A–G) and explicit Phase D/F checklists; added D1–D4/D5 guidance and future absorption tasks.'"\\n- Updated "'`docs/fix_plan.md:2194-2210` Next Actions to align with the refreshed plan (Phase D1–D4 plus Phase E staging).'"\\n- Issued new "'`input.md` (Docs mode) directing Ralph to complete Phase D1 documentation, capture collect-only proof, and log tensor-shape/C-reference requirements.'"\\n- Follow-up: Ralph to author "'`reports/2025-10-vectorization/phase_d/polynomial_validation.md`, run collect-only selector, and prepare tap_points.md if needed before coding D2.'"\\n\"
text = path.read_text().rstrip() + \"\\n\" + entry + \"\\n\"
path.write_text(text)
PY" succeeded in 792ms:
<stdin>:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
[2025-10-07T22:16:18] tokens used: 195,755

[2025-10-07T22:16:20] thinking

**Reviewing galph_memory.md end**
[2025-10-07T22:16:20] exec bash -lc 'tail -n 20 galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:21] bash -lc 'tail -n 20 galph_memory.md' succeeded in 711ms:
- Issued new 110-line `input.md` (Docs mode) directing Ralph to regenerate per-φ traces with ≤1e-6 tolerances, document spec-vs-parity strategy, and log evidence (TRACE_TAG workflow, memo, tests).
- No code changes made; focus was planning/docs alignment ahead of the next engineering loop.

## 2025-11-27 (galph loop — φ=0 spec audit)
- Confirmed spec mandate (`specs/spec-a-core.md:211`) requires fresh φ rotations each step; C-PARITY-001 documents nanoBragg.c’s stale-vector carryover (`docs/bugs/verified_c_bugs.md:166`).
- PyTorch currently mirrors the bug via `_phi_last_cache` in `src/nanobrag_torch/models/crystal.py:1115-1198`; this contradicts the spec and the long-term goal to eliminate the carryover.
- CLI plan still instructs emulating the bug (L3k.3c.3). Issued new input.md directing Ralph to refresh `diagnosis.md` (L3k.3c.4) with spec-vs-parity guidance, log an Attempt, and run collect-only pytest. Expect next loop to revise the plan and design a spec-compliant default plus optional parity shim.

## 2025-10-07 (galph loop — φ=0 spec alignment)
- Reconfirmed spec mandate (`specs/spec-a-core.md:211-214`) that every φ step re-rotates the lattice and that C’s carryover bug is quarantined in `docs/bugs/verified_c_bugs.md:166-204`.
- Noted PyTorch still mirrors the bug via `_phi_last_cache` (`src/nanobrag_torch/models/crystal.py:1097-1198`); updated `docs/fix_plan.md` Next Actions and `plans/active/cli-noise-pix0/plan.md` context to call this out and require a parity shim decision.
- Issued new `input.md` (Docs mode) directing Ralph to refresh `reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md`, log the attempt, cross-link the plan, and run the collect-only selector with `KMP_DUPLICATE_LIB_OK=TRUE`.
- No tests run; repo clean after commit `10333c0`.

## 2025-10-07 22:16 UTC (galph loop — VECTOR-TRICUBIC-001 planning refresh)
- Rewrote `plans/active/vectorization.md` with phased structure (A–G) and explicit Phase D/F checklists; added D1–D4/D5 guidance and future absorption tasks.
- Updated `docs/fix_plan.md:2194-2210` Next Actions to align with the refreshed plan (Phase D1–D4 plus Phase E staging).
- Issued new `input.md` (Docs mode) directing Ralph to complete Phase D1 documentation, capture collect-only proof, and log tensor-shape/C-reference requirements.
- Follow-up: Ralph to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md`, run collect-only selector, and prepare tap_points.md if needed before coding D2.

[2025-10-07T22:16:21] tokens used: 196,251

[2025-10-07T22:16:25] thinking

**Verifying date consistency and diffs**
[2025-10-07T22:16:25] exec bash -lc 'git diff plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:26] bash -lc 'git diff plans/active/vectorization.md' succeeded in 710ms:
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 3bfbb6c..ba3fdc3 100644
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,90 +1,91 @@
 ## Context
-- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
-- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
-- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
-- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
+- Initiative: PERF-PYTORCH-004 vectorization backlog supporting docs/fix_plan.md entry [VECTOR-TRICUBIC-001].
+- Phase Goal: Deliver a production-ready batched tricubic interpolation pipeline (gather + polynomial evaluation) and subsequently vectorize detector absorption without regressing parity, gradients, or device/dtype neutrality.
+- Dependencies:
+  - specs/spec-a-core.md §4 (structure-factor sampling contract)
+  - specs/spec-a-parallel.md §2.3 (tricubic acceptance tests + tolerances)
+  - docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy, broadcast shapes)
+  - docs/development/testing_strategy.md §§1.4–2 (test cadence, authoritative commands)
+  - docs/development/pytorch_runtime_checklist.md (device/vectorization guardrails)
+  - `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint) & 3375–3450 (detector absorption loop)
[2025-10-07T22:16:26] tokens used: 197,279

[2025-10-07T22:16:29] thinking

**Reviewing documentation changes**
[2025-10-07T22:16:29] exec bash -lc 'git diff docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:30] bash -lc 'git diff docs/fix_plan.md' succeeded in 756ms:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 0e405c6..9819370 100644
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2202,10 +2202,12 @@
   * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-23 refresh):
- 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
- 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
- 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
+- Next Actions (2025-11-27 refresh → galph supervision):
+  1. Phase D1 — Follow `plans/active/vectorization.md` (Phase D table) to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md` with tensor-shape derivations and C references before code edits. Include tap-point plan and cite design_notes §3.
+  2. Phase D2 — Implement vectorised `polint`/`polin2`/`polin3` per plan guidance, adding CLAUDE Rule #11 docstrings and ensuring differentiability/device neutrality.
+  3. Phase D3 — Extend `tests/test_tricubic_vectorized.py` with `TestTricubicPoly` and capture collect-only evidence under `phase_d/collect.log` prior to targeted pytest runs.
+  4. Phase D4 — Execute CPU + CUDA sweeps (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) storing logs under `phase_d/pytest_cpu.log` & `phase_d/pytest_cuda.log`; summarise timings in `polynomial_validation.md`.
+  5. Phase E staging — After D1–D4 pass, prep `reports/2025-10-vectorization/phase_e/` (collect log, benchmark command templates) before launching E1–E3 validation tasks.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
[2025-10-07T22:16:30] tokens used: 199,617

[2025-10-07T22:16:33] thinking

**Checking git diff of input.md**
[2025-10-07T22:16:33] exec bash -lc 'git diff input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:34] bash -lc 'git diff input.md' succeeded in 701ms:
diff --git a/input.md b/input.md
index b1e2fd6..803d5fd 100644
--- a/input.md
+++ b/input.md
@@ -1,39 +1,104 @@
-Summary: Refresh the φ=0 rotation memo with explicit spec citations and outline how we default to spec-compliant behavior while preserving a parity shim.
+Summary: Capture detailed Phase D1 blueprint so polynomial vectorization can proceed without surprises
 Mode: Docs
-Focus: CLI-FLAGS-003 — Handle -nonoise and -pix0_vector_mm
+Focus: VECTOR-TRICUBIC-001 / Phase D1
 Branch: feature/spec-based-2
-Mapped tests: KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q tests/test_cli_scaling_phi0.py
-Artifacts: reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md (rewrite), plans/active/cli-noise-pix0/plan.md (cross-link), docs/fix_plan.md (Attempt log), reports/2025-10-cli-flags/phase_l/rot_vector/collect_only.log
-Do Now: CLI-FLAGS-003 L3k.3c.4 — update reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md with the spec-vs-C analysis, note the parity shim plan in docs/fix_plan.md, then run `KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q tests/test_cli_scaling_phi0.py` and stash the log.
-If Blocked: Capture the obstacle in docs/fix_plan.md Attempt history, save working notes under reports/2025-10-cli-flags/phase_l/rot_vector/blockers.md, and still run the collect-only selector for traceability.
+Mapped tests: pytest --collect-only -q tests/test_tricubic_vectorized.py
+Artifacts: reports/2025-10-vectorization/phase_d/polynomial_validation.md; reports/2025-10-vectorization/phase_d/collect.log; reports/2025-10-vectorization/phase_d/tap_points.md (if tap inventory grows)
+Do Now: VECTOR-TRICUBIC-001 Phase D1 — draft reports/2025-10-vectorization/phase_d/polynomial_validation.md with tensor-shape + C-reference plan; run `pytest --collect-only -q tests/test_tricubic_vectorized.py` and tee stdout to reports/2025-10-vectorization/phase_d/collect.log
+If Blocked: Capture blockers + hypotheses in polynomial_validation.md, rerun the collect-only command to confirm selectors still resolve, and park raw stderr/stdout in collect.log for supervisor triage
+
[2025-10-07T22:16:34] tokens used: 207,144

[2025-10-07T22:16:39] thinking

**Preparing commit for changes**
[2025-10-07T22:16:40] exec bash -lc 'git add docs/fix_plan.md plans/active/vectorization.md input.md galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:41] bash -lc 'git add docs/fix_plan.md plans/active/vectorization.md input.md galph_memory.md' succeeded in 750ms:

[2025-10-07T22:16:41] tokens used: 209,837

[2025-10-07T22:16:43] thinking

**Preparing to commit changes**
[2025-10-07T22:16:44] exec bash -lc 'git commit -m "SUPERVISOR: vectorization plan refresh - tests: not run"' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:45] bash -lc 'git commit -m "SUPERVISOR: vectorization plan refresh - tests: not run"' succeeded in 719ms:
[feature/spec-based-2 f245738] SUPERVISOR: vectorization plan refresh - tests: not run
 4 files changed, 170 insertions(+), 95 deletions(-)
[2025-10-07T22:16:45] tokens used: 210,070

[2025-10-07T22:16:50] thinking

**Pushing changes**
[2025-10-07T22:16:50] exec bash -lc 'git push' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:53] bash -lc 'git push' succeeded in 2.58s:
To github.com:hoidn/nanoBragg.git
   fedb25f..f245738  feature/spec-based-2 -> feature/spec-based-2
[2025-10-07T22:16:53] tokens used: 282,484

[2025-10-07T22:16:56] thinking

**Checking for a clean working tree**
[2025-10-07T22:16:58] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T22:16:58] bash -lc 'git status --short' succeeded in 738ms:

[2025-10-07T22:16:58] tokens used: 283,331

[2025-10-07T22:17:05] thinking

**Composing final summary message**

I’m putting together a clear final message that outlines the work done, shares observations like Ralph’s recent productive commit, and suggests next steps for him. I’ll organize it with headers and bullet points, including precise file references to plans and docs for easy navigation.
[2025-10-07T22:17:06] codex

**Vectorization Plan**
- Rebuilt `plans/active/vectorization.md:1-113` with clear Phase A–G structure, explicit D1–D4/D4 checklists, and new detector-absorption tasks so Ralph has an executable roadmap.
- Synced `docs/fix_plan.md:2194-2210` Next Actions to match the refreshed plan (Phase D1–D4 plus Phase E staging) and documented the required artefacts.

**Engineer Steering**
- Issued `input.md` directing Ralph to deliver Phase D1 documentation, capture collect-only evidence, and enumerate tensor-shape/C-code references before any implementation work.

**Activity Review**
- Latest Ralph commits (e.g., 0856435, 0a75aab) focused on φ-spec documentation; no regressions surfaced, and documentation aligns with spec requirements.

**Next Steps**
- Ralph to author `reports/2025-10-vectorization/phase_d/polynomial_validation.md`, run `pytest --collect-only -q tests/test_tricubic_vectorized.py`, and prepare tap points ahead of Phase D2 implementation.
[2025-10-07T22:17:08] tokens used: 284,707
Reading prompt from stdin...
To github.com:hoidn/nanoBragg.git
   f245738..2b69f66  HEAD -> feature/spec-based-2
Waiting for Ralph to complete i=115...
Already up to date.
[sync] state: actor=ralph status=waiting-ralph iter=115
Updating 2b69f66..556de97
Fast-forward
 sync/state.json | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
From github.com:hoidn/nanoBragg
   2b69f66..556de97  feature/spec-based-2 -> origin/feature/spec-based-2
[sync] state: actor=ralph status=running-ralph iter=115
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating 556de97..16c51ca
Fast-forward
 docs/fix_plan.md                                   |  14 +
 reports/2025-10-vectorization/phase_d/collect.log  |   7 +
 .../phase_d/polynomial_validation.md               | 982 +++++++++++++++++++++
 3 files changed, 1003 insertions(+)
 create mode 100644 reports/2025-10-vectorization/phase_d/collect.log
 create mode 100644 reports/2025-10-vectorization/phase_d/polynomial_validation.md
From github.com:hoidn/nanoBragg
   556de97..16c51ca  feature/spec-based-2 -> origin/feature/spec-based-2
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating 16c51ca..38814c6
Fast-forward
 sync/state.json | 12 ++++++------
 1 file changed, 6 insertions(+), 6 deletions(-)
From github.com:hoidn/nanoBragg
   16c51ca..38814c6  feature/spec-based-2 -> origin/feature/spec-based-2
[sync] state: actor=galph status=complete iter=116
Ralph completed iteration 115; proceeding to 116
