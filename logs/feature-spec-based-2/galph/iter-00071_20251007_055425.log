Already up to date.
Waiting for expected_actor=galph...
Already up to date.
[sync] state: actor=ralph status=running-ralph iter=71
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating 79dc7a9..49f78d7
Fast-forward
 prompts/supervisor.md | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
From github.com:hoidn/nanoBragg
   79dc7a9..49f78d7  feature/spec-based-2 -> origin/feature/spec-based-2
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating 49f78d7..0f3de26
Fast-forward
 docs/fix_plan.md                                   | 17 ++++++++-
 .../scaling_audit/harness_hkl_state_fixed.txt      | 17 +++++++++
 .../phase_l/scaling_audit/trace_harness.py         | 10 +++---
 .../phase_l/scaling_audit/trace_py_baseline.log    | 40 ++++++++++++++++++++++
 .../phase_l/scaling_audit/trace_py_env.json        |  4 +--
 .../phase_l/scaling_audit/trace_py_scaling.log     | 24 ++++++-------
 6 files changed, 92 insertions(+), 20 deletions(-)
 create mode 100644 reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state_fixed.txt
 create mode 100644 reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_baseline.log
From github.com:hoidn/nanoBragg
   49f78d7..0f3de26  feature/spec-based-2 -> origin/feature/spec-based-2
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating 0f3de26..870d5fe
Fast-forward
 sync/state.json | 12 ++++++------
 1 file changed, 6 insertions(+), 6 deletions(-)
From github.com:hoidn/nanoBragg
   0f3de26..870d5fe  feature/spec-based-2 -> origin/feature/spec-based-2
[sync] state: actor=galph status=complete iter=72
To github.com:hoidn/nanoBragg.git
   870d5fe..2d8e073  HEAD -> feature/spec-based-2
$ codex exec -m gpt-5-codex -c model_reasoning_effort=high --dangerously-bypass-approvals-and-sandbox
[2025-10-07T06:14:14] OpenAI Codex v0.38.0 (research preview)
--------
workdir: /Users/ollie/Documents/nanoBragg3
model: gpt-5-codex
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: high
reasoning summaries: auto
--------
[2025-10-07T06:14:14] User instructions:
<role>
planning, review and analysis. do not make implementation code changes.
</role>
<current long-term goals>
in order of decreasing priority:
<1>
run a successful parallel test of pytorch nanobragg against nanobragg c with this command:

nanoBragg  -mat A.mat -floatfile img.bin -hkl scaled.hkl  -nonoise  -nointerpolate -oversample 1  -exposure 1  -flux 1e18 -beamsize 1.0  -spindle_axis -1 0 0 -Xbeam 217.742295 -Ybeam 213.907080  -distance 231.274660 -lambda 0.976800 -pixel 0.172 -detpixels_x 2463 -detpixels_y 2527 -odet_vector -0.000088 0.004914 -0.999988 -sdet_vector -0.005998 -0.999970 -0.004913 -fdet_vector 0.999982 -0.005998 -0.000118 -pix0_vector_mm -216.336293 215.205512 -230.200866  -beam_vector 0.00051387949 0.0 -0.99999986  -Na 36  -Nb 47 -Nc 29 -osc 0.1 -phi 0 -phisteps 10 -detector_rotx 0 -detector_roty 0 -detector_rotz 0 -twotheta 0

this will require first adding support for the following cli params to pytorch nanobragg:
-nonoise
-pix0_vector_mm

</1>
<2>
review and firm up if needed plans/active/vectorization.md. then implement it (or rather, delegate its implementation to ralph), starting with the tricubic interpolation vectorization 
</2>
</current long-term goals>
</past long term goals>
(just for archival / reference purposes):
- error-correcting the engineer agent 
- profiling pytorch nanobragg to find performance bottlenecks. analyzing to understand the CRITICAL slowness of the pytorch implementation compared to reference C, which persists after our recent improvement attempts
- finding performance issues in the PyTorch reimplementation of nanobragg (originally a C code) and speeding it up. It should be efficiently vectorized and faster than C nanobragg, but currently it's slower 
- ensuring that the pytorch implementation uses fp32 (not fp64) by default 
- understanding why pytorch is slower than C in the warm condition at 4096x4096 resolution and fixing the underlying performance issue, if one is found. THIS IS A CRITICAL PERFORMANCE ISSUE.
- once all the above are taken care of: building a user-facing showcase of autodiff-based parameter refinement, with plots / visuals

</past long-term goals>
<task>
You are galph, a planner / supervisor agent. you are overseeing the work of an agent (ralph) that is running prompts/main.md in a loop, using docs/fix_plan.md as its instruction set and long term memory. 

You will get invoked repeatedly, for multiple iterations. Use galph_memory.md to communicate with your future self. You'll plans under plans/, when needed, to help steer multi-turn efforts by the coder agent (ralph). Those plans will be cross referenced from docs/fix_plan.md so that ralph can find / read them. 

At the start of every invocation:
- Run `timeout 30 git pull --rebase` with a hard 30-second timeout  to sync with origin before reviewing context. If the command times out, immediately abort any partial rebase (`git rebase --abort`) and fall back to a normal merge via `git pull --no-rebase`. Whatever path you take, resolve resulting conflicts (docs/fix_plan.md is a frequent hotspot) and document key decisions in galph_memory.md. If the pull reports conflicts:
  * Run `git status --short` to list conflicted files.
  * Fix each file (remove conflict markers, keep the intended content) and stage it with `git add`.
  * When the index is clean, resume with `timeout 30 git rebase --continue --no-edit`. IMPORTANT: NEVER RUN THIS COMMAND WITHOUT TIMEOUT
- After resolving any conflicts, read the latest galph_memory.md entry (and any linked plan files) so you do not lose past context.
- Prune or summarize older entries when they become stale or redundant.

During the main, central phase of invocation you will be doing essentially three things:
<main analysis step 1> 
An initial analysis pass in which you gather and review information in order to choose a <focus issue> for the turn, corresponding to <instructions> steps <0> through <3>. This will involve a multi-category selection process. You will choose both a <focus issue> and an associated <Action type> for the remainder of the iteration. The available <Action type>s are the following:
<Action type> list:
<1>
<Evidence collection> (i.e. Evidence task)
No full pytest runs. Allowed: non-mutating probes and CLI validation tools (e.g., scripts/validation/*, nb-compare, pixel trace); pytest --collect-only to validate selectors; and in TDD mode only, a single targeted pytest run to confirm the newly authored test fails. Do not change production code. This gate applies only to galph. Ralph is exempt. Do not include any Phase label in input.md.

Evidence collection includes the following subtype:
    Callchain Tracing (Evidence subtype)
    - When to use: before code edits when the pipeline/factor order relevant to the current issue is unclear; when onboarding a new surface; or upon parity failures where the locus is unknown.
    - Directive: run `prompts/callchain.md` with a question‑driven invocation and produce standardized artifacts under `reports/<initiative_id>/`.
    - Example invocation variables (fill at run time):
      analysis_question: "<what are we trying to understand or fix?>"
      initiative_id: "<short‑slug>"
      scope_hints: ["CLI flags", "normalization", "scaling"]
      roi_hint: "<minimal input/ROI>"
      namespace_filter: "<project primary package>"
      time_budget_minutes: 30
    - Expected outputs:
      - `reports/<initiative_id>/callchain/static.md` (entry→sink with file:line anchors)
      - `reports/<initiative_id>/callgraph/dynamic.txt` (optional, module‑filtered)
      - `reports/<initiative_id>/trace/tap_points.md` (proposed numeric taps with owners)
      - `reports/<initiative_id>/summary.md` (question‑oriented narrative + next steps)
      - `reports/<initiative_id>/env/trace_env.json`
    - Guardrails: evidence‑only (no prod edits), module/device/dtype neutrality, small ROI, respect Protected Assets, stable key names in traces.
</Evidence collection>
</1>
<2>
<Debug> i.e. Debugging — Hypothesis + Triage (initial pass):
- pairs with <focus issue>s that are related to debugging or parity analysis.
<steps>
- Formulate 1–3 plausible hypotheses for the observed gap/issue.
- Triage each with checks appropriate to scope using existing artifacts or quick, documented reproductions; this triage may constitute the primary work for the iteration. Record outcomes succinctly in the evidence.
- For the top hypothesis, state confidence and the single confirming step to run next. Deliver 1–3 ranked hypotheses with supporting evidence, artifact paths, and the next confirming step.
</steps>
</Debug>
</2>
<3>
<Planning>
- we will be calling the plan topic the <focus issue> of this turn.
- based on which long term <goal> and sub-goal is that effort / plan? 
- Which existing docs/fix_plan.md items does it (i.e. the <focus issue>) relate to? 
- Documentation review for <focus issue>: Using `docs/index.md` as the map, identify and read the specific documents relevant to the chosen <focus issue> (e.g., component contracts, architecture ADRs, parity/testing strategy). List the file paths you will rely on (with a one‑line rationale each) before drafting or updating the plan.
- think deeply. draft / redraft the plan and save it to a .md under plans/active/. Structure the write-up as a phased implementation document (see `plans/archive/general-detector-geometry/implementation.md` for tone/shape): begin with context + phase overviews, then outline each phase’s intent, prerequisites, and exit criteria. When a phase benefits from explicit tracking, embed a checklist table using the `ID | Task Description | State | How/Why & Guidance` format (with `[ ]`, `[P]`, `[D]` markers) inside that phase section.
  • Include reproduction commands, owners (if known), and decision rules in the guidance column.
  • Favor narrative flow first; layer checklists only where they clarify verification steps or deliverables.
  • Mini-template to crib when drafting:
    ```md
    ## Context
    - Initiative: <initiative>
    - Phase Goal: <outcome>
    - Dependencies: <docs/tests>

    ### Phase A — <short title>
    Goal: <what this phase proves or delivers>
    Prereqs: <artifacts or measurements required before starting>
    Exit Criteria: <verifiable completion signal>

    | ID | Task Description | State | How/Why & Guidance (including API / document / artifact / source file references) |
    | --- | --- | --- | --- |
    | A1 | <Key diagnostic or implementation step> | [ ] | Run `<command>`; capture results under `reports/<date>/...`. |
    | A2 | <Follow-up validation> | [ ] | Compare against `<artifact>`; stop if deviation > threshold. |
    ```
- When refreshing an existing plan, retrofit it to this phased format before adding or editing tasks.
- review docs/fix_plan.md. edit if needed. cross reference the new plans .md so that ralph can find it.
</Planning>
</3>

<4>
<Review or housekeeping>
- Review and evaluate ralph's work. Scrutinize the commit history. Look at the diffs. 
- Are the docs/fix_plan.md contents and priorities sane? things to consider:
  - if docs/fix_plan.md is longer than 1000 lines it should be housecleaned. If it's disorganized and / or internally inconsistent, consider how this could be addressed. 
- after considering the above, you have enough information to choose a <focus issue> for this turn. do so. Consider the nature of the <focus issue>:
    - Documentation review for <focus issue>: From `docs/index.md`, enumerate and read the documents that are most relevant to the chosen <focus issue>`; note the key file paths you will rely on for this turn.
    - Do we need a new docs/fix_plan item to put ralph back on course, fix one of his mistakes, or instruct him to do something that he overlooked? If so, draft it and add it to docs/fix_plans
    - does the <focus issue> involve identified issues in docs/fix_plan.md? If so, fix them. If you decide to shorten docs/fix_plan.md, the least relevant portions should be moved to archive/fix_plan_archive.md (with summary + archive cross reference if appropriate)
</Review or housekeeping>
</4>

In addition to selecting an <Action type> and <focus issue> you will choose a <Mode> flag. 
 - Mode flags are combinable and refine execution, and are applicable to both the supervisor (you) and ralph; do not include any Phase label in input.md.
 - available modes: <TDD | Parity | Perf | Docs | none>
<mode descriptions>
TDD mode (supervisor-scoped): When operating in supervisor evidence mode, author/update a single minimal failing test that encodes the acceptance criterion. Confirm it fails via a targeted pytest selector; record the selector and expected failure text in input.md. Do not change production code, and do not include any Phase label in input.md.
</mode descriptions>

</main analysis step 1>

<main analysis step 2>
Here you will do a deep analysis. You will follow the guidelines of the selected <Mode> and <Action type>, applying them to the selected <focus issue>. This corresponds to <instructions> step <3.2>.
</main analysis step 2>

<main analysis step 3>
Here you synthesize the analysis findings into output files (<instructions> steps <3.5> to <4>)
</main analysis step 3>


Before concluding each invocation:
- Append a concise update to galph_memory.md capturing key findings, decisions, and open questions (reference file paths or plan names).
- Note any follow-up actions you expect Ralph to take.
- If no substantial update is needed, explicitly log that fact so future runs know context was reviewed.
</task>

<instructions>
<0>
READ the following files:
- Index of project documentation: `./docs/index.md`
- $SPECS: `./specs/spec-a.md`
- $ARCH: `./arch.md` (ADR-backed implementation architecture; reconcile design with spec, surface conflicts)
- docs/development/c_to_pytorch_config_map.md — C↔Py config parity and implicit rules
-- docs/debugging/debugging.md — Parallel trace-driven debugging SOP
- $PLAN: `./fix_plan.md` (living, prioritized to‑do; keep it up to date)
- $TESTS: `./docs/development/testing_strategy.md` (testing philosophy, tiers, seeds/tolerances, commands)
- Set `AUTHORITATIVE_CMDS_DOC=./docs/development/testing_strategy.md` (or project‑specific path) and consult it for authoritative reference commands and test discovery.
<0>
<1>
do a deep analysis of the codebase in light of the <current long term goals>. What are some current issues / gaps and possible approaches to resolving them? Review docs/fix_plan.md and plans/active/, as previous iterations of you may have already done some legwork.
 


At this point, you can do a <Callchain tracing> or <Debug> action.
</1>
<2>
flip a coin using python. if it comes up <heads>:
review ralph's work over the last N (~10 but can be more or less - you decide) iterations. Check the commit history. Has the work been productive? Have there been regressions? Do we need to provide any feedback / course-correction?
</heads>
if it comes up <tails>: proceed to step <3>
</2>
<3>
Given your findings in <1> and <2>, think about whether there's any need for a multi-turn planning effort -- i.e. ralph can't see the forest for the trees and may struggle with major refactorings and multi-turn implementation efforts unless they are coordinated by you. Is there a need for such planning *right now*? If such a plan is already spoken for (plans/active/ or wherever else past galph might have saved to), does that plan require updates or is it up to date / high quality and simply pending? IFF you determine the need for a new plan or modification of an existing one:
<yes case>
follow the <Planning> <Action type> instructions
</yes case>
</no case>
Since you are not <Planning>, you must select one of the other <Action type>s and follow its instructions.
</no case>
</3>
<3.2>
Carefully follow the guidelines of the selected <Mode> and <Action type>, applying them to the selected <focus issue>. Complete the task that you selected in step <3>.
</3.2>
<3.5>
Render and write ./input.md (supervisor→engineer steering memo). Overwrite the entire file every invocation. Keep length ~100–200 lines. Include these sections in order:
Header:
- Summary: <one‑sentence goal for this loop>
 - Mode: <TDD | Parity | Perf | Docs | none>
- Focus: <plan item ID/title from docs/fix_plan.md>
- Branch: <expected branch>
- Mapped tests: <validated list | none — evidence‑only>
- Artifacts: <key paths to produce under reports/>
- Do Now: 1 line naming the exact docs/fix_plan.md item (ID and title) to execute this loop, plus the exact pytest command/env to reproduce it (only when an authoritative mapping exists). If no such test exists, the Do Now MUST be to author the minimal targeted test first and then run it. If you intend to delegate the choice, write “Do Now: delegate” and provide decision guidance below.
  - Note: If operating in supervisor <Evidence collection> (internal-only), do not run the full suite. Allowed: pytest --collect-only to validate selectors; in TDD mode only, run one targeted selector to confirm a new failing test. All other test execution is deferred to Ralph. Do not include any Phase label in input.md.
<Do Now guidelines>
Verification scripts: You may run nb-compare and scripts/validation/* to collect metrics and artifacts (no code changes). Record outputs under reports/.
Mapped tests under supervisor evidence mode: Include exact selectors in input.md; validate with --collect-only; do not run them (except the TDD failure confirmation). Do not include any Phase label in input.md.
Command Sourcing (tests): Only include an exact pytest command in Do Now when sourced from an authoritative mapping (e.g., docs/development/testing_strategy.md) or an existing, known test file/identifier. If no authoritative mapping exists, set the Do Now task to author the minimal targeted test first; do not guess at a pytest selector here.
Implementation: refer to phased plans, checklists, and all associated artifacts
</Do Now guidelines>
- If Blocked: fallback action (what to run/capture, how to record it in Attempts History).
- Priorities & Rationale: 3–6 bullets with file pointers (specs/arch/tests/plan) justifying the Do Now.
- How-To Map: exact commands (pytest, nb-compare), env vars, ROI/thresholds, and where to store artifacts; prefer using `scripts/validation/*` when available.
- Pitfalls To Avoid: 5–10 crisp do/don’t reminders (device/dtype neutrality, vectorization, Protected Assets, two‑message loop policy, no ad‑hoc scripts).
- Pointers: file paths with line anchors to the most relevant spec/arch/testing_strategy/fix_plan entries for this loop.
- Next Up (optional): 1–2 candidates Ralph may choose next loop if he finishes early (still one thing per loop).

 Rules:
 - Ralph must not edit input.md. You (galph) are the single writer.
 - If input.md’s Do Now conflicts with an existing in_progress selection in fix_plan.md, Ralph is allowed to switch; he must record the change in Attempts History.
- Do not instruct Ralph to run the full test suite more than once per turn. Require targeted tests first; run the full suite once at the end only if code changed. For prompt/docs‑only loops, require `pytest --collect-only -q` instead.
- Prefer referencing reusable scripts under `scripts/validation/` from Do Now when available.
- Commit input.md each run as part of step <4> (commit only if the content changed).
 </3.5>

<4>
Before finishing the loop, enforce git hygiene:
- Run `git status --short` to inspect new or modified files that appeared during this invocation.
- Review diffs for each change; revert only if you created it this loop and it was accidental.
- Stage intentional updates with `git add -A` and commit via `git commit -m "SUPERVISOR: <scope> - <tests or rationale>"`, noting any tests run (use `tests: not run` when you skip them).
- After committing, run `git push` to share the updates. If the push is rejected, `timeout 30 git pull --rebase`, resolve conflicts (capture decisions—especially for docs/fix_plan.md—in galph_memory.md), then push again.
- If you deliberately leave the tree dirty, document the rationale in galph_memory.md so the next invocation knows why.
</4>
</instructions>
<notes>
- ignore 'routing violations'. these are out of scope.
- ignore AT parallel 012-related items for now
</notes>
Now carefully and exhaustively follow your <instructions>.


[2025-10-07T06:14:18] thinking

**Preparing to update repository**
[2025-10-07T06:14:18] exec bash -lc 'timeout 30 git pull --rebase' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:21] bash -lc 'timeout 30 git pull --rebase' succeeded in 2.59s:
Already up to date.
[2025-10-07T06:14:21] tokens used: 4,657

[2025-10-07T06:14:22] thinking

**Preparing to review galph_memory**
[2025-10-07T06:14:23] exec bash -lc 'cat galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:23] bash -lc 'cat galph_memory.md' succeeded in 685ms:
## 2025-09-30 (loops 1-4 summary)
- Established parity backlog: AT-020/021/022/024 failing; created first supervisor plan for AT-021 and enforced prompts/debug.md routing.
- Diagnosed AT-024 random misset cap mismatch (π/2 vs 90 radians) and opened dedicated plan; insisted Ralph stop verification-only loops.
- Flagged torch.compile warm-up overhead (per-instance compilation, inline tensor factories) and opened AT-012 rotation parity plan (Phases A–E).
- Documented performance hotspots (`_compute_physics_for_position` guard tensors, `Crystal.compute_cell_tensors` clamps) and chronic dirty worktree artifacts blocking `git pull --rebase`.

## 2025-09-30 (loops 5-10 summary)
- Authored repo hygiene checklist (REPO-HYGIENE-002) to undo accidental `golden_suite_generator/nanoBragg.c` churn and purge stray reports.
- Created PERF-PYTORCH-004 plan to hoist constants, introduce compile caching, and remove Dynamo graph breaks; reiterated need for prompts/debug.md while parity fails.
- Repeatedly documented routing violations from Ralph and emphasized restoring Core Rule #13 metric duality after WIP commit 058986f swapped `V_actual` for formula volume.
- Noted that `_compute_physics_for_position` still recompiles each Simulator and that benchmarks in `reports/benchmarks/20250930-004916/` show ≥200× slowdown vs C for small detectors.

## 2025-09-30 (ralph debugging loop — AT-012 float32 regression)
- **Context**: AT-PARALLEL-012 test_simple_cubic_correlation failing (43/50 peaks matched, need ≥95%) after DTYPE-DEFAULT-001 (commit 8c2ceb4) switched simulator to native float32.
- **Investigation**:
  * Reproduced: 43/50 peaks matched (86%), corr≈1.0 (perfect physics) ✅
  * Parity matrix test: PASSES perfectly ✅ (live C↔Py comparison with current float32)
  * **Root cause identified**: PyTorch float32 produces 7× more unique values (4901 vs C's 669) in hot pixels, fragmenting intensity plateaus. Peak detection algorithm (scipy.ndimage.maximum_filter) is sensitive to plateau structure.
  * Parallel comparison: C float32 beam center (20×20 ROI) has 91 unique values; PyTorch has 331 (3.6× fragmentation). Max absolute diff tiny (0.0017).
  * **First Divergence**: Numerical accumulation patterns differ (likely FMA, compiler opts, vectorized accumulation order, or torch.compile kernel fusion) → perfect correlation but incompatible plateau structure.
[2025-10-07T06:14:23] tokens used: 4,921

[2025-10-07T06:14:26] thinking

**Checking plan files and entries**
[2025-10-07T06:14:28] exec bash -lc 'ls plans/active' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:28] bash -lc 'ls plans/active' succeeded in 665ms:
cli-noise-pix0
gradcheck-tier2-completion
perf-pytorch-compile-refactor
routing-loop-guard
supervisor-loop-guard
unification.md
vectorization.md
[2025-10-07T06:14:28] tokens used: 7,721

[2025-10-07T06:14:33] thinking

**Preparing to read documentation files**
[2025-10-07T06:14:34] exec bash -lc 'cat docs/index.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:35] bash -lc 'cat docs/index.md' succeeded in 688ms:
# Project Documentation Index

Welcome to the central index for all `nanoBragg-PyTorch` project documentation. This guide provides a map to the key technical specifications, development processes, and historical records that define the project.

---

## 🏛️ Permanent Documentation

These are the core, living documents that guide the project.

### Core Project Guides
### PyTorch Guardrails
* **[PyTorch Runtime Checklist](./development/pytorch_runtime_checklist.md)** – quick do/don’t list for vectorization and device placement. Always review before editing simulator code.
* **[PyTorch Design](./architecture/pytorch_design.md#vectorization-strategy)** – detailed explanation of the required broadcast shapes and batched flows.
* **[Testing Strategy §1.4](./development/testing_strategy.md#14-pytorch-device--dtype-discipline)** – required CPU/GPU smoke tests and compile checks.

* **[CLAUDE.md](../CLAUDE.md)** - The primary instruction set for the AI agent.
* **[README.md](../README.md)** - The main project entry point.
* **[README_PYTORCH.md](../README_PYTORCH.md)** - Comprehensive user guide for the PyTorch implementation, including CLI usage, parallel comparison tools, and visualization.
* **[PROJECT_STATUS.md](../PROJECT_STATUS.md)** - Tracks the current active development initiative.
[2025-10-07T06:14:35] tokens used: 24,690

[2025-10-07T06:14:38] thinking

**Preparing to read large spec file**
[2025-10-07T06:14:39] exec bash -lc 'cat specs/spec-a.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:39] bash -lc 'cat specs/spec-a.md' succeeded in 682ms:
# nanoBragg Spec A — Sharded Specification

Spec A is now organized across multiple shards. Read them together for the full normative contract.

- [spec-a-core.md](spec-a-core.md): Core physics, geometry, sampling, data, and associated acceptance tests.
- [spec-a-cli.md](spec-a-cli.md): CLI surface area, precedence rules, and CLI-focused acceptance tests.
- [spec-a-parallel.md](spec-a-parallel.md): Conformance profiles, parallel validation suites, and developer tooling requirements.

Each shard cross-references the others; updates must keep them consistent.
[2025-10-07T06:14:39] tokens used: 26,401

[2025-10-07T06:14:43] thinking

**Opening spec-a-core.md**
[2025-10-07T06:14:43] exec bash -lc 'cat specs/spec-a-core.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:44] bash -lc 'cat specs/spec-a-core.md' succeeded in 760ms:
# nanoBragg Spec A — Core Engine

This shard contains the normative physics, geometry, sampling, and data handling requirements. CLI flag semantics live in [spec-a-cli.md](spec-a-cli.md); cross-implementation profiles and developer tooling are captured in [spec-a-parallel.md](spec-a-parallel.md).

Overview (Normative)

- Purpose: Simulates far-field diffraction from a perfect-lattice nanocrystal on a pixelated area
detector. No near-field propagation or detector PSF beyond pixel solid-angle/obliquity is modeled.
No symmetry is imposed; reflection indexing is P1 only (no Friedel pairing).
- Scope: Renders pixel intensities from a set of sources (beam divergence and spectral dispersion),
crystal orientation (including rotation oscillation and mosaic domains), and detector geometry.
Outputs: raw float image, SMV-format integer image (with and without Poisson noise), and optional
PGM.
- Key constants:
    - Classical electron radius squared r_e^2 = 7.94079248018965e-30 m^2.
    - Avogadro’s number = 6.02214179e23 mol^-1.

Units & Conversions (Normative)

- Length:
[2025-10-07T06:14:44] tokens used: 26,695

[2025-10-07T06:14:50] thinking

**Handling truncated file output**
[2025-10-07T06:14:50] exec bash -lc 'cat arch.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:51] bash -lc 'cat arch.md' succeeded in 702ms:
# nanoBragg PyTorch — Implementation Architecture

Document version: 1.0 (aligned with specs/spec-a.md)
Target spec: specs/spec-a.md (single-file normative spec)
Implementation target: Python (>=3.11) + PyTorch (float32 default). Type blocks may use TypeScript-style for clarity; implement with Python dataclasses and torch tensors.

## Running The CLI

- Install (recommended):
  - `pip install -e .` from repo root (provides `nanoBragg` console script).
- Run (installed):
  - `nanoBragg -hkl P1.hkl -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -floatfile out.bin`
- Run (without install):
  - `PYTHONPATH=src python -m nanobrag_torch -hkl P1.hkl -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -floatfile out.bin`
- Minimal quick test (no HKL):
  - `nanoBragg -default_F 1 -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -detpixels 128 -pgmfile test.pgm`

Notes
- Entry point: `src/nanobrag_torch/__main__.py` (module runner `python -m nanobrag_torch`).
- Required inputs: provide `-hkl` (or existing `Fdump.bin`) or set `-default_F > 0`, and either `-mat` (MOSFLM A*) or `-cell`.
[2025-10-07T06:14:51] tokens used: 30,470

[2025-10-07T06:14:55] thinking

**Noting missing documentation file**
[2025-10-07T06:14:56] exec bash -lc 'cat docs/development/c_to_pytorch_config_map.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:14:57] bash -lc 'cat docs/development/c_to_pytorch_config_map.md' succeeded in 815ms:
# C-CLI to PyTorch Configuration Map

## Critical Importance Notice

**This document is the authoritative source of truth for configuration parity between nanoBragg.c and the PyTorch implementation.**

Before writing any test or implementation that involves C-code validation, you **MUST** consult this document. Failure to ensure 1:1 configuration parity is the most common source of bugs, particularly with:
- Implicit pivot mode logic
- Convention-dependent beam center calculations
- Rotation axis defaults
- Unit conversions

## Quick Reference Table

### Crystal Parameters

| C-CLI Flag | PyTorch Config Field | C Variable | Units/Convention | Critical Notes |
|------------|---------------------|------------|------------------|----------------|
| `-cell a b c al be ga` | `CrystalConfig.cell_a/b/c/alpha/beta/gamma` | `a[0], b[0], c[0], alpha, beta, gamma` | Å and degrees → radians | Must convert degrees to radians internally |
| `-N <val>` | `CrystalConfig.N_cells` | `Na, Nb, Nc` | Number of unit cells | Sets all three axes to same value |
[2025-10-07T06:14:57] tokens used: 33,934

[2025-10-07T06:15:00] thinking

**Noting additional documentation needed**
[2025-10-07T06:15:01] exec bash -lc 'cat docs/debugging/debugging.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:01] bash -lc 'cat docs/debugging/debugging.md' succeeded in 700ms:
# nanoBragg PyTorch Debugging Guidelines

**Version:** 1.1  
**Date:** 2024-07-25  
**Owner:** PyTorch Development Team

## Overview

This document outlines the debugging methodology and tools for the nanoBragg PyTorch implementation. The debugging approach is built around a parallel trace comparison between the C code and the PyTorch implementation to ensure correctness and facilitate rapid issue resolution.

## Core Debugging Philosophy

### Parallel Trace Comparison Rule

**CRITICAL:** All debugging of physics discrepancies MUST begin with a parallel trace comparison. This involves:
1. Generating a detailed, step-by-step log of intermediate variables from the original C code for a specific pixel (the "Golden Trace").
2. Generating an identical log from the PyTorch implementation using `scripts/debug_pixel_trace.py`.
3. Comparing these two logs line-by-line to find the first point of divergence.

This methodology is mandatory to avoid guesswork and ensure bugs are found deterministically.
[2025-10-07T06:15:01] tokens used: 35,872

[2025-10-07T06:15:06] thinking

**Preparing to review fix_plan.md**
[2025-10-07T06:15:07] exec bash -lc "sed -n '1,160p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:07] bash -lc "sed -n '1,160p' docs/fix_plan.md" succeeded in 689ms:
# Fix Plan Ledger

**Last Updated:** 2025-10-17 (galph loop)
**Active Focus:**
- ROUTING: Close the reopened guard plan by capturing a fresh regression audit referencing commit `c49e3be` and re-confirming the guarded `loop.sh` flow (`plans/active/routing-loop-guard/plan.md` Phases A–C) before automation resumes.
- ROUTING-SUPERVISOR: Launch Phase A of `plans/active/supervisor-loop-guard/plan.md`, then drive Phase B guard work (B2–B4) and new task B5 to add `supervisor.sh` to docs/index.md so Protected-Asset policy covers the script before automation runs again.
- AT-012: Plan archived (`plans/archive/at-parallel-012-plateau-regression/plan.md`); monitor for regressions using `reports/2025-10-AT012-regression/phase_c_validation/` artifacts and re-open only if peak matches drop below spec.
- GRADIENT: Execute `plans/active/gradcheck-tier2-completion/plan.md` Phase A (A1–A3 baseline audit + env alignment) before adding misset/beam gradchecks from Phases B/C; once pass logs exist, close `[AT-TIER2-GRADCHECK]` with Phase D documentation updates.
- DTYPE: ✅ Complete. Plan archived to `plans/archive/dtype-default-fp32/`. All phases (A-D) finished; float32 defaults documented in arch.md, pytorch_runtime_checklist.md, CLAUDE.md, prompts/debug.md.
- PERF: Land plan task B7 (benchmark env toggle fix), rerun Phase B6 ten-process reproducibility with the new compile metadata, capture the weighted-source parity memo feeding C5, then execute Phase C diagnostics (C1/C2 plus C8/C9 pixel-grid & rotated-vector cost probes, and new C10 mosaic RNG timing) ahead of Phase D caching work (D5/D6/D7) and detector-scalar hoisting (D8).

## Index
| ID | Title | Priority | Status |
| --- | --- | --- | --- |
| [PROTECTED-ASSETS-001](#protected-assets-001-docsindexmd-safeguard) | Protect docs/index.md assets | Medium | in_progress |
| [REPO-HYGIENE-002](#repo-hygiene-002-restore-canonical-nanobraggc) | Restore canonical nanoBragg.c | Medium | in_progress |
| [PERF-PYTORCH-004](#perf-pytorch-004-fuse-physics-kernels) | Fuse physics kernels | High | in_progress |
| [AT-TIER2-GRADCHECK](#at-tier2-gradcheck-implement-tier-2-gradient-correctness-tests) | Implement Tier 2 gradient correctness tests | High | in_progress |
| [VECTOR-TRICUBIC-001](#vector-tricubic-001-vectorize-tricubic-interpolation-and-detector-absorption) | Vectorize tricubic interpolation and detector absorption | High | in_planning |
| [CLI-DTYPE-002](#cli-dtype-002-cli-dtype-parity) | CLI dtype parity | High | in_progress |
[2025-10-07T06:15:07] tokens used: 38,500

[2025-10-07T06:15:09] thinking

**Searching for CLI flags documentation**
[2025-10-07T06:15:10] exec bash -lc 'rg -n "CLI-FLAGS-003" docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:11] bash -lc 'rg -n "CLI-FLAGS-003" docs/fix_plan.md' succeeded in 686ms:
21:| [CLI-FLAGS-003](#cli-flags-003-handle-nonoise-and-pix0_vector_mm) | Handle -nonoise and -pix0_vector_mm | High | in_progress |
448:## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
[2025-10-07T06:15:11] tokens used: 41,466

[2025-10-07T06:15:12] thinking

**Reviewing code section**
[2025-10-07T06:15:12] exec bash -lc "sed -n '448,620p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:13] bash -lc "sed -n '448,620p' docs/fix_plan.md" succeeded in 741ms:
## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
- Spec/AT: specs/spec-a-cli.md flag catalogue, docs/architecture/detector.md §5 (pix0 workflow), docs/development/c_to_pytorch_config_map.md (pivot rules), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860
- Priority: High
- Status: in_progress (Phases A–H complete; K3a/K3b/K3d landed via Attempts #43–44, pending per-φ evidence + normalization closure)
- Owner/Date: ralph/2025-10-05
- Plan Reference: `plans/active/cli-noise-pix0/plan.md`
- Reproduction (C & PyTorch):
  * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
  * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
- Next Actions (2025-11-13 refresh):
  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
- Attempts History:
  * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
    Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:1-41` - Refreshed trace with live values (polar=0.91464138, omega_pixel=4.20404859e-07 sr, F_cell=0, I_before_scaling=0)
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1-54` - Phase L2c comparison report showing first divergence and all divergent factors
[2025-10-07T06:15:13] tokens used: 41,670

[2025-10-07T06:15:15] thinking

**Noting need for testing strategy doc**
[2025-10-07T06:15:16] exec bash -lc 'cat docs/development/testing_strategy.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:16] bash -lc 'cat docs/development/testing_strategy.md' succeeded in 695ms:
# nanoBragg PyTorch Testing Strategy

**Version:** 1.1  
**Date:** 2024-07-25  
**Owner:** [Your Name/Team]

## 1. Introduction & Philosophy

This document outlines the comprehensive testing strategy for the PyTorch implementation of nanoBragg. The primary goal is to ensure that the new application is a correct, verifiable, and trustworthy scientific tool.
Our testing philosophy is a three-tiered hybrid approach, designed to build confidence layer by layer:

1. **Tier 1: Translation Correctness:** We first prove that the PyTorch code is a faithful, numerically precise reimplementation of the original C code's physical model. The C code is treated as the "ground truth" specification.
2. **Tier 2: Gradient Correctness:** We then prove that the new differentiable capabilities are mathematically sound.
3. **Tier 3: Scientific Validation:** Finally, we validate the model against objective physical principles.

All tests will be implemented using the PyTest framework.

### 1.4 PyTorch Device & Dtype Discipline

- **Device-neutral code:** Every PyTorch path MUST operate correctly on both CPU and CUDA tensors and across supported dtypes. Do not hard-code `.cpu()`/`.cuda()` calls, create CPU-only constants, or assume float64 execution when the caller may supply float32/half tensors.
[2025-10-07T06:15:16] tokens used: 44,763

[2025-10-07T06:15:20] thinking

**Preparing environment and reviewing plans**
[2025-10-07T06:15:20] exec bash -lc 'cat plans/active/cli-noise-pix0/plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:21] bash -lc 'cat plans/active/cli-noise-pix0/plan.md' succeeded in 690ms:
## Context
- Initiative: CLI Parity for nanoBragg PyTorch vs C (supports long-term goal in prompts/supervisor.md)
- Phase Goal: Accept `-nonoise` and `-pix0_vector_mm` flags with C-equivalent semantics so the parallel comparison command in prompts/supervisor.md executes end-to-end.
- Dependencies: specs/spec-a-cli.md §§3.2–3.4, docs/architecture/detector.md §5, docs/development/c_to_pytorch_config_map.md (detector pivot + noise), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860 (flag behavior), docs/debugging/detector_geometry_checklist.md (pix0 validation), docs/development/testing_strategy.md §2 (CLI parity tests).
- Current gap snapshot (2025-10-18 refresh): Phase H4 parity landed (Attempt #25) with pix0 deltas < 2e-8 m and regression tolerances tightened; the remaining blocker before executing the supervisor command end-to-end is Phase I polarization alignment.
- Gap snapshot update (2025-10-19): Attempt #27 parity run reveals 1.24538e5× intensity scaling mismatch despite polarization fix; Phases J–L track the normalization diagnosis, fix, and closure required before long-term Goal #1 completes.
- Gap snapshot refresh (2025-10-22): Attempt #31 restored C precedence for custom detector vectors (pix0 override now gated again). Outstanding work: H5c PyTorch traces and Phase K normalization to eliminate the `F_latt`-driven intensity gap.
- Gap snapshot update (2025-10-24): Attempt #35 reran the PyTorch trace harness post-unit-fix; metrics still show |Δpix0| ≈ 1.145 mm, so a fresh diagnostics phase is required before resuming normalization work.
- Gap snapshot refresh (2025-10-26): Attempt #40 completed Phase H6f — custom detector vectors now force SAMPLE pivot parity, parity visuals relocated under `reports/2025-10-cli-flags/phase_h6/visuals/`, and targeted regression tests cover pivot selection. Outstanding work at that point: Phase H6g trace rerun to confirm |Δpix0| < 5e-5 m before returning to Phase K scalings.
- Gap snapshot update (2025-10-27): Attempt #41 validated Phase H6g — SAMPLE pivot parity holds with pix0 deltas ≤2.85 µm, beam center deltas 0.0, and supporting artifacts under `reports/2025-10-cli-flags/phase_h6/post_fix/`. Remaining blockers: rerun the scaling chain (Phase K2), execute the scaling regression + doc updates (Phase K3), then resume Phase L parity once normalization matches C.
- Gap snapshot refresh (2025-11-09): Attempt #49 closed Phase K3g3 — `tests/test_cli_scaling.py::test_f_latt_square_matches_c` now passes after isolating the HKL cache, but the full supervisor command still shows correlation ≈ 0.9965 and sum_ratio ≈ 1.26×10⁵. Need fresh HKL/normalization parity evidence (Phase L) before rerunning nb-compare.
- Gap snapshot refresh (2025-11-10): Attempt #56 (evidence loop) proved the existing `TRACE_PY` path prints placeholder scaling data (`capture_fraction 1`, `polar 1.0`, `steps`=φ-steps only). Without exposing the real per-pixel factors computed in `Simulator.run`, Phase L2b cannot produce a trustworthy PyTorch trace. Instrumentation must pull actual values from `_apply_detector_absorption`, polarization kernels, and total-step calculation before rerunning the harness.
- Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
- Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
- Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
- Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
- Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
- Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
[2025-10-07T06:15:21] tokens used: 47,489

[2025-10-07T06:15:24] thinking

**Planning vectorization approach**
[2025-10-07T06:15:24] exec bash -lc 'cat plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:25] bash -lc 'cat plans/active/vectorization.md' succeeded in 709ms:
## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md
- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
- Gap Snapshot (2025-11-09): Phase A remains untouched; no artifacts exist under `reports/2025-10-vectorization/phase_a/`, so Ralph must prioritise A1–A3 baseline capture before any implementation edits. docs/fix_plan.md item VECTOR-TRICUBIC-001 lists these as the gating next actions.

### Phase A — Evidence & Baseline Capture
Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.
Prereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.
Exit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [ ] | `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py -v` ⇒ save log to `reports/2025-10-vectorization/phase_a/test_at_str_002.log`; confirm nearest-neighbour fallback warning message appears for batched inputs. |
| A2 | Measure current tricubic runtime | [ ] | Author `scripts/benchmarks/tricubic_baseline.py` (device/dtype neutral, honours `KMP_DUPLICATE_LIB_OK=TRUE`) and run `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --repeats 5`. Capture CPU timings (and CUDA when available) in `phase_a/tricubic_baseline.md` plus raw JSON/CSV under `phase_a/tricubic_baseline_results.json`. |
| A3 | Record detector absorption baseline | [ ] | Create `scripts/benchmarks/absorption_baseline.py` mirroring A2's interface; execute `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/absorption_baseline.py --sizes 256 512 --repeats 5` alongside `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_abs_001.py -v`. Store logs in `phase_a/absorption_baseline.md` and metrics in `phase_a/absorption_baseline_results.json`. |

### Phase B — Tricubic Vectorization Design
Goal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.
Prereqs: Phase A artifacts uploaded and referenced in docs/fix_plan.md.
[2025-10-07T06:15:25] tokens used: 51,209

[2025-10-07T06:15:33] thinking

**Outlining deep codebase analysis**

I’m preparing to deeply analyze the codebase with a focus on long-term goals like parallel test commands and vectorization plans. To do this, I’ll review task statuses in docs and reports, especially around the harness issue causing F_cell zero, while planning to confirm current issues via source inspection without changing implementation yet.
[2025-10-07T06:15:35] exec bash -lc "sed -n '1,200p' reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:35] bash -lc "sed -n '1,200p' reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py" succeeded in 682ms:
#!/usr/bin/env python
"""
Phase L2b PyTorch Scaling Trace Harness

Captures the PyTorch side of the scaling chain comparison for supervisor command.
Mirrors the C trace fields from reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log.

Date: 2025-10-17
Engineer: Ralph (loop i=62, evidence-only mode)
Plan Reference: plans/active/cli-noise-pix0/plan.md Phase L2b
"""

import argparse
import json
import sys
import platform
import os
import torch
from pathlib import Path
from datetime import datetime
[2025-10-07T06:15:35] tokens used: 54,286

[2025-10-07T06:15:38] thinking

**Checking later parts for attachments**
[2025-10-07T06:15:39] exec bash -lc "sed -n '200,400p' reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:40] bash -lc "sed -n '200,400p' reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py" succeeded in 699ms:
            'distance_mm': detector_config.distance_mm,
            'pixel_size_mm': detector_config.pixel_size_mm,
            'spixels': detector_config.spixels,
            'fpixels': detector_config.fpixels,
            'beam_center_s': detector_config.beam_center_s,
            'beam_center_f': detector_config.beam_center_f,
            'convention': str(detector_config.detector_convention),
            'pivot': str(detector_config.detector_pivot),
            'oversample': detector_config.oversample
        },
        'beam': {
            'wavelength_A': beam_config.wavelength_A,
            'polarization_factor': beam_config.polarization_factor,
            'flux': beam_config.flux,
            'exposure': beam_config.exposure,
            'beamsize_mm': beam_config.beamsize_mm
        },
        'hkl': {
            'path': str(hkl_path),
            'h_range': (h_min, h_min + h_range),
[2025-10-07T06:15:40] tokens used: 56,831

[2025-10-07T06:15:45] thinking

**Reviewing harness status and plan updates**

I'm checking whether the harness properly attaches data now, as code shows—it seems earlier plans might be outdated. I want to confirm the fix_plan statuses and ensure understanding of current progress, especially focusing on long-term goals like CLI flags. I'll also verify if the fix_plan attempts go beyond Attempt #73 to get the latest task updates.
[2025-10-07T06:15:47] exec bash -lc "sed -n '620,840p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:47] bash -lc "sed -n '620,840p' docs/fix_plan.md" succeeded in 673ms:
      - **Phase H5 Tasks:** H5a (C precedence) ✅, H5b (revert override for custom vectors) ✅, H5d (fix_plan update) ✅, H5e (unit correction) ✅; H5c (post-fix trace capture) pending
    Next Actions: Execute Phase H5c trace harness to capture post-fix PyTorch traces showing pix0 parity with C, then proceed to Phase K1 (F_latt SQUARE sincg fix)
  * [2025-10-24] Attempt #35 (ralph) — Result: **EVIDENCE COMPLETE** (Phase H5c trace capture). **Critical finding: Attempt #33's beam-center mm→m fix had NO impact on pix0 calculation. Pix0 deltas IDENTICAL to 2025-10-22 baseline.**
    Metrics: Pix0 parity NOT achieved. ΔF = -1136.4 μm (exceeds <50 μm threshold), ΔS = +139.3 μm (exceeds threshold), ΔO = -5.6 μm (within threshold). Total magnitude Δ = 1.145 mm. All deltas identical to pre-Attempt #33 baseline.
    Artifacts:
      - `reports/2025-10-cli-flags/phase_h5/py_traces/2025-10-24/trace_py.stdout` - Fresh PyTorch trace post-Attempt #33 (wall-clock: ~3s)
      - `reports/2025-10-cli-flags/phase_h5/py_traces/2025-10-24/README.md` - Trace command, environment, git context
      - `reports/2025-10-cli-flags/phase_h5/py_traces/2025-10-24/git_context.txt` - Git commit hash and log
      - `reports/2025-10-cli-flags/phase_h5/py_traces/2025-10-24/env_snapshot.txt` - Environment variables snapshot
      - `reports/2025-10-cli-flags/phase_h5/py_traces/2025-10-24/trace_py.stdout.sha256` - Trace checksum for reproducibility
      - `reports/2025-10-cli-flags/phase_h5/parity_summary.md` - Updated with 2025-10-24 metrics and Phase H6 proposal
    Observations/Hypotheses:
      - **Attempt #33 ineffective for custom-vector path:** Beam-center fix applied to BEAM pivot calculation in `_configure_geometry()`, but pix0 in custom-vector scenarios is computed via `_calculate_pix0_vector()` which uses a **different code path** not touched by H5e.
      - **Pix0 discrepancy root cause still unknown:** The 1.1mm fast-axis error persists despite H5b (custom-vector guard) and H5e (beam-center unit fix). Detector basis vectors match C exactly, ruling out orientation issues.
      - **Systematic bias pattern:** Fast-axis error (1136 μm) is 10× larger than slow-axis error (139 μm), suggesting targeted calculation error rather than global scaling issue.
      - **Hypothesis:** `_calculate_pix0_vector()` likely has unit conversion error when using custom vectors OR pivot mode (SAMPLE) calculation differs from C implementation despite identical detector_pivot setting.
      - **Phase K blocked:** The 1.1mm pix0 error will cascade into incorrect Miller index calculations (h/k/l off by several tenths) and invalidate F_latt comparisons.
    Next Actions: **Phase H6 required** — Instrument `_calculate_pix0_vector()` with targeted print statements, generate comparative pix0 trace (Python vs C), identify first divergence, fix root cause, verify ΔF/ΔS/ΔO all below 50μm. Phase K normalization work cannot proceed until pix0 parity is achieved.
  * [2025-10-24] Attempt #36 (ralph) — Result: **EVIDENCE COMPLETE** (Phase H6a C trace capture). **C pix0 calculation fully instrumented and captured for SAMPLE pivot with custom vectors.**
    Metrics: Evidence-only loop. Wall-clock ~3s. C binary rebuilt with SAMPLE pivot tracing. Supervisor command executed successfully with max_I=446.254.
[2025-10-07T06:15:47] tokens used: 58,983

[2025-10-07T06:15:54] thinking

**Reviewing attempt history and plan status**
[2025-10-07T06:15:55] exec bash -lc 'rg "2025-11-1" docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:15:55] bash -lc 'rg "2025-11-1" docs/fix_plan.md' succeeded in 686ms:
- Next Actions (2025-11-13 refresh):
  * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
  * [2025-11-14] Attempt #73 (galph loop) — Result: **BLOCKED** (Phase L2b structure-factor wiring incomplete). **Harness leaves `Crystal.hkl_data` / `Crystal.hkl_metadata` unset after loading scaled.hkl, so structure factors still fall back to `default_F=0`.**
  * [2025-11-13] Attempt #70 (galph audit) — Result: **BLOCKED** (Phase L2b regression). **Trace harness still expects the legacy seven-value `read_hkl_file` return signature and aborts before emitting TRACE_PY.**
[2025-10-07T06:15:55] tokens used: 62,389

[2025-10-07T06:16:00] thinking

**Reviewing plan and preparing coin flip**
[2025-10-07T06:16:01] exec bash -lc "python - <<'PY'
import random
print(random.choice(['heads','tails']))
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:16:02] bash -lc "python - <<'PY'
import random
print(random.choice(['heads','tails']))
PY" succeeded in 719ms:
heads
[2025-10-07T06:16:02] tokens used: 63,152

[2025-10-07T06:16:06] thinking

**Reviewing recent commits**
[2025-10-07T06:16:06] exec bash -lc 'git log --oneline -10' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:16:07] bash -lc 'git log --oneline -10' succeeded in 722ms:
2d8e073 [SYNC i=72] actor=galph status=running
870d5fe [SYNC i=72] actor=ralph → next=galph status=ok ralph_commit=0f3de26
0f3de26 CLI-FLAGS-003 Phase L2b+L2c harness fix: Attach hkl_data/hkl_metadata to Crystal
49f78d7 update supervisor
79dc7a9 [SYNC i=71] actor=ralph status=running
9b8403d [SYNC i=71] actor=galph → next=ralph status=ok galph_commit=9164638
9164638 SUPERVISOR: CLI-FLAGS-003 harness audit - tests: not run
11c6f96 [SYNC i=71] actor=galph status=running
f80181a [SYNC i=71] actor=ralph → next=galph status=ok ralph_commit=1cf77b5
1cf77b5 CLI-FLAGS-003 Phase L2b: Fix trace harness MOSFLM vector assignment
[2025-10-07T06:16:07] tokens used: 63,458

[2025-10-07T06:16:12] thinking

**Reviewing latest commit details**
[2025-10-07T06:16:13] exec bash -lc 'git show 0f3de26 --stat' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:16:13] bash -lc 'git show 0f3de26 --stat' succeeded in 725ms:
commit 0f3de261ce2f929fcb080917c0c299e8712da6cd
Author: ollie <ohoidn>
Date:   Mon Oct 6 23:13:24 2025 -0700

    CLI-FLAGS-003 Phase L2b+L2c harness fix: Attach hkl_data/hkl_metadata to Crystal
    
    - Fixed trace_harness.py to set crystal.hkl_data and crystal.hkl_metadata
      instead of ad-hoc attributes (F_grid, h_min, etc.)
    - Crystal.get_structure_factor now correctly accesses HKL grid
    - Verified: lookup returns F=100 for (1,12,3), F=0 for out-of-range
    - Ran comparison script: all scaling factors match C within <0.002%
      (r_e², fluence, steps, polar, omega all validated)
    - First divergence: I_before_scaling (C=943654.809, Py=0) confirmed;
      expected because pixel (685,1039) maps to reflection not in HKL grid
    - Test suite: tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes 4/4 variants
    
    Module: harness/trace
    Artifacts: harness_hkl_state_fixed.txt, scaling_audit_summary.md
    Phase: L2b/L2c complete

[2025-10-07T06:16:13] tokens used: 63,890

[2025-10-07T06:16:15] thinking

**Checking fix_plan.md changes**
[2025-10-07T06:16:16] exec bash -lc "git show 0f3de26:docs/fix_plan.md | sed -n '448,520p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:16:17] bash -lc "git show 0f3de26:docs/fix_plan.md | sed -n '448,520p'" succeeded in 716ms:
## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
- Spec/AT: specs/spec-a-cli.md flag catalogue, docs/architecture/detector.md §5 (pix0 workflow), docs/development/c_to_pytorch_config_map.md (pivot rules), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860
- Priority: High
- Status: in_progress (Phases A–H complete; K3a/K3b/K3d landed via Attempts #43–44, pending per-φ evidence + normalization closure)
- Owner/Date: ralph/2025-10-05
- Plan Reference: `plans/active/cli-noise-pix0/plan.md`
- Reproduction (C & PyTorch):
  * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
  * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
- Next Actions (2025-11-13 refresh):
  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
- Attempts History:
  * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
    Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:1-41` - Refreshed trace with live values (polar=0.91464138, omega_pixel=4.20404859e-07 sr, F_cell=0, I_before_scaling=0)
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1-54` - Phase L2c comparison report showing first divergence and all divergent factors
[2025-10-07T06:16:17] tokens used: 65,168

[2025-10-07T06:16:36] thinking

**Analyzing plan and commit alignment**

I'm reviewing recent commits and the fix_plan to see whether progress like hooking hkl_data is properly reflected. It looks like the fix_plan’s “Next Actions” still mentions tasks already done, so I need to update it to match the current project state, marking Phase L2b as done and outlining next steps for L3. I’m also cross-checking numerical results related to scaling issues to verify if underlying problems like zero F_cell are resolved or still present.
[2025-10-07T06:16:38] exec bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:16:39] bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log' succeeded in 921ms:
TRACE_PY: pix0_vector_meters -0.216475710272789 0.216343179345131 -0.230195268988609
TRACE_PY: fdet_vec 0.999981999397278 -0.00599800003692508 -0.000118000003567431
TRACE_PY: sdet_vec -0.00599800003692508 -0.999970018863678 -0.0049129999242723
TRACE_PY: pixel_pos_meters -0.0383921265602112 0.0973683074116707 -0.230795636773109
TRACE_PY: R_distance_meters 0.253418952226639
TRACE_PY: omega_pixel_sr 4.20404859369228e-07
TRACE_PY: close_distance_meters 0.231274679303169
TRACE_PY: obliquity_factor 0.912617921829224
TRACE_PY: diffracted_vec -0.151496648788452 0.384218692779541 -0.910727560520172
TRACE_PY: incident_vec 0.000513879465870559 0 -0.99999988079071
TRACE_PY: lambda_meters 9.7680002450943e-11
TRACE_PY: lambda_angstroms 0.97680002450943
TRACE_PY: scattering_vec_A_inv -1556209280 3933442816 913926272
TRACE_PY: rot_a_angstroms -14.3562698364258 -21.8717937469482 -5.58202123641968
TRACE_PY: rot_b_angstroms -11.4986982345581 0.717319786548615 -29.1132164001465
TRACE_PY: rot_c_angstroms 21.0699501037598 -24.3892974853516 -9.75265312194824
TRACE_PY: rot_a_star_A_inv -0.0290510933846235 -0.0293958801776171 0.010749876499176
TRACE_PY: rot_b_star_A_inv -0.00312639237381518 0.0104376431554556 -0.0328566692769527
TRACE_PY: rot_c_star_A_inv 0.0259604379534721 -0.0143330143764615 -0.0106066130101681
TRACE_PY: hkl_frac -6.87916421890259 -0.589141607284546 -13.763635635376
[2025-10-07T06:16:39] tokens used: 67,912

[2025-10-07T06:16:45] thinking

**Analyzing zero structure factor issue**

I’m sorting through why F_cell remains zero despite recent changes, suspecting it stems from mismatches between reflection coordinates and available HKL data. I’ll verify if the scaling and reflection ranges align by checking logs and adjust the plan based on what I find.
[2025-10-07T06:16:45] exec bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:16:46] bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log' succeeded in 708ms:
WARNING: auto-generating odet_vector
nanoBragg nanocrystal diffraction simulator - James Holton and Ken Frankel 5-17-17
custom convention selected.
pivoting detector around sample
TRACE_C:detector_convention=CUSTOM
TRACE_C:angles_rad=rotx:0 roty:0 rotz:0 twotheta:0
TRACE_C:beam_center_m=Xclose:0.000211818 Yclose:0.000217322 pixel_mm:0.172
TRACE_C:initial_fdet=0.999982004873912 -0.00599800002923425 -0.000118000000575132
TRACE_C:initial_sdet=-0.0059979996566955 -0.999969942765222 -0.0049129997187971
TRACE_C:initial_odet=-8.85282813644494e-05 0.00491361907271126 -0.999987924182263
TRACE_C:Fclose_m=0.217742295
TRACE_C:Sclose_m=0.21390708
TRACE_C:close_distance_m=0.231271826111781
TRACE_C:ratio=0.999987746654913
TRACE_C:distance_m=0.23127466
TRACE_C:term_fast_before_rot=-0.217738376699947 0.00130601829177553 2.56935909352306e-05
TRACE_C:term_slow_before_rot=0.00128301459240474 0.213900650544676 0.00105092542388871
TRACE_C:term_close_before_rot=-2.04740972936938e-05 0.00113638165576361 -0.231269033315361
TRACE_C:pix0_before_rotation=-0.216475836204836 0.216343050492215 -0.230192414300537
TRACE_C:pix0_after_rotz=-0.216475836204836 0.216343050492215 -0.230192414300537
[2025-10-07T06:16:46] tokens used: 69,961

[2025-10-07T06:17:12] thinking

**Detailing plan updates for structure factor issue**

I'm outlining necessary plan and documentation updates to address the zero F_cell problem due to structure factor retrieval, focusing on adjusting phase statuses, adding new subtasks to Phase L3, and revising next actions in relevant docs to align with the Parity mode and CLI-FLAGS-003 focus.
[2025-10-07T06:17:13] exec bash -lc 'rg "Attempt #74" -n docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:17:14] bash -lc 'rg "Attempt #74" -n docs/fix_plan.md' succeeded in 921ms:
489:  * [2025-10-07] Attempt #74 (ralph loop) — Result: **SUCCESS** (Phase L2b harness fix + L2c comparison complete). **Corrected harness to attach `crystal.hkl_data` and `crystal.hkl_metadata` instead of ad-hoc attributes; structure factor lookup now functional.**
513:    Next Actions: **[COMPLETED in Attempt #74]** Patch harness to attach HKL grid + metadata, rerun the L2b trace capture, update `scaling_audit_summary.md`, then resume L2c normalization analysis.
[2025-10-07T06:17:14] tokens used: 75,553

[2025-10-07T06:17:16] thinking

**Reviewing previous attempt reference**
[2025-10-07T06:17:17] exec bash -lc "sed -n '476,520p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:17:18] bash -lc "sed -n '476,520p' docs/fix_plan.md" succeeded in 707ms:
  * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
    Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py:159-161` - Fixed MOSFLM vector assignment (mosflm_a_star, mosflm_b_star, mosflm_c_star as separate tensors)
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1-76` - Updated L2c comparison report confirming first divergence at I_before_scaling
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` - Regenerated trace showing live polarization and omega values
    Observations/Hypotheses:
      - **Fix confirmed:** Switching from `mosflm_a_star=[a*, b*, c*]` (list) to individual tensor assignments (mosflm_a_star=tensor(a*), mosflm_b_star=tensor(b*), mosflm_c_star=tensor(c*)) enables Crystal.compute_cell_tensors to use the MOSFLM orientation properly
      - **F_latt now non-zero:** Lattice shape factors are computed correctly (F_latt_a=-2.405, F_latt_b=-0.861, F_latt_c=0.652, product=1.351)
      - **F_cell still zero:** This is expected—pixel (685,1039) computes h=-7,k=-1,l=-14 but scaled.hkl only contains (1,12,3), so structure factor lookup correctly returns 0
      - **Scaling factors verified:** All intermediate scaling terms (r_e², fluence, steps, capture_fraction, polar, omega_pixel) match C within tolerance (Δ<0.002%)
      - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants (4/4)
    Next Actions: Phase L2b complete; L2c evidence captured. Supervisor to proceed with Phase L3 structure-factor investigation based on comparison summary showing I_before_scaling as first divergence.
  * [2025-10-07] Attempt #74 (ralph loop) — Result: **SUCCESS** (Phase L2b harness fix + L2c comparison complete). **Corrected harness to attach `crystal.hkl_data` and `crystal.hkl_metadata` instead of ad-hoc attributes; structure factor lookup now functional.**
    Metrics: Harness probe confirms hkl_data attached (lookup returns F=100 for (1,12,3), F=0 for out-of-range). Comparison identifies I_before_scaling as first divergence. Test suite passes 4/4 variants (tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics).
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py:233-236` — Fixed HKL attachment (crystal.hkl_data = F_grid_tensor, crystal.hkl_metadata = hkl_metadata)
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state_fixed.txt` — Post-fix verification showing hkl_data/metadata properly attached
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` — Refreshed trace with functional HKL lookup
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1-54` — L2c comparison showing all scaling factors match C (r_e², fluence, steps, polar, omega all <0.002% delta)
[2025-10-07T06:17:18] tokens used: 75,883

[2025-10-07T06:17:29] thinking

**Clarifying next steps and data discrepancies**

I’m sorting out the Next Actions since some steps seem outdated despite success on attempt #74. The key issue is the unexpected zero in `Crystal.get_structure_factor` for a certain pixel, likely related to the contents of `scaled.hkl` and its handling of negative indices. I want to confirm the actual reflections in `scaled.hkl` by inspecting its lines to ensure this difference is understood and addressed.
[2025-10-07T06:17:30] exec bash -lc 'head -n 5 scaled.hkl' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:17:31] bash -lc 'head -n 5 scaled.hkl' succeeded in 896ms:
1 12 3 100.0
[2025-10-07T06:17:31] tokens used: 79,047

[2025-10-07T06:17:33] thinking

**Checking for additional reflections**
[2025-10-07T06:17:33] exec bash -lc 'wc -l scaled.hkl' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:17:34] bash -lc 'wc -l scaled.hkl' succeeded in 721ms:
       1 scaled.hkl
[2025-10-07T06:17:34] tokens used: 79,226

[2025-10-07T06:17:41] thinking

**Investigating reflection discrepancy**

I’m trying to figure out why the structure factor amplitude is 190 for a reflection not in the `scaled.hkl` file, which only has one reflection. It seems like the program might be interpolating or using fallback data like `Fdump.bin`. I’ll check the directory for any `Fdump` files to confirm if they influence the computation.
[2025-10-07T06:17:42] exec bash -lc 'ls Fdump*' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:17:43] bash -lc 'ls Fdump*' exited 1 in 690ms:
ls: Fdump*: No such file or directory
[2025-10-07T06:17:43] tokens used: 79,694

[2025-10-07T06:17:45] thinking

**Considering test output artifacts**
[2025-10-07T06:17:46] exec bash -lc "find . -maxdepth 1 -name 'Fdump.bin'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:17:47] bash -lc "find . -maxdepth 1 -name 'Fdump.bin'" succeeded in 686ms:

[2025-10-07T06:17:47] tokens used: 79,901

[2025-10-07T06:17:59] thinking

**Analyzing discrepancy in F_cell values**

I'm trying to understand why the `F_cell` value is around 190 despite only one reflection being present in the HKL file and the `-nointerpolate` flag being set, which should use direct HKL values without interpolation. There might be differences in how the C program and the Python harness handle background, default values, or grid extents. I’ll plan to verify if the C run produces an Fdump file to match, and then inspect the Python `read_hkl_file` function to check how it processes single reflections into a grid, aiming to align the two approaches.
[2025-10-07T06:18:02] exec bash -lc "sed -n '1,200p' src/nanobrag_torch/io/hkl.py" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:18:03] bash -lc "sed -n '1,200p' src/nanobrag_torch/io/hkl.py" succeeded in 920ms:
"""
HKL file reader and Fdump binary cache for nanoBragg PyTorch.

Implements AT-STR-001, AT-STR-002, and AT-IO-003 from spec-a.md.
"""

import struct
from pathlib import Path
from typing import Tuple, Optional

import torch
import numpy as np


def read_hkl_file(
    filepath: str,
    default_F: float = 0.0,
    device=None,
    dtype=torch.float32
) -> Tuple[torch.Tensor, dict]:
[2025-10-07T06:18:03] tokens used: 80,942

[2025-10-07T06:18:14] thinking

**Analyzing reflection data discrepancies**
[2025-10-07T06:18:15] exec bash -lc "find . -name 'scaled.hkl' -print" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:18:16] bash -lc "find . -name 'scaled.hkl' -print" succeeded in 1.22s:
./scaled.hkl
[2025-10-07T06:18:16] tokens used: 83,758

[2025-10-07T06:18:55] thinking

**Revising plan for structure factor mismatch**

I'm preparing detailed updates to the plan and fix_plan files to address the mismatch in structure factor calculations between the Python and C code, focusing on verifying and reproducing the C code's F_cell values for specific reflections. This involves adding new analysis steps, reorganizing Phase L tasks, updating documentation, and ensuring the plan aligns with the latest commit insights and datasets.
[2025-10-07T06:18:57] exec bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_baseline.log' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:18:58] bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_baseline.log' succeeded in 940ms:
TRACE_PY: pix0_vector_meters -0.216475710272789 0.216343179345131 -0.230195268988609
TRACE_PY: fdet_vec 0.999981999397278 -0.00599800003692508 -0.000118000003567431
TRACE_PY: sdet_vec -0.00599800003692508 -0.999970018863678 -0.0049129999242723
TRACE_PY: pixel_pos_meters -0.0383921265602112 0.0973683074116707 -0.230795636773109
TRACE_PY: R_distance_meters 0.253418952226639
TRACE_PY: omega_pixel_sr 4.20404859369228e-07
TRACE_PY: close_distance_meters 0.231274679303169
TRACE_PY: obliquity_factor 0.912617921829224
TRACE_PY: diffracted_vec -0.151496648788452 0.384218692779541 -0.910727560520172
TRACE_PY: incident_vec 0.000513879465870559 0 -0.99999988079071
TRACE_PY: lambda_meters 9.7680002450943e-11
TRACE_PY: lambda_angstroms 0.97680002450943
TRACE_PY: scattering_vec_A_inv -1556209280 3933442816 913926272
TRACE_PY: rot_a_angstroms -14.3562698364258 -21.8717937469482 -5.58202123641968
TRACE_PY: rot_b_angstroms -11.4986982345581 0.717319786548615 -29.1132164001465
TRACE_PY: rot_c_angstroms 21.0699501037598 -24.3892974853516 -9.75265312194824
TRACE_PY: rot_a_star_A_inv -0.0290510933846235 -0.0293958801776171 0.010749876499176
TRACE_PY: rot_b_star_A_inv -0.00312639237381518 0.0104376431554556 -0.0328566692769527
TRACE_PY: rot_c_star_A_inv 0.0259604379534721 -0.0143330143764615 -0.0106066130101681
TRACE_PY: hkl_frac -6.87916421890259 -0.589141607284546 -13.763635635376
[2025-10-07T06:18:58] tokens used: 86,520

[2025-10-07T06:19:02] thinking

**Investigating data discrepancies**
[2025-10-07T06:19:02] exec bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state_fixed.txt' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:03] bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state_fixed.txt' succeeded in 699ms:
POST-FIX HKL State Verification (Attempt #74)
=============================================

After Phase L2b harness fix (attaching hkl_data and hkl_metadata):

hkl_data is None? False
hkl_metadata is None? False
h_range: (1, 1)
k_range: (12, 12)
l_range: (3, 3)

Structure factor lookups:
- (1,12,3): F=100.0 ✅ (correct - matches scaled.hkl)
- (-7,-1,-14): F=0.0 ✅ (correct - out of range)

Pixel (685,1039) maps to h≈-7, k≈-1, l≈-14, so F_cell=0 is expected behavior.
This confirms the harness fix is working correctly.
[2025-10-07T06:19:03] tokens used: 87,610

[2025-10-07T06:19:08] thinking

**Investigating data mismatch in scaled.hkl usage**
[2025-10-07T06:19:08] exec bash -lc "find reports/2025-10-cli-flags -name 'scaled.hkl' -print" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:09] bash -lc "find reports/2025-10-cli-flags -name 'scaled.hkl' -print" succeeded in 705ms:

[2025-10-07T06:19:09] tokens used: 88,194

[2025-10-07T06:19:13] thinking

**Investigating default structure factor values**
[2025-10-07T06:19:14] exec bash -lc 'rg "default_F" -n golden_suite_generator/nanoBragg.c | head' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:15] bash -lc 'rg "default_F" -n golden_suite_generator/nanoBragg.c | head' succeeded in 717ms:
329:    double default_F=0.0;
986:            if(strstr(argv[i], "-default_F") && (argc > (i+1)))
988:                default_F = atof(argv[i+1]);
1301:        if(Fdumpfile == NULL && default_F == 0.0)
1307:    if(hklfilename == NULL && Fdumpfile == NULL && default_F == 0.0 || matfilename == NULL && a[0] == 0.0){
1315:        printf("\t-default_F       \talternative to -hkl: assign all unspecified structure factors (default: 0)\n");
2381:            if(default_F == 0.0)
2439:        if(default_F != 0.0) {
2440:            printf("initializing to default_F = %g:\n",default_F);
2444:                        Fhkl[h0][k0][l0] = default_F;
[2025-10-07T06:19:15] tokens used: 88,759

[2025-10-07T06:19:20] thinking

**Investigating log file details**
[2025-10-07T06:19:21] exec bash -lc 'rg "scaled" -n reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:22] bash -lc 'rg "scaled" -n reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log' succeeded in 713ms:
110:counting entries in scaled.hkl
111:re-reading scaled.hkl
[2025-10-07T06:19:22] tokens used: 89,750

[2025-10-07T06:19:24] thinking

**Checking for Fdump references**
[2025-10-07T06:19:25] exec bash -lc 'rg "Fdump" reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:26] bash -lc 'rg "Fdump" reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log' succeeded in 684ms:
writing dump file for next time: Fdump.bin
[2025-10-07T06:19:26] tokens used: 90,016

[2025-10-07T06:19:28] thinking

**Searching for Fdump files**
[2025-10-07T06:19:29] exec bash -lc "find . -name 'Fdump.bin'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:30] bash -lc "find . -name 'Fdump.bin'" succeeded in 973ms:
./golden_suite_generator/Fdump.bin
./tmp/Fdump.bin
[2025-10-07T06:19:30] tokens used: 90,272

[2025-10-07T06:19:39] thinking

**Analyzing Fdump and scaled.hkl files**

I'm investigating how Fdump.bin under golden_suite_generator and tmp relates to scaled.hkl, considering that reading scaled.hkl might show only one reflection in a truncated file but Fdump could hold the full grid. I want to verify the true size and line count of scaled.hkl, since line ending differences might mislead wc and head commands, and check log details on h_min/h_max to understand data coverage.
[2025-10-07T06:19:42] exec bash -lc 'ls -l scaled.hkl' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:42] bash -lc 'ls -l scaled.hkl' succeeded in 790ms:
-rw-r--r--  1 ollie  staff  13 Oct  6 22:46 scaled.hkl
[2025-10-07T06:19:42] tokens used: 90,856

[2025-10-07T06:19:45] thinking

**Checking file size details**
[2025-10-07T06:19:46] exec bash -lc 'ls -l golden_suite_generator/Fdump.bin tmp/Fdump.bin' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:19:47] bash -lc 'ls -l golden_suite_generator/Fdump.bin tmp/Fdump.bin' succeeded in 687ms:
-rw-r--r--  1 ollie  staff   229 Oct  1 10:04 golden_suite_generator/Fdump.bin
-rw-r--r--  1 ollie  staff  1744 Oct  1 10:04 tmp/Fdump.bin
[2025-10-07T06:19:47] tokens used: 91,831

[2025-10-07T06:20:03] thinking

**Analyzing F_cell discrepancy and updating plan**

I'm piecing together how C computes F_cell and suspect interpolation or symmetry effects might explain discrepancies. To clarify, I plan to run C with matching commands to generate and inspect Fdump data, then update the project plan and documentation with these new tasks and insights, carefully preserving historical logs while adding notes referencing the updated understanding.
[2025-10-07T06:20:05] exec bash -lc "sed -n '180,320p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:20:06] bash -lc "sed -n '180,320p' plans/active/cli-noise-pix0/plan.md" succeeded in 864ms:
| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| J1 | Capture single-pixel scaling traces | [D] | ✅ 2025-10-19: C trace (`trace_c_scaling.log`) and PyTorch trace (`trace_py_scaling.log`) captured for pixel (1039,685) with full scaling chain (`steps`, `I_before_scaling`, `r_e²`, `fluence`, `polar`, `omega`). |
| J2 | Compute factor-by-factor ratios | [D] | ✅ 2025-10-19: `analyze_scaling.py` created and executed; identifies first divergence as `I_before_scaling` with Py/C ratio=3.6e-7. Root cause: F_latt components differ by ~463× (C: 35636 vs PyTorch: 76.9). Markdown report at `scaling_chain.md`. |
| J3 | Update fix_plan Attempt log | [D] | ✅ 2025-10-19: Attempt #28 logged in `docs/fix_plan.md` with complete metrics, artifacts, and hypothesis (F_latt calculation error in sincg lattice shape factor). Phase I3 remains blocked pending Phase K F_latt fix. |

### Phase K — Normalization Implementation
Goal: Align PyTorch normalization logic with C based on Phase J evidence (steps division, fluence, r_e², omega/polarization application order).
Prereqs: Phase J report pinpoints the mismatched factor; existing regression suite green.
Exit Criteria: Code changes merged with targeted tests covering the corrected scaling, and docs/fix_plan.md records Attempt #29 metrics before moving to Phase L.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| K1 | Align lattice factor math with C (SQUARE case) | [D] | ✅ 2025-10-24 Attempt #34 (commit 0fef8f7). `Simulator._compute_physics_for_position` now uses `sincg(torch.pi * h, Na)` with embedded C-code reference; regression `tests/test_cli_scaling.py::test_f_latt_square_matches_c` added (skips unless `NB_RUN_PARALLEL=1`). |
| K2 | Recompute scaling chain & extend diagnostics | [D] | ✅ 2025-10-06 Attempt #42. Fresh PyTorch trace captured (trace_py_after.log); scaling chain refreshed showing F_latt_b=46.98 (Py) vs 38.63 (C) = 21.6% error, polar=1.0 (Py) vs 0.913 (C) = 9.6% error. Updated scaling_chain.md with post-SAMPLE-pivot ratios. |
| K2b | Document MOSFLM rescale mismatch | [D] | ✅ 2025-10-06 Attempt #42. Created mosflm_rescale.py and orientation_delta.md. Finding: C skips vector_rescale when `user_cell==0`, but PyTorch still rescales, leading to persistent F_latt_b drift. |
| K3a | Guard MOSFLM rescale path in `Crystal.compute_cell_tensors` | [D] | ✅ 2025-11-06 Attempt #43 (`a89f6fd`): added `mosflm_provided` guard; `mosflm_rescale.py` now reports Δa/b/c=0.0 Å against C (`orientation_delta.md`). |
| K3b | Realign polarization defaults with C | [D] | ✅ 2025-11-06 Attempt #43: `BeamConfig.polarization_factor` defaults to 0.0; CLI regression updated; scaling harness will be re-run once K3e/K3f land. |
| K3d | Diagnose dtype sensitivity of F_latt | [D] | ✅ 2025-11-06 Attempt #44 (`271e2b6`): float64 sweep stored under `phase_k/f_latt_fix/dtype_sweep/` proved precision is not the culprit (F_latt_b error persists at 93.98%). |
| K3c | Regression & documentation close-out | [ ] | `env KMP_DUPLICATE_LIB_OK=TRUE NB_RUN_PARALLEL=1 pytest tests/test_cli_scaling.py::test_f_latt_square_matches_c -v` plus any new normalization tests. Save log as `phase_k/f_latt_fix/pytest_post_fix.log`, update `docs/architecture/pytorch_design.md` normalization notes and `docs/development/testing_strategy.md`, then record Attempt #43 with metrics and artifacts. |
[2025-10-07T06:20:06] tokens used: 92,862

[2025-10-07T06:20:09] thinking

**Scrolling further in changelog**
[2025-10-07T06:20:10] exec bash -lc "sed -n '320,520p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:20:10] bash -lc "sed -n '320,520p' plans/active/cli-noise-pix0/plan.md" succeeded in 719ms:

[2025-10-07T06:20:10] tokens used: 94,595

[2025-10-07T06:20:13] thinking

**Noticing incomplete plan and seeking more**
[2025-10-07T06:20:14] exec bash -lc 'rg -n "Phase L" plans/active/cli-noise-pix0/plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:20:14] bash -lc 'rg -n "Phase L" plans/active/cli-noise-pix0/plan.md' succeeded in 702ms:
10:- Gap snapshot update (2025-10-27): Attempt #41 validated Phase H6g — SAMPLE pivot parity holds with pix0 deltas ≤2.85 µm, beam center deltas 0.0, and supporting artifacts under `reports/2025-10-cli-flags/phase_h6/post_fix/`. Remaining blockers: rerun the scaling chain (Phase K2), execute the scaling regression + doc updates (Phase K3), then resume Phase L parity once normalization matches C.
11:- Gap snapshot refresh (2025-11-09): Attempt #49 closed Phase K3g3 — `tests/test_cli_scaling.py::test_f_latt_square_matches_c` now passes after isolating the HKL cache, but the full supervisor command still shows correlation ≈ 0.9965 and sum_ratio ≈ 1.26×10⁵. Need fresh HKL/normalization parity evidence (Phase L) before rerunning nb-compare.
12:- Gap snapshot refresh (2025-11-10): Attempt #56 (evidence loop) proved the existing `TRACE_PY` path prints placeholder scaling data (`capture_fraction 1`, `polar 1.0`, `steps`=φ-steps only). Without exposing the real per-pixel factors computed in `Simulator.run`, Phase L2b cannot produce a trustworthy PyTorch trace. Instrumentation must pull actual values from `_apply_detector_absorption`, polarization kernels, and total-step calculation before rerunning the harness.
13:- Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
15:- Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
16:- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
17:- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
18:- Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
19:- Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
189:Exit Criteria: Code changes merged with targeted tests covering the corrected scaling, and docs/fix_plan.md records Attempt #29 metrics before moving to Phase L.
224:### Phase L — Supervisor Command Normalization
234:| L1d | Re-run parity script after fixes and update artefacts | [D] | ✅ Attempt #54 (2025-10-17): Regenerated C cache using supervisor command flags, achieved perfect HKL parity (max |ΔF|=0.0, 0 mismatches). Artifacts: `reports/2025-10-cli-flags/phase_l/hkl_parity/{Fdump_c_20251109.bin, summary_20251109.md, metrics_20251109.json}`. Phase L2 prerequisites now met—structure factors match C exactly. |
236:### Phase L2 — Scaling Chain Audit
238:Prereqs: Phase L1d artifacts in place; Ralph working under `prompts/debug.md`; C binary instrumentable via `golden_suite_generator/` per CLAUDE Rule #0.3.
247:### Phase L3 — Normalization Fix Implementation
259:### Phase L4 — Supervisor Command Parity Rerun
[2025-10-07T06:20:14] tokens used: 95,014

[2025-10-07T06:20:18] thinking

**Opening Phase L tables**
[2025-10-07T06:20:20] exec bash -lc "sed -n '224,360p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:20:21] bash -lc "sed -n '224,360p' plans/active/cli-noise-pix0/plan.md" succeeded in 712ms:
### Phase L — Supervisor Command Normalization
Goal: Isolate and resolve the 1.26×10⁵ intensity mismatch that persists when running the full supervisor command after Phase K fixes.
Prereqs: Phase K3g artifacts refreshed (Attempt #49), nb-compare data in `phase_k/f_latt_fix/post_fix/`, instrumentation from Phase J available.
Exit Criteria: Structure-factor grids, scaling chain, and final intensities match C within thresholds (|Δh|,|Δk|,|Δl| < 5e-4; sum_ratio 0.99–1.01; mean_peak_distance ≤ 1 px); nb-compare rerun archived under `phase_l/supervisor_command/`; docs/fix_plan Attempt log updated; plan ready for archival.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| L1a | Run HKL ↔ Fdump parity script and capture metrics | [D] | Attempt #50 (2025-10-06) produced `summary_20251006175032.md` / `metrics_20251006175032.json`; this loop repeated the run with `Fdump_scaled_20251006175946.bin`, confirming max |ΔF|=5.22e2, 99,209 mismatched voxels, and storing `c_fdump_20251006175946.log`. Artefacts live under `reports/2025-10-cli-flags/phase_l/hkl_parity/`. |
| L1b | Diagnose binary-layout mismatch between HKL and Fdump | [D] | ✅ Attempt #52 (2025-10-06) produced `scripts/validation/analyze_fdump_layout.py` plus `reports/2025-10-cli-flags/phase_l/hkl_parity/layout_analysis.md`. Confirmed nanoBragg writes `(h_range+2)×(k_range+2)×(l_range+2)` voxels via `for(h0=0; h0<=h_range; h0++)` loops (see `nanoBragg.c:2400-2486`), leaving 9,534 zero-padded entries. PyTorch reader must drop the padded plane per axis. |
| L1c | Align PyTorch HKL cache reader/writer with confirmed layout | [D] | ✅ Attempt #53 (2025-10-17): Updated `src/nanobrag_torch/io/hkl.py` to honour `(range+1)` padding, added C-code docstring quotes per Rule #11, and introduced `tests/test_cli_flags.py::TestHKLFdumpParity::test_scaled_hkl_roundtrip` (max |ΔF| = 0.0, mismatches = 0). |
| L1d | Re-run parity script after fixes and update artefacts | [D] | ✅ Attempt #54 (2025-10-17): Regenerated C cache using supervisor command flags, achieved perfect HKL parity (max |ΔF|=0.0, 0 mismatches). Artifacts: `reports/2025-10-cli-flags/phase_l/hkl_parity/{Fdump_c_20251109.bin, summary_20251109.md, metrics_20251109.json}`. Phase L2 prerequisites now met—structure factors match C exactly. |

### Phase L2 — Scaling Chain Audit
Goal: Capture a side-by-side breakdown of the intensity scaling pipeline (I_before_scaling → ω → polarization → r_e² → fluence → steps) for the supervisor command to isolate the first divergence that drives the 1.26×10⁵ sum ratio.
Prereqs: Phase L1d artifacts in place; Ralph working under `prompts/debug.md`; C binary instrumentable via `golden_suite_generator/` per CLAUDE Rule #0.3.
Exit Criteria: C and PyTorch traces capturing scaling factors are stored under `reports/2025-10-cli-flags/phase_l/scaling_audit/`, a comparison summary identifies the first mismatched term with quantitative deltas, and docs/fix_plan.md Attempt log references the findings.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
[2025-10-07T06:20:21] tokens used: 96,402

[2025-10-07T06:20:39] thinking

**Revising task rows and plan structure**
[2025-10-07T06:20:44] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/plans/active/cli-noise-pix0/plan.md
@@ -243,4 +243,4 @@
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
[2025-10-07T06:20:44] apply_patch(auto_approved=true) exited 0 in 9ms:
Success. Updated the following files:
M plans/active/cli-noise-pix0/plan.md
[2025-10-07T06:20:44] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..d2b60734268d5a9c229c6026a26826ae147203a5
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.

[2025-10-07T06:20:44] tokens used: 101,240
[2025-10-07T06:20:44] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..d2b60734268d5a9c229c6026a26826ae147203a5
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.


[2025-10-07T06:20:48] thinking

**Ensuring consistent table row endings**
[2025-10-07T06:20:49] exec bash -lc "sed -n '252,270p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:20:50] bash -lc "sed -n '252,270p' plans/active/cli-noise-pix0/plan.md" succeeded in 950ms:
| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |

### Phase L4 — Supervisor Command Parity Rerun
Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.
Prereqs: L3 validation artifacts show ≤1e-6 deltas for scaling factors; regression tests green.
Exit Criteria: nb-compare metrics meet thresholds, artifacts stored under `reports/2025-10-cli-flags/phase_l/supervisor_command_rerun/`, docs/fix_plan.md Attempt #56 documents the pass, and this plan is ready for archival.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| L4a | Rerun supervisor command parity | [ ] | Execute the authoritative command from `reports/2025-10-cli-flags/phase_i/supervisor_command/README.md`, writing outputs to a new timestamped directory. Capture `summary.json`, stdout/stderr, and SHA256 hashes. |
| L4b | Analyze results & log attempt | [ ] | Update `supervisor_command_rerun/README.md` with metrics, confirm thresholds met, and log Attempt #56 in docs/fix_plan.md summarizing deltas. |
| L4c | Finalize documentation | [ ] | If parity passes, move key artifacts to `reports/archive/` per SOP, update plan status to ready-for-archive, and prepare closing notes for CLI-FLAGS-003. If parity fails, loop back to L2 with findings. |
[2025-10-07T06:20:50] tokens used: 102,301
[2025-10-07T06:20:50] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..d2b60734268d5a9c229c6026a26826ae147203a5
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.


[2025-10-07T06:20:53] thinking

**Reviewing table updates**
[2025-10-07T06:20:54] exec bash -lc "sed -n '236,252p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:20:54] bash -lc "sed -n '236,252p' plans/active/cli-noise-pix0/plan.md" succeeded in 714ms:
### Phase L2 — Scaling Chain Audit
Goal: Capture a side-by-side breakdown of the intensity scaling pipeline (I_before_scaling → ω → polarization → r_e² → fluence → steps) for the supervisor command to isolate the first divergence that drives the 1.26×10⁵ sum ratio.
Prereqs: Phase L1d artifacts in place; Ralph working under `prompts/debug.md`; C binary instrumentable via `golden_suite_generator/` per CLAUDE Rule #0.3.
Exit Criteria: C and PyTorch traces capturing scaling factors are stored under `reports/2025-10-cli-flags/phase_l/scaling_audit/`, a comparison summary identifies the first mismatched term with quantitative deltas, and docs/fix_plan.md Attempt log references the findings.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |

### Phase L3 — Normalization Fix Implementation
Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
Prereqs: L2 comparison summary pointing to the exact divergent factor; relevant C references documented; regression tests identified.
Exit Criteria: PyTorch source changes with inline C-code docstring references are merged, targeted regression tests cover the corrected scaling semantics, and new artifacts demonstrate matching intermediate values. docs/fix_plan.md records the fix attempt and resulting metrics.

| ID | Task Description | State | How/Why & Guidance |
[2025-10-07T06:20:54] tokens used: 103,143
[2025-10-07T06:20:54] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..d2b60734268d5a9c229c6026a26826ae147203a5
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.


[2025-10-07T06:20:57] thinking

**Cleaning table row formatting**
[2025-10-07T06:21:00] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/plans/active/cli-noise-pix0/plan.md
@@ -243,3 +243,3 @@
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. | 
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
 | L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
[2025-10-07T06:21:00] apply_patch(auto_approved=true) exited 0 in 26ms:
Success. Updated the following files:
M plans/active/cli-noise-pix0/plan.md
[2025-10-07T06:21:00] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..9a9bbc37f0ef88b070b0813bcdca6925385590c1
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.

[2025-10-07T06:21:00] tokens used: 104,329
[2025-10-07T06:21:00] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..9a9bbc37f0ef88b070b0813bcdca6925385590c1
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.


[2025-10-07T06:21:13] thinking

**Preparing new L3 task table**
[2025-10-07T06:21:25] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/plans/active/cli-noise-pix0/plan.md
@@ -253,6 +253,8 @@
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
[2025-10-07T06:21:25] apply_patch(auto_approved=true) exited 0 in 20ms:
Success. Updated the following files:
M plans/active/cli-noise-pix0/plan.md
[2025-10-07T06:21:25] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..a383ef842cce5763f08a5132600ddee55024700a
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +251,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:21:25] tokens used: 106,778
[2025-10-07T06:21:25] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..a383ef842cce5763f08a5132600ddee55024700a
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +251,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:21:30] thinking

**Verifying task insertion**
[2025-10-07T06:21:31] exec bash -lc "sed -n '248,288p' plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:21:32] bash -lc "sed -n '248,288p' plans/active/cli-noise-pix0/plan.md" succeeded in 788ms:
Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
Prereqs: L2 comparison summary pointing to the exact divergent factor; relevant C references documented; regression tests identified.
Exit Criteria: PyTorch source changes with inline C-code docstring references are merged, targeted regression tests cover the corrected scaling semantics, and new artifacts demonstrate matching intermediate values. docs/fix_plan.md records the fix attempt and resulting metrics.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |

### Phase L4 — Supervisor Command Parity Rerun
Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.
Prereqs: L3 validation artifacts show ≤1e-6 deltas for scaling factors; regression tests green.
Exit Criteria: nb-compare metrics meet thresholds, artifacts stored under `reports/2025-10-cli-flags/phase_l/supervisor_command_rerun/`, docs/fix_plan.md Attempt #56 documents the pass, and this plan is ready for archival.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
[2025-10-07T06:21:32] tokens used: 108,322
[2025-10-07T06:21:32] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..a383ef842cce5763f08a5132600ddee55024700a
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -241,8 +241,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +251,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:21:37] thinking

**Updating context with new snapshot**
[2025-10-07T06:21:42] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/plans/active/cli-noise-pix0/plan.md
@@ -17,2 +17,3 @@
 - Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
[2025-10-07T06:21:42] apply_patch(auto_approved=true) exited 0 in 15ms:
Success. Updated the following files:
M plans/active/cli-noise-pix0/plan.md
[2025-10-07T06:21:42] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..c1e24704414365cea48de71a4b91ca9dcb58660f
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -15,6 +15,7 @@
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
 - Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
 - Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:21:42] tokens used: 110,372
[2025-10-07T06:21:42] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..c1e24704414365cea48de71a4b91ca9dcb58660f
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -15,6 +15,7 @@
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
 - Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
 - Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:21:48] thinking

**Updating outdated status lines**
[2025-10-07T06:21:52] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/plans/active/cli-noise-pix0/plan.md
@@ -15,4 +15,4 @@
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
 - Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
[2025-10-07T06:21:52] apply_patch(auto_approved=true) exited 0 in 16ms:
Success. Updated the following files:
M plans/active/cli-noise-pix0/plan.md
[2025-10-07T06:21:52] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:21:52] tokens used: 112,487
[2025-10-07T06:21:52] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:21:55] thinking

**Preparing to update documentation**
[2025-10-07T06:21:56] exec bash -lc "sed -n '448,476p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:21:57] bash -lc "sed -n '448,476p' docs/fix_plan.md" succeeded in 888ms:
## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
- Spec/AT: specs/spec-a-cli.md flag catalogue, docs/architecture/detector.md §5 (pix0 workflow), docs/development/c_to_pytorch_config_map.md (pivot rules), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860
- Priority: High
- Status: in_progress (Phases A–H complete; K3a/K3b/K3d landed via Attempts #43–44, pending per-φ evidence + normalization closure)
- Owner/Date: ralph/2025-10-05
- Plan Reference: `plans/active/cli-noise-pix0/plan.md`
- Reproduction (C & PyTorch):
  * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
  * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
- Next Actions (2025-11-13 refresh):
  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
- Attempts History:
  * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
    Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:1-41` - Refreshed trace with live values (polar=0.91464138, omega_pixel=4.20404859e-07 sr, F_cell=0, I_before_scaling=0)
      - `reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1-54` - Phase L2c comparison report showing first divergence and all divergent factors
[2025-10-07T06:21:57] tokens used: 113,765
[2025-10-07T06:21:57] turn diff:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:22:07] thinking

**Revising project documentation and next steps**

I’m updating the ‘First Divergence’ text to reflect the new insight about F_cell and restructuring the Next Actions list to match the L3 task plan. I’ll also add clarifying update notes to the Observations section to mark resolved issues while preserving historical records, making sure everything aligns cleanly with the new understanding.
[2025-10-07T06:22:15] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/docs/fix_plan.md
@@ -456,7 +456,7 @@
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
[2025-10-07T06:22:15] apply_patch(auto_approved=true) exited 0 in 23ms:
Success. Updated the following files:
M docs/fix_plan.md
[2025-10-07T06:22:15] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..87266ca170d0ca428d7eef601180a46a1e89c05c
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:22:15] tokens used: 116,515
[2025-10-07T06:22:15] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..87266ca170d0ca428d7eef601180a46a1e89c05c
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:22:19] thinking

**Updating observations for attempt #71**
[2025-10-07T06:22:23] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/docs/fix_plan.md
@@ -470,4 +470,4 @@
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
[2025-10-07T06:22:23] apply_patch(auto_approved=true) exited 0 in 24ms:
Success. Updated the following files:
M docs/fix_plan.md
[2025-10-07T06:22:23] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:22:23] tokens used: 118,001
[2025-10-07T06:22:23] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:22:27] thinking

**Aligning plans and analyzing data**

I'm making sure the updated plan and fix_plan stay consistent and ready to reference new tasks properly. Next, I'll check out the file `golden_suite_generator/Fdump.bin` by running a Python snippet to read the reflection amplitude values, which might be important for the summary and validation steps coming up.
[2025-10-07T06:22:32] exec bash -lc "python - <<'PY'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('golden_suite_generator/Fdump.bin', dtype=torch.float64)
h_min, k_min, l_min = meta['h_min'], meta['k_min'], meta['l_min']
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - h_min
k_idx = k_target - k_min
l_idx = l_target - l_min
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
if in_range:
    val = F_grid[h_idx, k_idx, l_idx].item()
    print('Fdump value for (-7,-1,-14):', val)
else:
    print('(-7,-1,-14) out of range; ranges:', meta)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:22:33] bash -lc "python - <<'PY'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('golden_suite_generator/Fdump.bin', dtype=torch.float64)
h_min, k_min, l_min = meta['h_min'], meta['k_min'], meta['l_min']
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - h_min
k_idx = k_target - k_min
l_idx = l_target - l_min
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
if in_range:
    val = F_grid[h_idx, k_idx, l_idx].item()
    print('Fdump value for (-7,-1,-14):', val)
else:
    print('(-7,-1,-14) out of range; ranges:', meta)
PY" exited 134 in 1.20s:
OMP: Error #15: Initializing libomp.dylib, but found libomp.dylib already initialized.
OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://openmp.llvm.org/
bash: line 16: 38075 Abort trap: 6              python - <<'PY'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('golden_suite_generator/Fdump.bin', dtype=torch.float64)
h_min, k_min, l_min = meta['h_min'], meta['k_min'], meta['l_min']
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - h_min
k_idx = k_target - k_min
l_idx = l_target - l_min
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
if in_range:
    val = F_grid[h_idx, k_idx, l_idx].item()
    print('Fdump value for (-7,-1,-14):', val)
else:
    print('(-7,-1,-14) out of range; ranges:', meta)
PY

[2025-10-07T06:22:33] tokens used: 119,002
[2025-10-07T06:22:33] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:22:39] thinking

**Setting environment variable before import**
[2025-10-07T06:22:42] exec bash -lc "python - <<'PY'
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('golden_suite_generator/Fdump.bin', dtype=torch.float64)
h_min, k_min, l_min = meta['h_min'], meta['k_min'], meta['l_min']
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - h_min
k_idx = k_target - k_min
l_idx = l_target - l_min
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
print('Ranges:', meta)
print('In range?', in_range)
if in_range:
    val = F_grid[h_idx, k_idx, l_idx].item()
    print('Fdump value for (-7,-1,-14):', val)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:22:43] bash -lc "python - <<'PY'
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('golden_suite_generator/Fdump.bin', dtype=torch.float64)
h_min, k_min, l_min = meta['h_min'], meta['k_min'], meta['l_min']
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - h_min
k_idx = k_target - k_min
l_idx = l_target - l_min
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
print('Ranges:', meta)
print('In range?', in_range)
if in_range:
    val = F_grid[h_idx, k_idx, l_idx].item()
    print('Fdump value for (-7,-1,-14):', val)
PY" succeeded in 1.62s:
Ranges: {'h_min': 0, 'h_max': 1, 'k_min': 0, 'k_max': 1, 'l_min': 0, 'l_max': 1, 'h_range': 2, 'k_range': 2, 'l_range': 2}
In range? False
[2025-10-07T06:22:43] tokens used: 120,693
[2025-10-07T06:22:43] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:22:47] thinking

**Investigating Fdump source discrepancy**
[2025-10-07T06:22:49] exec bash -lc "python - <<'PY'
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('tmp/Fdump.bin', dtype=torch.float64)
print('Ranges:', meta)
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - meta['h_min']
k_idx = k_target - meta['k_min']
l_idx = l_target - meta['l_min']
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
print('In range?', in_range)
if in_range:
    print('Value:', F_grid[h_idx, k_idx, l_idx].item())
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:22:51] bash -lc "python - <<'PY'
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import torch
from nanobrag_torch.io.hkl import read_fdump
F_grid, meta = read_fdump('tmp/Fdump.bin', dtype=torch.float64)
print('Ranges:', meta)
h_target, k_target, l_target = -7, -1, -14
h_idx = h_target - meta['h_min']
k_idx = k_target - meta['k_min']
l_idx = l_target - meta['l_min']
in_range = 0 <= h_idx < F_grid.shape[0] and 0 <= k_idx < F_grid.shape[1] and 0 <= l_idx < F_grid.shape[2]
print('In range?', in_range)
if in_range:
    print('Value:', F_grid[h_idx, k_idx, l_idx].item())
PY" succeeded in 1.49s:
Ranges: {'h_min': -2, 'h_max': 2, 'k_min': -2, 'k_max': 2, 'l_min': -2, 'l_max': 2, 'h_range': 5, 'k_range': 5, 'l_range': 5}
In range? False
[2025-10-07T06:22:51] tokens used: 121,668
[2025-10-07T06:22:51] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:22:57] thinking

**Examining C trace details and defaults**

I'm trying to understand why reflections like -7 are missing and where the C code gets its F_cell value, which might be influenced by default_F settings or interpolation flags. To clarify this, I’ll inspect the script that runs the C trace, especially the `run_c_trace.sh` file, to see if any default_F values are explicitly set.
[2025-10-07T06:23:00] exec bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/run_c_trace.sh' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:23:01] bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/run_c_trace.sh' exited 1 in 701ms:
cat: reports/2025-10-cli-flags/phase_l/scaling_audit/run_c_trace.sh: No such file or directory
[2025-10-07T06:23:01] tokens used: 123,142
[2025-10-07T06:23:01] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:23:04] thinking

**Checking base lattice directory**
[2025-10-07T06:23:05] exec bash -lc "find reports/2025-10-cli-flags -name 'run_c_trace.sh' -print" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:23:05] bash -lc "find reports/2025-10-cli-flags -name 'run_c_trace.sh' -print" succeeded in 720ms:
reports/2025-10-cli-flags/phase_k/base_lattice/run_c_trace.sh
[2025-10-07T06:23:05] tokens used: 123,717
[2025-10-07T06:23:05] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:23:08] thinking

**Checking audit command details**
[2025-10-07T06:23:09] exec bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/notes.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:23:10] bash -lc 'cat reports/2025-10-cli-flags/phase_l/scaling_audit/notes.md' succeeded in 704ms:
# Phase L2 Scaling Audit Notes

**Last Updated:** 2025-10-07 (Attempt #69, ralph loop)
**Status:** Phase L2b complete with live TRACE_PY data; ready for Phase L2c comparison

## Phase L2b Evidence Summary

### Harness Refresh (2025-10-07, Attempt #69)
- **Updated:** `trace_harness.py` now uses `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` and captures stdout via `contextlib.redirect_stdout`
- **Output:** `trace_py_scaling.log` contains 40 TRACE_PY lines with real computed values (no placeholders)
- **Verification:** `test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes 4/4 variants (cpu/cuda × float32/float64)

### Key Trace Values (Pixel 685, 1039)

From `trace_py_scaling.log`:

```
TRACE_PY: I_before_scaling 0
TRACE_PY: r_e_sqr 7.9407927259064e-30
TRACE_PY: fluence_photons_per_m2 1.00000001384843e+24
[2025-10-07T06:23:10] tokens used: 123,897
[2025-10-07T06:23:10] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:23:14] thinking

**Reviewing documentation and planning input file**
[2025-10-07T06:23:15] exec bash -lc 'git rev-parse --abbrev-ref HEAD' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:23:16] bash -lc 'git rev-parse --abbrev-ref HEAD' succeeded in 724ms:
feature/spec-based-2
[2025-10-07T06:23:16] tokens used: 125,087
[2025-10-07T06:23:16] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:23:29] thinking

**Organizing content for input.md compilation**
[2025-10-07T06:23:29] exec bash -lc "nl -ba plans/active/cli-noise-pix0/plan.md | sed -n '240,280p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:23:30] bash -lc "nl -ba plans/active/cli-noise-pix0/plan.md | sed -n '240,280p'" succeeded in 673ms:
   240	Exit Criteria: C and PyTorch traces capturing scaling factors are stored under `reports/2025-10-cli-flags/phase_l/scaling_audit/`, a comparison summary identifies the first mismatched term with quantitative deltas, and docs/fix_plan.md Attempt log references the findings.
   241	
   242	| ID | Task Description | State | How/Why & Guidance |
   243	| --- | --- | --- | --- |
   244	| L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
   245	| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
   246	| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
   247	
   248	### Phase L3 — Normalization Fix Implementation
   249	Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
   250	Prereqs: L2 comparison summary pointing to the exact divergent factor; relevant C references documented; regression tests identified.
   251	Exit Criteria: PyTorch source changes with inline C-code docstring references are merged, targeted regression tests cover the corrected scaling semantics, and new artifacts demonstrate matching intermediate values. docs/fix_plan.md records the fix attempt and resulting metrics.
   252	
   253	| ID | Task Description | State | How/Why & Guidance |
   254	| --- | --- | --- | --- |
   255	| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
   256	| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
   257	| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
   258	| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
   259	| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
[2025-10-07T06:23:30] tokens used: 126,077
[2025-10-07T06:23:30] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:23:32] exec bash -lc "nl -ba docs/fix_plan.md | sed -n '448,520p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:23:33] bash -lc "nl -ba docs/fix_plan.md | sed -n '448,520p'" succeeded in 710ms:
   448	## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
   449	- Spec/AT: specs/spec-a-cli.md flag catalogue, docs/architecture/detector.md §5 (pix0 workflow), docs/development/c_to_pytorch_config_map.md (pivot rules), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860
   450	- Priority: High
   451	- Status: in_progress (Phases A–H complete; K3a/K3b/K3d landed via Attempts #43–44, pending per-φ evidence + normalization closure)
   452	- Owner/Date: ralph/2025-10-05
   453	- Plan Reference: `plans/active/cli-noise-pix0/plan.md`
   454	- Reproduction (C & PyTorch):
   455	  * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   456	  * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
   457	- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
   458	- Next Actions (2025-11-15 refresh):
   459	  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
   460	  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
   461	  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
   462	- Attempts History:
   463	  * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
   464	    Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
   465	    Artifacts:
   466	      - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:1-41` - Refreshed trace with live values (polar=0.91464138, omega_pixel=4.20404859e-07 sr, F_cell=0, I_before_scaling=0)
   467	      - `reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1-54` - Phase L2c comparison report showing first divergence and all divergent factors
[2025-10-07T06:23:33] tokens used: 128,711
[2025-10-07T06:23:33] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..4a1b081065304bb63598bd6958849246c632eb15
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,8 +468,8 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
     Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:23:40] thinking

**Updating Next Actions note**
[2025-10-07T06:23:42] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/docs/fix_plan.md
@@ -474,3 +474,3 @@
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
[2025-10-07T06:23:42] apply_patch(auto_approved=true) exited 0 in 26ms:
Success. Updated the following files:
M docs/fix_plan.md
[2025-10-07T06:23:42] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:23:42] tokens used: 131,114
[2025-10-07T06:23:42] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:24:01] thinking

**Preparing detailed input.md plan**

I’m organizing a comprehensive input.md document focused on probing the supervisor pixel structure factor for Step 3.5. The plan includes clear sections like summary, mode, focus, artifacts, commands, priorities with references, pitfalls, and pointers. I’m also outlining a script to compute structure factors using existing harness functions while ensuring KMP environment settings and logging requirements are covered. The goal is to create a thorough memo about 100-200 lines long that guides running and troubleshooting this task effectively.
[2025-10-07T06:24:12] exec bash -lc "cat <<'EOF' > input.md
Summary: Probe the supervisor pixel’s structure-factor source so PyTorch can match C’s I_before_scaling.
Mode: Parity
Focus: CLI-FLAGS-003 › Phase L3a structure-factor verification
Branch: feature/spec-based-2
Mapped tests: none — evidence-only
Artifacts: reports/2025-10-cli-flags/phase_l/structure_factor/probe.log; reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md
Do Now: CLI-FLAGS-003 › Phase L3a Verify structure-factor coverage — author the probe noted below, then run "'`KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin`
If Blocked: Capture the failure mode (stdout/stderr, traceback) to `reports/2025-10-cli-flags/phase_l/structure_factor/blocked.md` and run `KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q tests/test_trace_pixel.py` to confirm imports still succeed.

Priorities & Rationale
- plans/active/cli-noise-pix0/plan.md:255 pinpoints L3a as the immediate blocker before any normalization edits.
- docs/fix_plan.md:457 shows C delivers `F_cell=190.27` where PyTorch returns zero; we must understand that ingestion gap first.
- reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1 documents that every downstream scaling factor already matches C, so focus stays on structure factors.
- specs/spec-a-cli.md:1 reminds us the CLI contract treats HKL/Fdump equivalently; parity depends on respecting that pipeline.

How-To Map
- Create `reports/2025-10-cli-flags/phase_l/structure_factor/` (if missing) and stage `probe.py` plus `README.md` describing the run context.
- Base the probe on `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py`: import `get_supervisor_params` so the Crystal/Detector configs remain identical to the supervisor command.
- For each data source (HKL text, C Fdump outputs), load tensors via `read_hkl_file` / `read_fdump` and assign `crystal.hkl_data` / `crystal.hkl_metadata` before calling `Crystal.get_structure_factor(torch.tensor([-7,-1,-14], dtype=dtype, device=device))`.
- Emit all intermediate context (ranges, presence of the target hkl, resulting amplitude) to stdout and to `probe.log` (use `tee` or file writes) so Phase L3b can build on the evidence.
- After running the command above, append a short comparison table to `analysis.md` summarizing HKL vs Fdump values and confirming whether either reproduces C’s 190.27 amplitude.

Pitfalls To Avoid
- Always set `KMP_DUPLICATE_LIB_OK=TRUE` before importing torch to avoid libomp crashes.
- Do not mutate production modules; keep the probe under `reports/` per tooling rules.
- Preserve device/dtype neutrality in the probe (respect the `--dtype` / `--device` flags if you add them; otherwise default to cpu/float64 for clarity).
- Avoid `.item()` on tensors that still require gradients in simulator paths; confine scalar extraction to the standalone probe outputs.
- Leave Protected Assets untouched (see docs/index.md for allowlist) while staging new artifacts.
- Keep vectorization intact; no Python loops over HKL slices in simulator code until after L3 planning.
- Record every command run (exact CLI + git SHA) in the artifact README to maintain reproducibility.

Pointers
- docs/fix_plan.md:448 for the refreshed Next Actions and divergence summary.
- plans/active/cli-noise-pix0/plan.md:253 for the detailed Phase L3 task list.
- reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log:137 for the C-side `F_cell=190.27` reference.
- reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:21 for the current PyTorch `F_cell=0` observation.

Next Up (if time remains)
- Start Phase L3b analysis: diff the newly captured probe data against C’s Fdump layout and outline the ingestion strategy before touching simulator code.
EOF
' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:24:13] bash -lc "cat <<'EOF' > input.md
Summary: Probe the supervisor pixel’s structure-factor source so PyTorch can match C’s I_before_scaling.
Mode: Parity
Focus: CLI-FLAGS-003 › Phase L3a structure-factor verification
Branch: feature/spec-based-2
Mapped tests: none — evidence-only
Artifacts: reports/2025-10-cli-flags/phase_l/structure_factor/probe.log; reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md
Do Now: CLI-FLAGS-003 › Phase L3a Verify structure-factor coverage — author the probe noted below, then run "'`KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin`
If Blocked: Capture the failure mode (stdout/stderr, traceback) to `reports/2025-10-cli-flags/phase_l/structure_factor/blocked.md` and run `KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q tests/test_trace_pixel.py` to confirm imports still succeed.

Priorities & Rationale
- plans/active/cli-noise-pix0/plan.md:255 pinpoints L3a as the immediate blocker before any normalization edits.
- docs/fix_plan.md:457 shows C delivers `F_cell=190.27` where PyTorch returns zero; we must understand that ingestion gap first.
- reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1 documents that every downstream scaling factor already matches C, so focus stays on structure factors.
- specs/spec-a-cli.md:1 reminds us the CLI contract treats HKL/Fdump equivalently; parity depends on respecting that pipeline.

How-To Map
- Create `reports/2025-10-cli-flags/phase_l/structure_factor/` (if missing) and stage `probe.py` plus `README.md` describing the run context.
- Base the probe on `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py`: import `get_supervisor_params` so the Crystal/Detector configs remain identical to the supervisor command.
- For each data source (HKL text, C Fdump outputs), load tensors via `read_hkl_file` / `read_fdump` and assign `crystal.hkl_data` / `crystal.hkl_metadata` before calling `Crystal.get_structure_factor(torch.tensor([-7,-1,-14], dtype=dtype, device=device))`.
- Emit all intermediate context (ranges, presence of the target hkl, resulting amplitude) to stdout and to `probe.log` (use `tee` or file writes) so Phase L3b can build on the evidence.
- After running the command above, append a short comparison table to `analysis.md` summarizing HKL vs Fdump values and confirming whether either reproduces C’s 190.27 amplitude.

Pitfalls To Avoid
- Always set `KMP_DUPLICATE_LIB_OK=TRUE` before importing torch to avoid libomp crashes.
- Do not mutate production modules; keep the probe under `reports/` per tooling rules.
- Preserve device/dtype neutrality in the probe (respect the `--dtype` / `--device` flags if you add them; otherwise default to cpu/float64 for clarity).
- Avoid `.item()` on tensors that still require gradients in simulator paths; confine scalar extraction to the standalone probe outputs.
- Leave Protected Assets untouched (see docs/index.md for allowlist) while staging new artifacts.
- Keep vectorization intact; no Python loops over HKL slices in simulator code until after L3 planning.
- Record every command run (exact CLI + git SHA) in the artifact README to maintain reproducibility.

Pointers
- docs/fix_plan.md:448 for the refreshed Next Actions and divergence summary.
- plans/active/cli-noise-pix0/plan.md:253 for the detailed Phase L3 task list.
- reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log:137 for the C-side `F_cell=190.27` reference.
- reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:21 for the current PyTorch `F_cell=0` observation.

Next Up (if time remains)
- Start Phase L3b analysis: diff the newly captured probe data against C’s Fdump layout and outline the ingestion strategy before touching simulator code.
EOF
' succeeded in 971ms:

[2025-10-07T06:24:13] tokens used: 133,727
[2025-10-07T06:24:13] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:24:15] thinking

**Verifying input.md length**
[2025-10-07T06:24:15] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:24:16] bash -lc 'wc -l input.md' succeeded in 756ms:
      39 input.md
[2025-10-07T06:24:16] tokens used: 135,439
[2025-10-07T06:24:16] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:24:29] thinking

**Planning detailed file expansion**

I see the input is too short, so I’m aiming to rewrite it completely to reach about 120 lines by adding multiple new sections like Context Snapshot, Success Criteria, expanded bullet points in Priorities & Rationale, Execution Sequence, How-To Map, Reporting Checklist, Pitfalls, Pointers, and Next Up. I’ll keep the specified structure and avoid nesting bullets to ensure clarity while filling out the required detail.
[2025-10-07T06:24:53] exec bash -lc "cat <<'EOF' > input.md
Summary: Probe the supervisor pixel’s structure-factor source so PyTorch can match C’s I_before_scaling.
Mode: Parity
Focus: CLI-FLAGS-003 › Phase L3a structure-factor verification
Branch: feature/spec-based-2
Mapped tests: none — evidence-only
Artifacts: reports/2025-10-cli-flags/phase_l/structure_factor/probe.py; reports/2025-10-cli-flags/phase_l/structure_factor/probe.log; reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md; reports/2025-10-cli-flags/phase_l/structure_factor/blocked.md (only if needed)
Do Now: CLI-FLAGS-003 › Phase L3a Verify structure-factor coverage — author the probe detailed below, then run "'`KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin`
If Blocked: Log the failure (command, stderr, git SHA) to `reports/2025-10-cli-flags/phase_l/structure_factor/blocked.md` and run `KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q tests/test_trace_pixel.py` to verify imports remain stable.

Context Snapshot
- Phase L2 is complete; TRACE_C and TRACE_PY scaling chains live under `reports/2025-10-cli-flags/phase_l/scaling_audit/` with all factors aligned except I_before_scaling.
- The supervisor pixel (slow=685, fast=1039) maps to hkl≈(−7,−1,−14) per `c_trace_scaling.log:143-164`.
- PyTorch currently reports `F_cell=0` for that hkl while C reports `F_cell=190.27`, driving I_before_scaling to zero on the Py side.
- Existing HKL/Fdump assets in repo appear to cover only a tiny grid (ranges -2..2), so the C amplitude must stem from additional logic.
- Plan Phase L3 (plans/active/cli-noise-pix0/plan.md) now targets structure-factor ingestion before normalization code changes.
- docs/fix_plan.md entry CLI-FLAGS-003 has refreshed Next Actions (lines 457-461) aligning to this probe-first strategy.
- We must keep detector/beam configs identical to the supervisor command (`trace_harness.get_supervisor_params`) so comparisons remain valid.
- All work stays evidence-only this loop; no production module changes or new tests yet.

Success Criteria
- Probe captures HKL-grid coverage and reports whether (-7,-1,-14) exists in either `scaled.hkl` or generated Fdump caches.
- Output log clearly lists the amplitude returned by `Crystal.get_structure_factor` for each data source and device/dtype used.
- `analysis.md` summarises findings, cites the C reference value, and states whether further ingestion work is required.
- Any blockers are documented with enough data for the next loop to resume without repeating work.

Priorities & Rationale
- plans/active/cli-noise-pix0/plan.md:255 mandates L3a before touching simulator code; satisfying that plan gate keeps the initiative on track.
- docs/fix_plan.md:457 documents the current divergence (I_before_scaling) and explicitly calls for L3a/L3b evidence.
- specs/spec-a-cli.md:1 establishes that CLI parity depends on identical HKL/Fdump handling; diverging here explains the PyTorch zero amplitude.
- reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1 already proves all other scaling factors align, isolating the structure-factor gap.
- c_trace_scaling.log:143-164 is the authoritative C reference for the target hkl and F_cell; we must reproduce or explain that value.
- trace_harness.py lines 65-206 keep the configuration canonical; reusing it prevents accidental drift (beam, detector, or crystal mismatches).

Execution Sequence
- Create the directory `reports/2025-10-cli-flags/phase_l/structure_factor/` if missing.
- Copy or import `get_supervisor_params` from the scaling harness to guarantee identical configs.
- Build a small CLI around torch + numpy that accepts `--pixel`, `--hkl`, and multiple `--fdump` paths for experimentation.
- Load HKL data via `read_hkl_file`, attach to a `Crystal` constructed with the supervisor config, and query `crystal.get_structure_factor` for the rounded hkl from the C trace.
- Repeat the query for each provided Fdump path using `read_fdump` (note that some may not contain the hkl; report index status).
- Consider toggling dtype/device (float64 cpu vs float32 cpu) to show that the amplitude mismatch is not precision-driven; record both runs if feasible.
- Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
- Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).

How-To Map
- Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
- Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
- Use `Path('"'reports/.../probe.log')"'` to write a structured log (JSON or plain text) capturing source name, in-range flag, amplitude, and metadata; also echo to stdout.
- Store CLI invocation, git SHA, torch version, and timestamp in the log header for reproducibility.
- Append a markdown table to `analysis.md` with columns `[source, in_range, amplitude]` and note whether any source matches the C value.
- If the probe discovers a new data dependency (e.g., C writes a fresh Fdump during the command), note the path and copy it under `reports/.../structure_factor/` for archival.

Reporting Checklist
- Update `analysis.md` with bullet conclusions plus open questions for Phase L3b.
- Add a short paragraph to `docs/fix_plan.md` Attempts History only after supervisor review (defer for now unless instructed).
- Ensure `git status` is clean of unexpected files before handing off; only the new probe artifacts should appear.
- Record the executed command(s) and SHA in `probe.log` for traceability.

Pitfalls To Avoid
- Forgetting `KMP_DUPLICATE_LIB_OK=TRUE` will crash the probe; set it early.
- Do not relocate or edit protected assets named in docs/index.md while working.
- Avoid instantiating `Simulator` with altered oversample or beam parameters; stay aligned with the supervisor command.
- No edits to production HKL readers this loop; evidence first, implementation later.
- Skip GPU runs unless needed; parity proof starts on CPU float64 for clarity.
- Do not delete existing scaling audit artifacts; future loops rely on them for comparisons.
- Keep the probe deterministic; seed torch/numpy if random numbers are introduced.
- Document any assumptions about the Fdump path—if the file is missing, note it instead of silently failing.
- Avoid `.item()` on tensors that might later require gradients in the simulator; extraction is fine inside the isolated probe only.
- Respect vectorization rules: if you loop over hkl indices in the probe, keep it clearly separate from production pipelines.

Pointers
- docs/fix_plan.md:448 for the refreshed Next Actions and divergence context.
- plans/active/cli-noise-pix0/plan.md:255 detailing the L3a/L3b deliverables.
- reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log:143 for the C-side reference amplitude.
- reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:21 showing PyTorch’s current zero amplitude.
- reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py:70-220 for the canonical config helper.
- specs/spec-a-core.md:200 (structure-factor section) for the expected physical contract.

Next Up (if time allows)
- Initiate Phase L3b by diffing the probe outputs against the newly generated C Fdump (if any) and drafting the ingestion strategy.
- Queue notes for Phase L3c describing the normalization adjustments once the structure-factor source is resolved.
EOF
' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:24:53] bash -lc "cat <<'EOF' > input.md
Summary: Probe the supervisor pixel’s structure-factor source so PyTorch can match C’s I_before_scaling.
Mode: Parity
Focus: CLI-FLAGS-003 › Phase L3a structure-factor verification
Branch: feature/spec-based-2
Mapped tests: none — evidence-only
Artifacts: reports/2025-10-cli-flags/phase_l/structure_factor/probe.py; reports/2025-10-cli-flags/phase_l/structure_factor/probe.log; reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md; reports/2025-10-cli-flags/phase_l/structure_factor/blocked.md (only if needed)
Do Now: CLI-FLAGS-003 › Phase L3a Verify structure-factor coverage — author the probe detailed below, then run "'`KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin`
If Blocked: Log the failure (command, stderr, git SHA) to `reports/2025-10-cli-flags/phase_l/structure_factor/blocked.md` and run `KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q tests/test_trace_pixel.py` to verify imports remain stable.

Context Snapshot
- Phase L2 is complete; TRACE_C and TRACE_PY scaling chains live under `reports/2025-10-cli-flags/phase_l/scaling_audit/` with all factors aligned except I_before_scaling.
- The supervisor pixel (slow=685, fast=1039) maps to hkl≈(−7,−1,−14) per `c_trace_scaling.log:143-164`.
- PyTorch currently reports `F_cell=0` for that hkl while C reports `F_cell=190.27`, driving I_before_scaling to zero on the Py side.
- Existing HKL/Fdump assets in repo appear to cover only a tiny grid (ranges -2..2), so the C amplitude must stem from additional logic.
- Plan Phase L3 (plans/active/cli-noise-pix0/plan.md) now targets structure-factor ingestion before normalization code changes.
- docs/fix_plan.md entry CLI-FLAGS-003 has refreshed Next Actions (lines 457-461) aligning to this probe-first strategy.
- We must keep detector/beam configs identical to the supervisor command (`trace_harness.get_supervisor_params`) so comparisons remain valid.
- All work stays evidence-only this loop; no production module changes or new tests yet.

Success Criteria
- Probe captures HKL-grid coverage and reports whether (-7,-1,-14) exists in either `scaled.hkl` or generated Fdump caches.
- Output log clearly lists the amplitude returned by `Crystal.get_structure_factor` for each data source and device/dtype used.
- `analysis.md` summarises findings, cites the C reference value, and states whether further ingestion work is required.
- Any blockers are documented with enough data for the next loop to resume without repeating work.

Priorities & Rationale
- plans/active/cli-noise-pix0/plan.md:255 mandates L3a before touching simulator code; satisfying that plan gate keeps the initiative on track.
- docs/fix_plan.md:457 documents the current divergence (I_before_scaling) and explicitly calls for L3a/L3b evidence.
- specs/spec-a-cli.md:1 establishes that CLI parity depends on identical HKL/Fdump handling; diverging here explains the PyTorch zero amplitude.
- reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md:1 already proves all other scaling factors align, isolating the structure-factor gap.
- c_trace_scaling.log:143-164 is the authoritative C reference for the target hkl and F_cell; we must reproduce or explain that value.
- trace_harness.py lines 65-206 keep the configuration canonical; reusing it prevents accidental drift (beam, detector, or crystal mismatches).

Execution Sequence
- Create the directory `reports/2025-10-cli-flags/phase_l/structure_factor/` if missing.
- Copy or import `get_supervisor_params` from the scaling harness to guarantee identical configs.
- Build a small CLI around torch + numpy that accepts `--pixel`, `--hkl`, and multiple `--fdump` paths for experimentation.
- Load HKL data via `read_hkl_file`, attach to a `Crystal` constructed with the supervisor config, and query `crystal.get_structure_factor` for the rounded hkl from the C trace.
- Repeat the query for each provided Fdump path using `read_fdump` (note that some may not contain the hkl; report index status).
- Consider toggling dtype/device (float64 cpu vs float32 cpu) to show that the amplitude mismatch is not precision-driven; record both runs if feasible.
- Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
- Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).

How-To Map
- Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
- Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
- Use `Path('"'reports/.../probe.log')"'` to write a structured log (JSON or plain text) capturing source name, in-range flag, amplitude, and metadata; also echo to stdout.
- Store CLI invocation, git SHA, torch version, and timestamp in the log header for reproducibility.
- Append a markdown table to `analysis.md` with columns `[source, in_range, amplitude]` and note whether any source matches the C value.
- If the probe discovers a new data dependency (e.g., C writes a fresh Fdump during the command), note the path and copy it under `reports/.../structure_factor/` for archival.

Reporting Checklist
- Update `analysis.md` with bullet conclusions plus open questions for Phase L3b.
- Add a short paragraph to `docs/fix_plan.md` Attempts History only after supervisor review (defer for now unless instructed).
- Ensure `git status` is clean of unexpected files before handing off; only the new probe artifacts should appear.
- Record the executed command(s) and SHA in `probe.log` for traceability.

Pitfalls To Avoid
- Forgetting `KMP_DUPLICATE_LIB_OK=TRUE` will crash the probe; set it early.
- Do not relocate or edit protected assets named in docs/index.md while working.
- Avoid instantiating `Simulator` with altered oversample or beam parameters; stay aligned with the supervisor command.
- No edits to production HKL readers this loop; evidence first, implementation later.
- Skip GPU runs unless needed; parity proof starts on CPU float64 for clarity.
- Do not delete existing scaling audit artifacts; future loops rely on them for comparisons.
- Keep the probe deterministic; seed torch/numpy if random numbers are introduced.
- Document any assumptions about the Fdump path—if the file is missing, note it instead of silently failing.
- Avoid `.item()` on tensors that might later require gradients in the simulator; extraction is fine inside the isolated probe only.
- Respect vectorization rules: if you loop over hkl indices in the probe, keep it clearly separate from production pipelines.

Pointers
- docs/fix_plan.md:448 for the refreshed Next Actions and divergence context.
- plans/active/cli-noise-pix0/plan.md:255 detailing the L3a/L3b deliverables.
- reports/2025-10-cli-flags/phase_l/scaling_audit/c_trace_scaling.log:143 for the C-side reference amplitude.
- reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log:21 showing PyTorch’s current zero amplitude.
- reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py:70-220 for the canonical config helper.
- specs/spec-a-core.md:200 (structure-factor section) for the expected physical contract.

Next Up (if time allows)
- Initiate Phase L3b by diffing the probe outputs against the newly generated C Fdump (if any) and drafting the ingestion strategy.
- Queue notes for Phase L3c describing the normalization adjustments once the structure-factor source is resolved.
EOF
' succeeded in 897ms:

[2025-10-07T06:24:53] tokens used: 138,302
[2025-10-07T06:24:53] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:24:56] thinking

**Checking line count**
[2025-10-07T06:24:56] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:24:57] bash -lc 'wc -l input.md' succeeded in 748ms:
      80 input.md
[2025-10-07T06:24:57] tokens used: 140,485
[2025-10-07T06:24:57] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:01] thinking

**Planning document expansion**

I’m figuring out how to add new sections like "Evidence Sources" and "Tooling Prep" with detailed bullet points to increase the document length. I'll place them near the end after existing content, expanding other sections too so the total lines reach around 100-200 for better coverage.
[2025-10-07T06:25:14] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/input.md
@@ -43,2 +43,18 @@
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
 How-To Map
[2025-10-07T06:25:14] apply_patch(auto_approved=true) exited 0 in 30ms:
Success. Updated the following files:
M input.md
[2025-10-07T06:25:14] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..39045665d3153e15bd81c420b4cc743200780e40
--- a/input.md
+++ b/input.md
@@ -41,6 +41,22 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:25:14] tokens used: 141,569
[2025-10-07T06:25:14] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..39045665d3153e15bd81c420b4cc743200780e40
--- a/input.md
+++ b/input.md
@@ -41,6 +41,22 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:16] thinking

**Checking line count**
[2025-10-07T06:25:16] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:17] bash -lc 'wc -l input.md' succeeded in 903ms:
      96 input.md
[2025-10-07T06:25:17] tokens used: 143,123
[2025-10-07T06:25:17] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..39045665d3153e15bd81c420b4cc743200780e40
--- a/input.md
+++ b/input.md
@@ -41,6 +41,22 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:24] thinking

**Extending document to meet length**
[2025-10-07T06:25:28] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/input.md
@@ -59,2 +59,8 @@
 
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
[2025-10-07T06:25:28] apply_patch(auto_approved=true) exited 0 in 28ms:
Success. Updated the following files:
M input.md
[2025-10-07T06:25:28] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

[2025-10-07T06:25:28] tokens used: 234,012
[2025-10-07T06:25:28] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:31] thinking

**Verifying line count**
[2025-10-07T06:25:31] exec bash -lc 'wc -l input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:32] bash -lc 'wc -l input.md' succeeded in 916ms:
     102 input.md
[2025-10-07T06:25:32] tokens used: 234,504
[2025-10-07T06:25:32] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:35] thinking

**Preparing to check git status**
[2025-10-07T06:25:35] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:36] bash -lc 'git status --short' succeeded in 754ms:
 M docs/fix_plan.md
 M input.md
 M plans/active/cli-noise-pix0/plan.md
[2025-10-07T06:25:36] tokens used: 234,695
[2025-10-07T06:25:36] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:39] thinking

**Reviewing diffs for docs/fix_plan**
[2025-10-07T06:25:39] exec bash -lc 'git diff docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:40] bash -lc 'git diff docs/fix_plan.md' succeeded in 710ms:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb7226..a59c02e 100644
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
[2025-10-07T06:25:40] tokens used: 234,880
[2025-10-07T06:25:40] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:42] thinking

**Verifying diff and plan**
[2025-10-07T06:25:43] exec bash -lc 'git diff plans/active/cli-noise-pix0/plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:44] bash -lc 'git diff plans/active/cli-noise-pix0/plan.md' succeeded in 668ms:
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5..b1945fe 100644
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@ Exit Criteria: C and PyTorch traces capturing scaling factors are stored under `
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
[2025-10-07T06:25:44] tokens used: 236,773
[2025-10-07T06:25:44] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:46] thinking

**Reviewing input.md changes**
[2025-10-07T06:25:46] exec bash -lc 'git diff input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:47] bash -lc 'git diff input.md' succeeded in 683ms:
diff --git a/input.md b/input.md
index 8a805eb..1d40d6c 100644
--- a/input.md
+++ b/input.md
@@ -1,43 +1,102 @@
-Summary: Wire the scaling harness into the HKL grid so TRACE_PY sees real structure factors and rerun the L2b comparison.
+Summary: Probe the supervisor pixel’s structure-factor source so PyTorch can match C’s I_before_scaling.
 Mode: Parity
-Focus: CLI-FLAGS-003 — Handle -nonoise and -pix0_vector_mm (Phase L2b)
+Focus: CLI-FLAGS-003 › Phase L3a structure-factor verification
 Branch: feature/spec-based-2
-Mapped tests: tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics
-Artifacts: reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log, reports/2025-10-cli-flags/phase_l/scaling_audit/scaling_audit_summary.md, reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json, reports/2025-10-cli-flags/phase_l/scaling_audit/notes.md, reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt
-Do Now: CLI-FLAGS-003 — Handle -nonoise and -pix0_vector_mm (Phase L2b) → KMP_DUPLICATE_LIB_OK=TRUE python reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py --pixel 685 1039 --out trace_py_scaling.log --config supervisor (after updating the harness to attach `crystal.hkl_data` / `crystal.hkl_metadata` before constructing Simulator)
-If Blocked: Capture stdout/stderr to reports/2025-10-cli-flags/phase_l/scaling_audit/attempts/<timestamp>/, log the blocker under CLI-FLAGS-003 Attempt History, and stash the latest harness snapshot in notes.md before touching normalization code.
-
-Priorities & Rationale:
-- docs/fix_plan.md:458-476,482-492 — Phase L2b remains open because the harness never sets `Crystal.hkl_data`; fix_plan now cites harness_hkl_state.txt as proof.
-- plans/active/cli-noise-pix0/plan.md:12-20,243 — L2b guidance updated today: consume `(F_grid, metadata)` and attach them directly to the Crystal before rerunning the trace.
-- reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt — Evidence that `crystal.hkl_data is None` after the current harness path.
[2025-10-07T06:25:47] tokens used: 238,395
[2025-10-07T06:25:47] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:51] thinking

**Preparing commit for changes**
[2025-10-07T06:25:51] exec bash -lc 'git add -A' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:52] bash -lc 'git add -A' succeeded in 749ms:

[2025-10-07T06:25:52] tokens used: 240,454
[2025-10-07T06:25:52] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:25:57] thinking

**Committing changes**
[2025-10-07T06:25:58] exec bash -lc 'git commit -m "SUPERVISOR: CLI-FLAGS-003 planning refresh - tests: not run"' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:25:59] bash -lc 'git commit -m "SUPERVISOR: CLI-FLAGS-003 planning refresh - tests: not run"' succeeded in 729ms:
[feature/spec-based-2 ce7268a] SUPERVISOR: CLI-FLAGS-003 planning refresh - tests: not run
 3 files changed, 119 insertions(+), 57 deletions(-)
[2025-10-07T06:25:59] tokens used: 240,585
[2025-10-07T06:25:59] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:01] thinking

**Pushing changes to repository**
[2025-10-07T06:26:01] exec bash -lc 'git push' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:03] bash -lc 'git push' succeeded in 2.33s:
To github.com:hoidn/nanoBragg.git
   1348fc6..ce7268a  feature/spec-based-2 -> feature/spec-based-2
[2025-10-07T06:26:03] tokens used: 240,837
[2025-10-07T06:26:03] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:07] thinking

**Appending summary to galph_memory.md**
[2025-10-07T06:26:11] exec bash -lc "python - <<'PY'
from datetime import date
entry = f\"## {date.today()} (galph loop — CLI-FLAGS structure-factor probe)\\n- Marked Phase L2 as complete in plans/active/cli-noise-pix0/plan.md and refreshed Phase L3 task list (L3a/L3b now target supervisor pixel F_cell evidence).\\n- Updated docs/fix_plan.md Next Actions to focus on structure-factor ingestion; clarified divergence as F_cell=0 vs 190.27 at hkl≈(-7,-1,-14).\\n- Authored new input.md (L3a instructions) directing Ralph to build a probe under reports/.../structure_factor and log HKL vs Fdump amplitudes.\\n- Noted Fdump snapshots currently in repo do not cover (-7,-1,-14); follow-up question recorded for L3b to locate/replicate C’s data source.\\n- Follow-up for Ralph: implement the probe per input.md, store outputs in reports/2025-10-cli-flags/phase_l/structure_factor/, and feed findings into L3b planning.\\n\\n\"
with open('galph_memory.md','a') as f:
    f.write(entry)
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:12] bash -lc "python - <<'PY'
from datetime import date
entry = f\"## {date.today()} (galph loop — CLI-FLAGS structure-factor probe)\\n- Marked Phase L2 as complete in plans/active/cli-noise-pix0/plan.md and refreshed Phase L3 task list (L3a/L3b now target supervisor pixel F_cell evidence).\\n- Updated docs/fix_plan.md Next Actions to focus on structure-factor ingestion; clarified divergence as F_cell=0 vs 190.27 at hkl≈(-7,-1,-14).\\n- Authored new input.md (L3a instructions) directing Ralph to build a probe under reports/.../structure_factor and log HKL vs Fdump amplitudes.\\n- Noted Fdump snapshots currently in repo do not cover (-7,-1,-14); follow-up question recorded for L3b to locate/replicate C’s data source.\\n- Follow-up for Ralph: implement the probe per input.md, store outputs in reports/2025-10-cli-flags/phase_l/structure_factor/, and feed findings into L3b planning.\\n\\n\"
with open('galph_memory.md','a') as f:
    f.write(entry)
PY" succeeded in 725ms:

[2025-10-07T06:26:12] tokens used: 241,463
[2025-10-07T06:26:12] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:15] thinking

**Verifying appended entry**
[2025-10-07T06:26:16] exec bash -lc 'tail -n 20 galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:17] bash -lc 'tail -n 20 galph_memory.md' succeeded in 719ms:
## 2025-11-14 (galph loop — Phase L2b orientation fix)
- Verified repo up to date; reviewed core docs plus CLI plan & latest scaling artifacts.
- Diagnosed F_cell=0 in trace harness: `trace_harness.py` feeds all MOSFLM vectors into `mosflm_a_star` and leaves the other slots `None`, so Crystal falls back to default orientation during Phase L2b.
- Updated `plans/active/cli-noise-pix0/plan.md` L2b guidance and `docs/fix_plan.md` Next Actions / Attempt notes to call out the MOSFLM injection bug as the gating fix.
- Rewrote `input.md` directing Ralph to patch the harness, rerun the supervisor trace command, refresh artifacts, then proceed to L2c comparison.
- Follow-up for Ralph: apply the harness fix (`mosflm_a_star/b_star/c_star` assignments), rerun trace harness with supervisor flags, archive refreshed `trace_py_scaling.log`, execute `compare_scaling_traces.py`, and log the new Attempt entry before tackling normalization.

## 2025-11-14 (galph loop — L2b HKL wiring)
- `git pull --rebase` clean; reviewed core docs plus CLI plan and fix_plan before analysis.
- Evidence run (`reports/.../harness_hkl_state.txt`) shows `trace_harness.py` never assigns `Crystal.hkl_data`/`hkl_metadata`, leaving structure factors at default_F=0 and keeping F_cell=0 in TRACE_PY.
- Updated docs/fix_plan.md (Attempt #73) and plans/active/cli-noise-pix0/plan.md L2b guidance to call out the missing HKL attachment; next action is to set `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata` before simulator construction.
- Authored new input.md instructing Ralph to wire HKL metadata into the harness, rerun the supervisor trace command, refresh scaling_audit_summary.md, and validate via targeted pytest collection + compare_scaling_traces.
- Follow-up for Ralph: patch harness HKL assignment, rerun L2b command, update artifacts (trace_py_scaling.log, notes.md, harness_hkl_state.txt), then rerun the comparison tool to re-enter Phase L2c.
## 2025-10-06 (galph loop — CLI-FLAGS structure-factor probe)
- Marked Phase L2 as complete in plans/active/cli-noise-pix0/plan.md and refreshed Phase L3 task list (L3a/L3b now target supervisor pixel F_cell evidence).
- Updated docs/fix_plan.md Next Actions to focus on structure-factor ingestion; clarified divergence as F_cell=0 vs 190.27 at hkl≈(-7,-1,-14).
- Authored new input.md (L3a instructions) directing Ralph to build a probe under reports/.../structure_factor and log HKL vs Fdump amplitudes.
- Noted Fdump snapshots currently in repo do not cover (-7,-1,-14); follow-up question recorded for L3b to locate/replicate C’s data source.
- Follow-up for Ralph: implement the probe per input.md, store outputs in reports/2025-10-cli-flags/phase_l/structure_factor/, and feed findings into L3b planning.

[2025-10-07T06:26:17] tokens used: 241,911
[2025-10-07T06:26:17] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:23] thinking

**Verifying uncommitted changes**
[2025-10-07T06:26:23] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:24] bash -lc 'git status --short' succeeded in 778ms:
 M galph_memory.md
[2025-10-07T06:26:24] tokens used: 243,361
[2025-10-07T06:26:24] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:27] thinking

**Preparing to commit changes**
[2025-10-07T06:26:27] exec bash -lc 'git add galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:28] bash -lc 'git add galph_memory.md' succeeded in 693ms:

[2025-10-07T06:26:28] tokens used: 243,487
[2025-10-07T06:26:28] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:30] thinking

**Committing with clear message**
[2025-10-07T06:26:31] exec bash -lc 'git commit -m "SUPERVISOR: CLI-FLAGS-003 memory note - tests: not run"' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:32] bash -lc 'git commit -m "SUPERVISOR: CLI-FLAGS-003 memory note - tests: not run"' succeeded in 715ms:
[feature/spec-based-2 8857b54] SUPERVISOR: CLI-FLAGS-003 memory note - tests: not run
 1 file changed, 7 insertions(+)
[2025-10-07T06:26:32] tokens used: 243,712
[2025-10-07T06:26:32] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:34] thinking

**Pushing changes**
[2025-10-07T06:26:34] exec bash -lc 'git push' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:36] bash -lc 'git push' succeeded in 2.32s:
To github.com:hoidn/nanoBragg.git
   ce7268a..8857b54  feature/spec-based-2 -> feature/spec-based-2
[2025-10-07T06:26:36] tokens used: 243,948
[2025-10-07T06:26:36] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:39] thinking

**Confirming completion before response**
[2025-10-07T06:26:39] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T06:26:40] bash -lc 'git status --short' succeeded in 739ms:

[2025-10-07T06:26:40] tokens used: 244,166
[2025-10-07T06:26:40] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.


[2025-10-07T06:26:51] thinking

**Preparing final summary message**
[2025-10-07T06:26:51] codex

**Planning Updates**
- Plans now treat Phase L2 as complete and refocus Phase L3 on structure-factor parity: see `plans/active/cli-noise-pix0/plan.md:255` for the new L3a/L3b probe-and-analysis checklist, and `L3c–L3f` for downstream refactors.
- docs/fix_plan.md:448 reflects the same shift—Next Actions now call for an L3a probe comparing HKL vs Fdump ingestion and explicitly log the F_cell mismatch at hkl≈(−7,−1,−14).
- Authored a fresh supervisor brief (`input.md`, 102 lines) directing Ralph to build `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`, log HKL/Fdump amplitudes, and archive findings for Phase L3b.
- Logged today’s decisions in `galph_memory.md` (new 2025-10-06 entry) so future loops know why we pivoted to structure-factor evidence.

**Key Findings**
- Existing HKL/Fdump snapshots (`scaled.hkl`, `golden_suite_generator/Fdump.bin`, `tmp/Fdump.bin`) do not contain the (-7,-1,-14) reflection that yields `F_cell=190.27` in C; the upcoming probe must determine how nanoBragg synthesises that amplitude.

**Next Steps for Ralph**
- Follow `input.md` to implement Phase L3a: create the probe under `reports/2025-10-cli-flags/phase_l/structure_factor/`, run it with the provided command, and record HKL vs Fdump coverage/amplitudes (log + analysis.md). This evidence feeds Phase L3b planning.

**Commits**
- `SUPERVISOR: CLI-FLAGS-003 planning refresh - tests: not run`
- `SUPERVISOR: CLI-FLAGS-003 memory note - tests: not run`
[2025-10-07T06:26:56] tokens used: 244,901
[2025-10-07T06:26:56] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 8bb72268a5ff2961e0793245e01355a110178542..a59c02ee9d0290b1414e4c19648b19c36cf3c1d7
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -454,11 +454,11 @@
 - Reproduction (C & PyTorch):
   * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
   * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
-- First Divergence (if known): Phase K3e evidence reveals a **fundamental lattice/geometry mismatch**, not a φ-grid offset. C reports `k_frac≈−3.857` across all φ steps while PyTorch reports `k_frac≈−9.899` (Δk≈6.04 at φ=0°). This 6-unit discrepancy indicates the base reciprocal lattice vectors or scattering geometry differ before any φ rotation is applied.
-- Next Actions (2025-11-13 refresh):
-  1. Phase L2b harness fix — Update `trace_harness.py` to consume the current `read_hkl_file` `(F_grid, metadata)` signature, rebuild HKL ranges without tuple unpack errors, and capture live TRACE_PY output (`trace_py_scaling.log`) with non-placeholder polarization/absorption values. While touching the harness, mirror the CLI MOSFLM handling by assigning each reciprocal vector to `mosflm_a_star`, `mosflm_b_star`, and `mosflm_c_star` individually; the current harness packs all three into `mosflm_a_star`, leaving the others `None` and forcing default orientation (`F_cell` prints as 0 for hkl=1,12,3). **After the read, attach the grid/metadata to the Crystal (`crystal.hkl_data = F_grid`, `crystal.hkl_metadata = metadata`) — evidence in `reports/2025-10-cli-flags/phase_l/scaling_audit/harness_hkl_state.txt` shows the harness leaves `hkl_data` as `None`, so structure-factor lookup still falls back to `default_F=0`.**
-  2. Phase L2c rerun — Re-execute `scripts/validation/compare_scaling_traces.py` against the refreshed logs, update `scaling_audit_summary.md`, and record the earliest divergent factor in docs/fix_plan.md Attempt history.
-  3. Phase L3 prep — With real deltas in hand, outline the normalization fix scope (expected focus: polarization application order and F_latt mismatch) and queue targeted regression selectors.
+- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C’s trace records `F_cell=190.27`. The remaining delta is therefore rooted in structure-factor ingestion rather than normalization math.
+- Next Actions (2025-11-15 refresh):
+  1. Phase L3a probe — Capture the supervisor pixel’s structure factor using both the HKL reader and `read_fdump` to confirm which data source produces C’s `F_cell=190.27`. Archive probe code/logs under `reports/2025-10-cli-flags/phase_l/structure_factor/`.
+  2. Phase L3b analysis — Document how nanoBragg.c synthesizes that reflection (review `nanoBragg.c:2333-2490` and the generated Fdump). Decide whether the PyTorch harness must load the C Fdump, expand the HKL grid, or adjust interpolation flags before implementation. Update the plan once the ingestion strategy is agreed.
+  3. Phase L3c onward — After structure-factor parity is proven, proceed with the normalization refactor and regression additions (plan tasks L3c–L3f) before rerunning the supervisor parity suite in Phase L4.
 - Attempts History:
   * [2025-11-13] Attempt #71 (ralph loop) — Result: **SUCCESS** (Phase L2b validation + Phase L2c complete). **Harness already functional from Attempt #69; executed comparison script to identify first divergence.**
     Metrics: 40 TRACE_PY lines captured; test suite passes 4/4 variants (cpu/cuda × float32/float64). Comparison identifies `I_before_scaling` as first divergent factor (C=943654.809, PyTorch=0, -100% delta).
@@ -468,11 +468,11 @@
       - `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_env.json` - Updated environment snapshot (git_sha current, torch version, device/dtype)
     Observations/Hypotheses:
       - **Harness functional:** Attempt #70 audit was stale; Attempt #69 already resolved the `(F_grid, metadata)` API change
-      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C indicates missing structure factor (F_cell=0 for reflection 1,12,3)
-      - **Root cause hypothesis (updated 2025-11-14):** Harness injects MOSFLM vectors incorrectly (`mosflm_a_star=[a*, b*, c*]`, other slots `None`), so `Crystal.compute_cell_tensors` falls back to default orientation and `F_cell` resolves to the default 0.0 despite the HKL grid containing hkl=(1,12,3)
+      - **First divergence confirmed:** `I_before_scaling=0` in PyTorch vs `943654.809` in C stems from the targeted pixel (685,1039) mapping to hkl≈(−7,−1,−14), where PyTorch reports `F_cell=0` but C’s trace records `F_cell=190.27`.
+      - **Root cause hypothesis (updated 2025-11-15):** Harness instrumentation is now correct; the discrepancy arises from structure-factor ingestion (HKL grid vs generated Fdump) rather than MOSFLM vector wiring.
       - **Scaling infrastructure correct:** r_e², fluence, steps, capture_fraction, polar, omega_pixel all match C within tolerances (<0.002% delta)
       - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants
-    Next Actions: Phase L3 — Investigate why F_cell=0 for reflection (1,12,3). Check HKL file contents, structure factor lookup logic, and interpolation behavior. Update Phase L plan status to [L2b=D, L2c=D].
+    Next Actions: Phase L3 — Follow plan tasks L3a/L3b to trace how the supervisor pixel acquires `F_cell=190.27` in C (HKL vs Fdump), then proceed with the normalization/refactor steps once the ingestion gap is understood.
   * [2025-10-17] Attempt #72 (ralph loop) — Result: **SUCCESS** (Phase L2b harness MOSFLM orientation fix). **Corrected `trace_harness.py` to assign each MOSFLM reciprocal vector to its own config field instead of packing all three into `mosflm_a_star`.**
     Metrics: Harness now produces non-zero F_latt values (F_latt=1.351 vs previous 0), confirming proper orientation. Test suite passes 4/4 variants (tests/test_trace_pixel.py). Comparison script completed successfully (2 divergent factors identified).
     Artifacts:
diff --git a/input.md b/input.md
index 818da969589b20b8914c788d4cee4a73cedcd383..1d40d6cc436fb7133ae8f835e95009c5f02cad0c
--- a/input.md
+++ b/input.md
@@ -41,6 +41,28 @@
 - Print and log metadata: min/max ranges, whether the hkl falls inside each grid, and the amplitude retrieved.
 - Summarise findings and hypotheses in `analysis.md`, referencing any anomalies (e.g., if C amplitude cannot be reproduced from available data).
 
+Tooling Prep
+- Ensure editable install is in place (`pip install -e .`) so the probe can import `nanobrag_torch` modules without PYTHONPATH hacks beyond `PYTHONPATH=src`.
+- Export `NB_C_BIN=./golden_suite_generator/nanoBragg` to keep future C comparisons consistent.
+- Verify both `golden_suite_generator/Fdump.bin` and `tmp/Fdump.bin` exist before running the probe; list their `ls -l` output in the log for provenance.
+- Run `git rev-parse HEAD` and record the SHA at the top of `probe.log`.
+- Capture `torch.__version__`, `platform.platform()`, and device availability in the probe output to maintain context for later parity checks.
+- If you need additional Fdump snapshots from C, document the exact command used to regenerate them (copy/paste from `c_trace_scaling.log` header) and store the binary copy under `reports/.../structure_factor/`.
+
+Evidence Sources
+- `reports/2025-10-cli-flags/phase_l/scaling_audit/instrumentation_notes.md` for prior harness setup steps.
+- `docs/architecture/c_code_overview.md:310` (HKL handling) to cross-check the C ingestion pipeline while analysing probe results.
+- `docs/architecture/pytorch_design.md:180` for the expected PyTorch HKL workflow; note any deltas when explaining outcomes.
+- `reports/2025-10-cli-flags/phase_l/hkl_parity/summary_20251109.md` summarises prior HKL vs Fdump parity work—cite it if ranges conflict.
+- `reports/2025-10-cli-flags/phase_k/base_lattice/summary.md` contains notes on MOSFLM scaling decisions that might influence structure-factor expectations.
+- `tests/test_cli_scaling.py` (search for `TestHKLFdumpParity`) to understand existing coverage and gaps.
+
+Open Questions to Address in analysis.md
+- Does any existing Fdump (or a freshly generated one) actually contain the (-7,-1,-14) reflection, or is C deriving it procedurally?
+- If the reflection is absent, which section of `nanoBragg.c` fabricates the amplitude (default_F fallback, symmetry expansion, or sinc evaluation)?
+- Are there command-line flags (`-nonorm`, `-nointerpolate`) altering the structure-factor lookup in C that PyTorch is not mirroring?
+- What hypotheses should Phase L3b test next (e.g., loading the on-disk Fdump vs synthesising a wider HKL grid)?
+
 How-To Map
 - Command template: `KMP_DUPLICATE_LIB_OK=TRUE PYTHONPATH=src python reports/2025-10-cli-flags/phase_l/structure_factor/probe.py --pixel 685 1039 --hkl scaled.hkl --fdump golden_suite_generator/Fdump.bin --fdump tmp/Fdump.bin --dtype float64 --device cpu`.
 - Inside the probe, after loading tensors, compute rounded hkl from detector geometry by calling the same helper as the harness (`Simulator` or `Crystal` as needed) to double-check indices.
diff --git a/plans/active/cli-noise-pix0/plan.md b/plans/active/cli-noise-pix0/plan.md
index 7ef89b5dc77becad3d1508fbb589bef70424d89e..b1945fe8253b742f4947ebf5420e2494bfe65031
--- a/plans/active/cli-noise-pix0/plan.md
+++ b/plans/active/cli-noise-pix0/plan.md
@@ -13,8 +13,9 @@
 - Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
 - Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
 - Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
-- Gap snapshot update (2025-11-13): Latest harness rerun aborts before capturing TRACE_PY because `read_hkl_file` now returns `(F_grid, metadata)`; `trace_harness.py` still expects the legacy seven-value tuple. See `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_fullrun.log` for the `ValueError: not enough values to unpack` stack trace. As a result `trace_py_scaling_refreshed.log` still contains placeholder values (`I_before_scaling NOT_EXTRACTED`, `polar 0`), keeping Phase L2b open until the harness adopts the new API and records live physics data again.
-- Gap snapshot refresh (2025-11-14): Attempt #73 confirms the harness still leaves `Crystal.hkl_data` / `hkl_metadata` unset after loading scaled.hkl, so structure factors default to 0 and `F_cell` stays zero. Phase L2b remains open until the HKL grid/metadata are attached before calling `Simulator`.
+- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
+- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
+- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code. 
 - Gap snapshot addendum (2025-10-06T17:59 replayed 2025-11-09): Re-running Phase L1 with `Fdump_scaled_20251006175946.bin` shows the cache stores 182,700 doubles (≈9,534 more than the 173,166 expected from header ranges) and that reflections shift by Δk≈+10–12 / Δl≈−2…−8 relative to HKL indices. Use this dataset to reverse-engineer the C layout before touching PyTorch HKL IO.
 - Gap insight (2025-10-31): Scaling evidence shows MOSFLM matrix runs still rescale real vectors using formula lengths; C skips that step unless `-cell` is provided, so PyTorch must gate the `vector_rescale` analogue when `mosflm_a_star` is set. The same trace confirms the polarization Kahn factor should default to 0.0 (C’s `polarization`), not 1.0, so BeamConfig defaults need to be realigned before Phase L.
 - Gap correction (2025-10-22): Fresh C evidence (`reports/2025-10-cli-flags/phase_h5/c_precedence_2025-10-22.md`) proves nanoBragg ignores `-pix0_vector_mm` whenever custom detector vectors are present. PyTorch now deviates because the lattice factor uses fractional indices (h−h0); fix required before normalization parity.
@@ -241,8 +242,8 @@
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
 | L2a | Instrument C scaling chain | [D] | ✅ 2025-10-06 Attempt #55: Reused existing TRACE_C hooks (nanoBragg.c 3367-3382), captured `c_trace_scaling.log` for pixel (685,1039), and recorded setup in `instrumentation_notes.md`. Artifacts live under `reports/2025-10-cli-flags/phase_l/scaling_audit/`; ready to mirror fields on the PyTorch side. |
-| L2b | Expose and log PyTorch scaling factors | [P] | ✅ Attempt #67 (2025-10-06) patched `src/nanobrag_torch/simulator.py` so `TRACE_PY` emits real `I_before_scaling`, polarization, capture_fraction, and steps; regression `tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics` passes across dtype×device. **Remaining work:** update `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_harness.py` to consume the current `read_hkl_file` API `(F_grid, metadata)`, attach the grid via `crystal.hkl_data = F_grid` and `crystal.hkl_metadata = metadata`, rebuild HKL bounds on-device, and invoke `Simulator(..., debug_config={'trace_pixel': [685, 1039]})` under stdout capture so `trace_py_scaling.log` records live values (no `NOT_EXTRACTED` placeholders). Mirror the CLI MOSFLM handling while doing this—assign each reciprocal vector separately (`mosflm_a_star`, `mosflm_b_star`, `mosflm_c_star`). Refresh `trace_py_env.json`/`notes.md`, keep the failing `trace_py_fullrun.log` as evidence, then archive the successful rerun before proceeding to L2c. |
-| L2c | Diff traces & record first divergence | [P] | `scripts/validation/compare_scaling_traces.py` (Attempt #68, 2025-10-06) already parses TRACE_C/PY and produces markdown. After L2b captures live TRACE_PY output, rerun the script to update `scaling_audit_summary.md` with the earliest divergent factor and log the findings in docs/fix_plan.md. |
+| L2b | Expose and log PyTorch scaling factors | [D] | ✅ Attempts #69, #72, and #74 (commits `1cf77b5`, `0f3de26`) now drive the harness through the updated HKL API, attach `crystal.hkl_data` / `crystal.hkl_metadata`, and capture live TRACE_PY output for pixel (685,1039). `reports/2025-10-cli-flags/phase_l/scaling_audit/trace_py_scaling.log` shows real polarization/omega/steps, and `harness_hkl_state_fixed.txt` confirms the HKL tensor lives on the simulator device. |
+| L2c | Diff traces & record first divergence | [D] | ✅ Attempt #71 refreshed `scaling_audit_summary.md` via `scripts/validation/compare_scaling_traces.py`, highlighting `I_before_scaling` as the first divergence (C=9.4365e5, Py=0) while all downstream scaling factors match within 2e-3%. This establishes that the remaining gap stems from missing structure-factor coverage rather than normalization math. |
 
 ### Phase L3 — Normalization Fix Implementation
 Goal: Patch the PyTorch scaling pipeline so every factor (omega, polarization, capture_fraction, r_e², fluence, steps) matches the C implementation within 1e-6 relative error.
@@ -251,10 +252,12 @@
 
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
-| L3a | Implement scaling fix in simulator | [ ] | Modify `src/nanobrag_torch/simulator.py` (likely around lines 930-1085) to mirror the C normalization order confirmed in L2. Include mandatory C-code quote per Rule #11. Ensure device/dtype neutrality (no `.cpu()`/`.item()` in differentiable paths). |
-| L3b | Add targeted regression test | [ ] | Extend `tests/test_cli_scaling.py` with a supervisor-command fixture that asserts PyTorch I_before_scaling, ω, polarization, and final intensity match pre-recorded C values within tolerances (≤1e-6 relative). Parametrise over CPU/CUDA when available. |
-| L3c | Validate scaling via script | [ ] | Create `scripts/validation/compare_scaling_chain.py` that consumes the C/Py traces from L2 and reports pass/fail deltas. Run `KMP_DUPLICATE_LIB_OK=TRUE python scripts/validation/compare_scaling_chain.py --c-log ... --py-log ...` and archive output JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`. |
-| L3d | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` Attempt history with fix summary, link artifacts, and update this plan table to `[D]` where applicable. If scaling logic touches spec details, annotate `docs/architecture/pytorch_design.md` accordingly. |
+| L3a | Verify structure-factor coverage for supervisor pixel | [ ] | Use the refreshed harness to reproduce the rounded Miller index from C (`trace_c_scaling.log` lines 143-164 → hkl=(-7,-1,-14)). Author a small probe (e.g., `reports/2025-10-cli-flags/phase_l/structure_factor/probe.py`) that loads `scaled.hkl` via `read_hkl_file` **and** the latest `Fdump.bin` via `read_fdump`, then calls `Crystal.get_structure_factor` for that hkl. Record both outputs and compare against the C reference value `F_cell=190.27`. |
+| L3b | Reconcile HKL ingestion with C | [ ] | If the probe shows a mismatch (PyTorch 0 vs C 190.27), inspect the C reader (`nanoBragg.c:2333-2490`) to determine whether additional reflections are synthesized (e.g., via symmetry, padding, or sinc tables) despite the minimal HKL file. Document hypotheses and decide whether the harness must load the generated `Fdump.bin`, expand the HKL grid, or adjust interpolation flags before touching production code. Store notes in `reports/2025-10-cli-flags/phase_l/structure_factor/analysis.md`. |
+| L3c | Implement scaling fix in simulator | [ ] | After L3a/L3b confirm the correct structure-factor source, modify `src/nanobrag_torch/simulator.py` (≈lines 930-1085) so the scaling chain mirrors the C ordering. Include mandatory C-code quotes per Rule #11 and keep the implementation vectorized/device-neutral. |
+| L3d | Add targeted regression tests | [ ] | Extend `tests/test_cli_scaling.py` with (1) a structure-factor lookup assertion for hkl=(-7,-1,-14) using the agreed data source, and (2) a supervisor-command regression that checks I_before_scaling, ω, polarization, and final intensity against recorded C values within ≤1e-6 relative tolerance. Parametrise over CPU/CUDA when available. |
+| L3e | Validate scaling via script | [ ] | Enhance `scripts/validation/compare_scaling_chain.py` (or create it if missing) to consume the L2 traces plus the new structure-factor data, emit JSON under `reports/2025-10-cli-flags/phase_l/scaling_validation/metrics.json`, and fail loudly if any factor exceeds the agreed thresholds. |
+| L3f | Update documentation & plans | [ ] | Refresh `docs/fix_plan.md` with the implementation attempt, link the new artifacts, and edit architectural docs (`docs/architecture/pytorch_design.md`, `docs/development/testing_strategy.md`) to describe the final normalization + HKL ingestion flow. Mark L3 tasks `[D]` once artifacts are archived. |
 
 ### Phase L4 — Supervisor Command Parity Rerun
 Goal: Demonstrate end-to-end parity for the supervisor command (correlation ≥ 0.9995, sum_ratio 0.99–1.01, mean_peak_distance ≤ 1 px) and close CLI-FLAGS-003.

Reading prompt from stdin...
To github.com:hoidn/nanoBragg.git
   8857b54..62c4582  HEAD -> feature/spec-based-2
Waiting for Ralph to complete i=72...
Already up to date.
[sync] state: actor=ralph status=waiting-ralph iter=72
Updating 62c4582..a6ed279
Fast-forward
 sync/state.json | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
From github.com:hoidn/nanoBragg
   62c4582..a6ed279  feature/spec-based-2 -> origin/feature/spec-based-2
[sync] state: actor=ralph status=running-ralph iter=72
Already up to date.
