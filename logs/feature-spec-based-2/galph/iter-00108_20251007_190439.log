Already up to date.
Waiting for expected_actor=galph...
Already up to date.
[sync] state: actor=galph status=failed iter=108
To github.com:hoidn/nanoBragg.git
   2160885..c73da6a  HEAD -> feature/spec-based-2
$ codex exec -m gpt-5-codex -c model_reasoning_effort=high --dangerously-bypass-approvals-and-sandbox
[2025-10-07T19:04:43] OpenAI Codex v0.38.0 (research preview)
--------
workdir: /Users/ollie/Documents/nanoBragg3
model: gpt-5-codex
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: high
reasoning summaries: auto
--------
[2025-10-07T19:04:43] User instructions:
<role>
planning, review and analysis. do not make implementation code changes.
</role>
<current long-term goals>
in order of decreasing priority:
<1>
run a successful parallel test of pytorch nanobragg against nanobragg c with this command:

nanoBragg  -mat A.mat -floatfile img.bin -hkl scaled.hkl  -nonoise  -nointerpolate -oversample 1  -exposure 1  -flux 1e18 -beamsize 1.0  -spindle_axis -1 0 0 -Xbeam 217.742295 -Ybeam 213.907080  -distance 231.274660 -lambda 0.976800 -pixel 0.172 -detpixels_x 2463 -detpixels_y 2527 -odet_vector -0.000088 0.004914 -0.999988 -sdet_vector -0.005998 -0.999970 -0.004913 -fdet_vector 0.999982 -0.005998 -0.000118 -pix0_vector_mm -216.336293 215.205512 -230.200866  -beam_vector 0.00051387949 0.0 -0.99999986  -Na 36  -Nb 47 -Nc 29 -osc 0.1 -phi 0 -phisteps 10 -detector_rotx 0 -detector_roty 0 -detector_rotz 0 -twotheta 0

this will require first adding support for the following cli params to pytorch nanobragg:
-nonoise
-pix0_vector_mm

</1>
<2>
review and firm up if needed plans/active/vectorization.md. then implement it (or rather, delegate its implementation to ralph), starting with the tricubic interpolation vectorization 
</2>
</current long-term goals>
</past long term goals>
(just for archival / reference purposes):
- error-correcting the engineer agent 
- profiling pytorch nanobragg to find performance bottlenecks. analyzing to understand the CRITICAL slowness of the pytorch implementation compared to reference C, which persists after our recent improvement attempts
- finding performance issues in the PyTorch reimplementation of nanobragg (originally a C code) and speeding it up. It should be efficiently vectorized and faster than C nanobragg, but currently it's slower 
- ensuring that the pytorch implementation uses fp32 (not fp64) by default 
- understanding why pytorch is slower than C in the warm condition at 4096x4096 resolution and fixing the underlying performance issue, if one is found. THIS IS A CRITICAL PERFORMANCE ISSUE.
- once all the above are taken care of: building a user-facing showcase of autodiff-based parameter refinement, with plots / visuals

</past long-term goals>
<task>
You are galph, a planner / supervisor agent. you are overseeing the work of an agent (ralph) that is running prompts/main.md in a loop, using docs/fix_plan.md as its instruction set and long term memory. 

You will get invoked repeatedly, for multiple iterations. Use galph_memory.md to communicate with your future self. You'll plans under plans/, when needed, to help steer multi-turn efforts by the coder agent (ralph). Those plans will be cross referenced from docs/fix_plan.md so that ralph can find / read them. 

At the start of every invocation:
- Run `timeout 30 git pull --rebase` with a hard 30-second timeout  to sync with origin before reviewing context. If the command times out, immediately abort any partial rebase (`git rebase --abort`) and fall back to a normal merge via `git pull --no-rebase`. Whatever path you take, resolve resulting conflicts (docs/fix_plan.md is a frequent hotspot) and document key decisions in galph_memory.md. If the pull reports conflicts:
  * Run `git status --short` to list conflicted files.
  * Fix each file (remove conflict markers, keep the intended content) and stage it with `git add`.
  * When the index is clean, resume with `timeout 30 git rebase --continue --no-edit`. IMPORTANT: NEVER RUN THIS COMMAND WITHOUT TIMEOUT
- After resolving any conflicts, read the latest galph_memory.md entry (and any linked plan files) so you do not lose past context.
- Prune or summarize older entries when they become stale or redundant.

During the main, central phase of invocation you will be doing essentially three things:
<main analysis step 1> 
An initial analysis pass in which you gather and review information in order to choose a <focus issue> for the turn, corresponding to <instructions> steps <0> through <3>. This will involve a multi-category selection process. You will choose both a <focus issue> and an associated <Action type> for the remainder of the iteration. The available <Action type>s are the following:
<Action type> list:
<1>
<Evidence collection> (i.e. Evidence task)
No full pytest runs. Allowed: non-mutating probes and CLI validation tools (e.g., scripts/validation/*, nb-compare, pixel trace); pytest --collect-only to validate selectors; and in TDD mode only, a single targeted pytest run to confirm the newly authored test fails. Do not change production code. This gate applies only to galph. Ralph is exempt. Do not include any Phase label in input.md.

Evidence collection includes the following subtype:
    Callchain Tracing (Evidence subtype)
    - When to use: before code edits when the pipeline/factor order relevant to the current issue is unclear; when onboarding a new surface; or upon parity failures where the locus is unknown.
    - Directive: first, emit descriptions for the following things:
       - <analysis_question> (required): Free‑text description of the behavior/bug/perf issue to investigate. This will be closely related to <focus issue>, but viewed from the point of view of relevant code execution paths and their entry points.
       - <initiative_id> and <scope_hints> 

    - Directive: then read and carefully follow the instructions in `prompts/callchain.md` with the question‑driven invocation (<analysis_question>) and produce standardized artifacts under `reports/<initiative_id>/`.
    - Example invocation variables (fill at run time):
      analysis_question: "<what are we trying to understand or fix?>"
      initiative_id: "<short‑slug>"
      scope_hints: ["CLI flags", "normalization", "scaling"]
      roi_hint: "<minimal input/ROI>"
      namespace_filter: "<project primary package>"
      time_budget_minutes: 30
    - Expected outputs:
      - `reports/<initiative_id>/callchain/static.md` (entry→sink with file:line anchors)
      - `reports/<initiative_id>/callgraph/dynamic.txt` (optional, module‑filtered)
      - `reports/<initiative_id>/trace/tap_points.md` (proposed numeric taps with owners)
      - `reports/<initiative_id>/summary.md` (question‑oriented narrative + next steps)
      - `reports/<initiative_id>/env/trace_env.json`
    - Guardrails: evidence‑only (no prod edits), module/device/dtype neutrality, small ROI, respect Protected Assets, stable key names in traces.
</Evidence collection>
</1>
<2>
<Debug> i.e. Debugging — Hypothesis + Triage (initial pass):
- pairs with <focus issue>s that are related to debugging or parity analysis.
<steps>
- Formulate 1–3 plausible hypotheses for the observed gap/issue.
- Triage each with checks appropriate to scope using existing artifacts or quick, documented reproductions; this triage may constitute the primary work for the iteration. Record outcomes succinctly in the evidence.
- For the top hypothesis, state confidence and the single confirming step to run next. Deliver 1–3 ranked hypotheses with supporting evidence, artifact paths, and the next confirming step.
</steps>
</Debug>
</2>
<3>
<Planning>
- we will be calling the plan topic the <focus issue> of this turn.
- based on which long term <goal> and sub-goal is that effort / plan? 
- Which existing docs/fix_plan.md items does it (i.e. the <focus issue>) relate to? 
- Documentation review for <focus issue>: Using `docs/index.md` as the map, identify and read the specific documents relevant to the chosen <focus issue> (e.g., component contracts, architecture ADRs, parity/testing strategy). List the file paths you will rely on (with a one‑line rationale each) before drafting or updating the plan.
- think deeply. draft / redraft the plan and save it to a .md under plans/active/. Structure the write-up as a phased implementation document (see `plans/archive/general-detector-geometry/implementation.md` for tone/shape): begin with context + phase overviews, then outline each phase’s intent, prerequisites, and exit criteria. When a phase benefits from explicit tracking, embed a checklist table using the `ID | Task Description | State | How/Why & Guidance` format (with `[ ]`, `[P]`, `[D]` markers) inside that phase section.
  • Include reproduction commands, owners (if known), and decision rules in the guidance column.
  • Favor narrative flow first; layer checklists only where they clarify verification steps or deliverables.
  • Mini-template to crib when drafting:
    ```md
    ## Context
    - Initiative: <initiative>
    - Phase Goal: <outcome>
    - Dependencies: <docs/tests>

    ### Phase A — <short title>
    Goal: <what this phase proves or delivers>
    Prereqs: <artifacts or measurements required before starting>
    Exit Criteria: <verifiable completion signal>

    | ID | Task Description | State | How/Why & Guidance (including API / document / artifact / source file references) |
    | --- | --- | --- | --- |
    | A1 | <Key diagnostic or implementation step> | [ ] | Run `<command>`; capture results under `reports/<date>/...`. |
    | A2 | <Follow-up validation> | [ ] | Compare against `<artifact>`; stop if deviation > threshold. |
    ```
- When refreshing an existing plan, retrofit it to this phased format before adding or editing tasks.
- review docs/fix_plan.md. edit if needed. cross reference the new plans .md so that ralph can find it.
</Planning>
</3>

<4>
<Review or housekeeping>
- Review and evaluate ralph's work. Scrutinize the commit history. Look at the diffs. 
- Are the docs/fix_plan.md contents and priorities sane? things to consider:
  - if docs/fix_plan.md is longer than 1000 lines it should be housecleaned. If it's disorganized and / or internally inconsistent, consider how this could be addressed. 
- after considering the above, you have enough information to choose a <focus issue> for this turn. do so. Consider the nature of the <focus issue>:
    - Do we need a new docs/fix_plan item to put ralph back on course, fix one of his mistakes, or instruct him to do something that he overlooked? If so, draft it and add it to docs/fix_plans
    - does the <focus issue> involve identified issues in docs/fix_plan.md? If so, fix them. If you decide to shorten docs/fix_plan.md, the least relevant portions should be moved to archive/fix_plan_archive.md (with summary + archive cross reference if appropriate)
</Review or housekeeping>
</4>

In addition to selecting an <Action type> and <focus issue> you will choose a <Mode> flag. 
 - Mode flags are combinable and refine execution, and are applicable to both the supervisor (you) and ralph; do not include any Phase label in input.md.
 - available modes: <TDD | Parity | Perf | Docs | none>
<mode descriptions>
TDD mode (supervisor-scoped): When operating in supervisor evidence mode, author/update a single minimal failing test that encodes the acceptance criterion. Confirm it fails via a targeted pytest selector; record the selector and expected failure text in input.md. Do not change production code, and do not include any Phase label in input.md.
</mode descriptions>

</main analysis step 1>

<main analysis step 2>
Here you will do a deep analysis. You will follow the guidelines of the selected <Mode> and <Action type>, applying them to the selected <focus issue>. This corresponds to <instructions> step <3.2>.


</main analysis step 2>

<main analysis step 3>
Here you synthesize the analysis findings into output files (<instructions> steps <3.5> to <4>)
</main analysis step 3>


Before concluding each invocation:
- Append a concise update to galph_memory.md capturing key findings, decisions, and open questions (reference file paths or plan names).
- Note any follow-up actions you expect Ralph to take.
- If no substantial update is needed, explicitly log that fact so future runs know context was reviewed.
</task>

<instructions>
<0>
READ the following files:
- Index of project documentation: `./docs/index.md`
- $SPECS: `./specs/spec-a.md`
- $ARCH: `./arch.md` (ADR-backed implementation architecture; reconcile design with spec, surface conflicts)
- docs/development/c_to_pytorch_config_map.md — C↔Py config parity and implicit rules
-- docs/debugging/debugging.md — Parallel trace-driven debugging SOP
- $PLAN: `./fix_plan.md` (living, prioritized to‑do; keep it up to date)
- $TESTS: `./docs/development/testing_strategy.md` (testing philosophy, tiers, seeds/tolerances, commands)
- Set `AUTHORITATIVE_CMDS_DOC=./docs/development/testing_strategy.md` (or project‑specific path) and consult it for authoritative reference commands and test discovery.
<0>
<1>
do a deep analysis of the codebase in light of the <current long term goals>. What are some current issues / gaps and possible approaches to resolving them? Review docs/fix_plan.md and plans/active/, as previous iterations of you may have already done some legwork.
 
At this point, you can do a premature <Callchain tracing> action ahead of time, if it helps you gather information needed for this analysis.
</1>
<2>
flip a coin using python. if it comes up <heads>:
review ralph's work over the last N (~10 but can be more or less - you decide) iterations. Check the commit history. Has the work been productive? Have there been regressions? Do we need to provide any feedback / course-correction?
</heads>
if it comes up <tails>: proceed to step <3>
</2>
<3>
Given your findings in <1> and <2>, think about whether there's any need for a multi-turn planning effort -- i.e. ralph can't see the forest for the trees and may struggle with major refactorings and multi-turn implementation efforts unless they are coordinated by you. Is there a need for such planning *right now*? If such a plan is already spoken for (plans/active/ or wherever else past galph might have saved to), does that plan require updates or is it up to date / high quality and simply pending? IFF you determine the need for a new plan or modification of an existing one:
<yes case>
This plan-related work is now your <focus issue>.
You will be following the <Planning> <Action type> instructions. Think about what this will entail but don't execute the <Planning> instructions yet.
</yes case>
</no case>
Since you are not <Planning>, you must select one of the other <Action type>s and an associated <focus issue> based on what you think is the most productive work increment for this iteration. Think about the associated work, but don't execute it yet.
</no case>
</3>
<3.2>
- Documentation review for <focus issue>: From `docs/index.md`, enumerate and read the documents that are most relevant to the chosen <focus issue>`; note the key file paths you will rely on for the impending analysis.
- Then carefully follow the guidelines of the selected <Mode> and <Action type>, applying them to the selected <focus issue>. Complete the task that you selected in step <3>.
</3.2>
<3.5>
Render and write ./input.md (supervisor→engineer steering memo). Overwrite the entire file every invocation. Keep length ~100–200 lines. Include these sections in order:
Header:
- Summary: <one‑sentence goal for this loop>
 - Mode: <TDD | Parity | Perf | Docs | none>
- Focus: <plan item ID/title from docs/fix_plan.md>
- Branch: <expected branch>
- Mapped tests: <validated list | none — evidence‑only>
- Artifacts: <key paths to produce under reports/>
- Do Now: 1 line naming the exact docs/fix_plan.md item (ID and title) to execute this loop, plus the exact pytest command/env to reproduce it (only when an authoritative mapping exists). If no such test exists, the Do Now MUST be to author the minimal targeted test first and then run it. If you intend to delegate the choice, write “Do Now: delegate” and provide decision guidance below.
  - Note: If operating in supervisor <Evidence collection> (internal-only), do not run the full suite. Allowed: pytest --collect-only to validate selectors; in TDD mode only, run one targeted selector to confirm a new failing test. All other test execution is deferred to Ralph. Do not include any Phase label in input.md.
<Do Now guidelines>
Verification scripts: You may run nb-compare and scripts/validation/* to collect metrics and artifacts (no code changes). Record outputs under reports/.
Mapped tests under supervisor evidence mode: Include exact selectors in input.md; validate with --collect-only; do not run them (except the TDD failure confirmation). Do not include any Phase label in input.md.
Command Sourcing (tests): Only include an exact pytest command in Do Now when sourced from an authoritative mapping (e.g., docs/development/testing_strategy.md) or an existing, known test file/identifier. If no authoritative mapping exists, set the Do Now task to author the minimal targeted test first; do not guess at a pytest selector here.
Implementation: refer to phased plans, checklists, and all associated artifacts
</Do Now guidelines>
- If Blocked: fallback action (what to run/capture, how to record it in Attempts History).
- Priorities & Rationale: 3–6 bullets with file pointers (specs/arch/tests/plan) justifying the Do Now.
- How-To Map: exact commands (pytest, nb-compare), env vars, ROI/thresholds, and where to store artifacts; prefer using `scripts/validation/*` when available.
- Pitfalls To Avoid: 5–10 crisp do/don’t reminders (device/dtype neutrality, vectorization, Protected Assets, two‑message loop policy, no ad‑hoc scripts).
- Pointers: file paths with line anchors to the most relevant spec/arch/testing_strategy/fix_plan entries for this loop.
- Next Up (optional): 1–2 candidates Ralph may choose next loop if he finishes early (still one thing per loop).

 Rules:
 - Ralph must not edit input.md. You (galph) are the single writer.
 - If input.md’s Do Now conflicts with an existing in_progress selection in fix_plan.md, Ralph is allowed to switch; he must record the change in Attempts History.
- Do not instruct Ralph to run the full test suite more than once per turn. Require targeted tests first; run the full suite once at the end only if code changed. For prompt/docs‑only loops, require `pytest --collect-only -q` instead.
- Prefer referencing reusable scripts under `scripts/validation/` from Do Now when available.
- Commit input.md each run as part of step <4> (commit only if the content changed).
 </3.5>

<4>
Before finishing the loop, enforce git hygiene:
- Run `git status --short` to inspect new or modified files that appeared during this invocation.
- Review diffs for each change; revert only if you created it this loop and it was accidental.
- Stage intentional updates with `git add -A` and commit via `git commit -m "SUPERVISOR: <scope> - <tests or rationale>"`, noting any tests run (use `tests: not run` when you skip them).
- After committing, run `git push` to share the updates. If the push is rejected, `timeout 30 git pull --rebase`, resolve conflicts (capture decisions—especially for docs/fix_plan.md—in galph_memory.md), then push again.
- If you deliberately leave the tree dirty, document the rationale in galph_memory.md so the next invocation knows why.
</4>
</instructions>
<notes>
- ignore 'routing violations'. these are out of scope.
- ignore AT parallel 012-related items for now
</notes>
Now carefully and exhaustively follow your <instructions>, while keeping in mind the <task> directives.


[2025-10-07T19:04:45] thinking

**Preparing to run git pull with timeout**
[2025-10-07T19:04:45] exec bash -lc 'timeout 30 git pull --rebase' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:04:47] bash -lc 'timeout 30 git pull --rebase' succeeded in 2.09s:
Already up to date.
[2025-10-07T19:04:47] tokens used: 13,979

[2025-10-07T19:04:50] thinking

**Preparing to read latest galph_memory.md entry**
[2025-10-07T19:04:51] exec bash -lc 'cat galph_memory.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:04:51] bash -lc 'cat galph_memory.md' succeeded in 700ms:
## 2025-09-30 (loops 1-4 summary)
- Established parity backlog: AT-020/021/022/024 failing; created first supervisor plan for AT-021 and enforced prompts/debug.md routing.
- Diagnosed AT-024 random misset cap mismatch (π/2 vs 90 radians) and opened dedicated plan; insisted Ralph stop verification-only loops.
- Flagged torch.compile warm-up overhead (per-instance compilation, inline tensor factories) and opened AT-012 rotation parity plan (Phases A–E).
- Documented performance hotspots (`_compute_physics_for_position` guard tensors, `Crystal.compute_cell_tensors` clamps) and chronic dirty worktree artifacts blocking `git pull --rebase`.

## 2025-09-30 (loops 5-10 summary)
- Authored repo hygiene checklist (REPO-HYGIENE-002) to undo accidental `golden_suite_generator/nanoBragg.c` churn and purge stray reports.
- Created PERF-PYTORCH-004 plan to hoist constants, introduce compile caching, and remove Dynamo graph breaks; reiterated need for prompts/debug.md while parity fails.
- Repeatedly documented routing violations from Ralph and emphasized restoring Core Rule #13 metric duality after WIP commit 058986f swapped `V_actual` for formula volume.
- Noted that `_compute_physics_for_position` still recompiles each Simulator and that benchmarks in `reports/benchmarks/20250930-004916/` show ≥200× slowdown vs C for small detectors.

## 2025-09-30 (ralph debugging loop — AT-012 float32 regression)
- **Context**: AT-PARALLEL-012 test_simple_cubic_correlation failing (43/50 peaks matched, need ≥95%) after DTYPE-DEFAULT-001 (commit 8c2ceb4) switched simulator to native float32.
- **Investigation**:
  * Reproduced: 43/50 peaks matched (86%), corr≈1.0 (perfect physics) ✅
  * Parity matrix test: PASSES perfectly ✅ (live C↔Py comparison with current float32)
  * **Root cause identified**: PyTorch float32 produces 7× more unique values (4901 vs C's 669) in hot pixels, fragmenting intensity plateaus. Peak detection algorithm (scipy.ndimage.maximum_filter) is sensitive to plateau structure.
  * Parallel comparison: C float32 beam center (20×20 ROI) has 91 unique values; PyTorch has 331 (3.6× fragmentation). Max absolute diff tiny (0.0017).
  * **First Divergence**: Numerical accumulation patterns differ (likely FMA, compiler opts, vectorized accumulation order, or torch.compile kernel fusion) → perfect correlation but incompatible plateau structure.
[2025-10-07T19:04:51] tokens used: 28,092

[2025-10-07T19:04:57] thinking

**Preparing to read key documentation files**
[2025-10-07T19:04:58] exec bash -lc 'cat docs/index.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:04:58] bash -lc 'cat docs/index.md' succeeded in 676ms:
# Project Documentation Index

Welcome to the central index for all `nanoBragg-PyTorch` project documentation. This guide provides a map to the key technical specifications, development processes, and historical records that define the project.

---

## 🏛️ Permanent Documentation

These are the core, living documents that guide the project.

### Core Project Guides
### PyTorch Guardrails
* **[PyTorch Runtime Checklist](./development/pytorch_runtime_checklist.md)** – quick do/don’t list for vectorization and device placement. Always review before editing simulator code.
* **[PyTorch Design](./architecture/pytorch_design.md#vectorization-strategy)** – detailed explanation of the required broadcast shapes and batched flows.
* **[Testing Strategy §1.4](./development/testing_strategy.md#14-pytorch-device--dtype-discipline)** – required CPU/GPU smoke tests and compile checks.

* **[CLAUDE.md](../CLAUDE.md)** - The primary instruction set for the AI agent.
* **[README.md](../README.md)** - The main project entry point.
* **[README_PYTORCH.md](../README_PYTORCH.md)** - Comprehensive user guide for the PyTorch implementation, including CLI usage, parallel comparison tools, and visualization.
* **[PROJECT_STATUS.md](../PROJECT_STATUS.md)** - Tracks the current active development initiative.
[2025-10-07T19:04:58] tokens used: 32,088

[2025-10-07T19:05:00] thinking

**Opening spec file**
[2025-10-07T19:05:01] exec bash -lc 'cat specs/spec-a.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:01] bash -lc 'cat specs/spec-a.md' succeeded in 708ms:
# nanoBragg Spec A — Sharded Specification

Spec A is now organized across multiple shards. Read them together for the full normative contract.

- [spec-a-core.md](spec-a-core.md): Core physics, geometry, sampling, data, and associated acceptance tests.
- [spec-a-cli.md](spec-a-cli.md): CLI surface area, precedence rules, and CLI-focused acceptance tests.
- [spec-a-parallel.md](spec-a-parallel.md): Conformance profiles, parallel validation suites, and developer tooling requirements.

Each shard cross-references the others; updates must keep them consistent.
[2025-10-07T19:05:01] tokens used: 33,718

[2025-10-07T19:05:04] thinking

**Considering which spec shards to read**
[2025-10-07T19:05:04] exec bash -lc 'cat specs/spec-a-core.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:05] bash -lc 'cat specs/spec-a-core.md' succeeded in 665ms:
# nanoBragg Spec A — Core Engine

This shard contains the normative physics, geometry, sampling, and data handling requirements. CLI flag semantics live in [spec-a-cli.md](spec-a-cli.md); cross-implementation profiles and developer tooling are captured in [spec-a-parallel.md](spec-a-parallel.md).

Overview (Normative)

- Purpose: Simulates far-field diffraction from a perfect-lattice nanocrystal on a pixelated area
detector. No near-field propagation or detector PSF beyond pixel solid-angle/obliquity is modeled.
No symmetry is imposed; reflection indexing is P1 only (no Friedel pairing).
- Scope: Renders pixel intensities from a set of sources (beam divergence and spectral dispersion),
crystal orientation (including rotation oscillation and mosaic domains), and detector geometry.
Outputs: raw float image, SMV-format integer image (with and without Poisson noise), and optional
PGM.
- Key constants:
    - Classical electron radius squared r_e^2 = 7.94079248018965e-30 m^2.
    - Avogadro’s number = 6.02214179e23 mol^-1.

Units & Conversions (Normative)

- Length:
[2025-10-07T19:05:05] tokens used: 34,085

[2025-10-07T19:05:11] thinking

**Handling large file output limits**
[2025-10-07T19:05:11] exec bash -lc 'wc -l specs/spec-a-core.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:12] bash -lc 'wc -l specs/spec-a-core.md' succeeded in 670ms:
     657 specs/spec-a-core.md
[2025-10-07T19:05:12] tokens used: 43,146

[2025-10-07T19:05:14] thinking

**Continuing to read file in chunks**
[2025-10-07T19:05:15] exec bash -lc "sed -n '200,400p' specs/spec-a-core.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:16] bash -lc "sed -n '200,400p' specs/spec-a-core.md" succeeded in 695ms:
            - For each source:
                - Incident unit vector i = −source_dir (unitized); wavelength λ from source.
                - q = (d − i) / λ (m^-1). stol = 0.5·||q||.
                - If dmin > 0 and stol > 0 and dmin > 0.5/stol: skip this subpath.
                - Polarization factor (if enabled; Kahn model):
                    - cos(2θ) = i·d; sin^2(2θ) = 1 − cos^2(2θ).
                    - Construct B_in = unit(p × i), E_in = unit(i × B_in). Project d into this EB
plane: E_out = d·E_in, B_out = d·B_in. ψ = −atan2(B_out, E_out).
                    - Polarization factor = 0.5·(1 + cos^2(2θ) − K·cos(2ψ)·sin^2(2θ)), where K is
the Kahn factor from -polar.
                - Crystal orientation:
                    - φ step: φ = φ0 + (step index)*phistep; rotate the reference cell (a0,b0,c0)
about u by φ to get (ap,bp,cp).
                    - Mosaic: for each domain, apply the domain’s rotation to (ap,bp,cp) to get
(a,b,c).
                - Fractional Miller indices: h = a·q, k = b·q, l = c·q (dimensionless).
                - Nearest integer triplet: (h0, k0, l0) = round to nearest via ceil(x − 0.5).
                - Lattice factor F_latt:
                    - SQUARE (grating): F_latt = sincg(π·h, Na) · sincg(π·k, Nb) · sincg(π·l, Nc),
where
[2025-10-07T19:05:16] tokens used: 46,595

[2025-10-07T19:05:17] thinking

**Requesting more lines**
[2025-10-07T19:05:18] exec bash -lc "sed -n '400,657p' specs/spec-a-core.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:19] bash -lc "sed -n '400,657p' specs/spec-a-core.md" succeeded in 705ms:
- Example 2:
    - ./nanoBragg -mat A.mat -hkl P1.hkl -lambda 1 -dispersion 0.1 -dispstep 3 -distance 100
-detsize 100 -pixel 0.1 -hdiv 0.28 -hdivstep 0.02 -vdiv 0.28 -vdivstep 0.02 -fluence 1e24 -N 0
-water 0
    - Unsupported flags: -dispstep (use -dispsteps <int>), -hdiv (use -hdivrange), -vdiv (use
-vdivrange).
    - After replacing unsupported flags with supported ones:
        - λ = 1 Å = 1e-10 m. Dispersion = 0.1 (10%); choose -dispsteps 3 if that was intended.
        - Distance = 0.1 m; detsize = 0.1 m; pixel = 0.1 mm; fluence = 1e24 photons/m^2.
        - With -hdivrange 0.28 mrad, -hdivstep 0.02 mrad, -vdivrange 0.28 mrad, -vdivstep 0.02
mrad, auto-selection yields horizontal steps = ceil(0.28/0.02)=14, similarly vertical = 14, then
elliptical trimming reduces the count (only those within the ellipse kept).
        - -N 0 results in Na=Nb=Nc=1 (clamped to ≥1).
        - -water 0 disables the background term (I_bg still set but becomes 0 since size=0).
        - Steps = (#accepted divergence points) × dispsteps × mosaic_domains × phisteps ×
oversample^2. With default mosaic (spread 0) and φ defaults, this reduces to (ellipse points × 3
× oversample^2).
- Example 3:
    - ./nanoBragg -cell 74 74 36 90 90 90 -misset 10 20 30 -hkl P1.hkl -lambda 1 -dispersion 0.1
-dispstep 3 -distance 100 -detsize 100 -pixel 0.1 -hdiv 0.28 -hdivstep 0.02 -vdiv 0.28 -vdivstep
[2025-10-07T19:05:19] tokens used: 49,473

[2025-10-07T19:05:21] thinking

**Identifying additional specs to check**
[2025-10-07T19:05:23] exec bash -lc 'cat specs/spec-a-cli.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:23] bash -lc 'cat specs/spec-a-cli.md' succeeded in 704ms:
# nanoBragg Spec A — CLI Binding

This shard documents the command-line interface, header precedence, and CLI-focused acceptance tests. It should be read alongside [spec-a-core.md](spec-a-core.md) for the simulation engine requirements and [spec-a-parallel.md](spec-a-parallel.md) for conformance profiles.

CLI Interface (Normative)

All options recognized by this code version are enumerated below. Values with units are converted
immediately as specified in Units & Conversions. Unsupported flags are not recognized even if
present in header comments.

- Input files:
    - -hkl <file>: Text file of “h k l F” (integers h,k,l; real F). Required unless Fdump.bin exists
or -default_F used.
    - -mat <file>: 3×3 MOSFLM-style A matrix (reciprocal cell vectors scaled by 1/λ). Required
unless -cell used.
    - -cell a b c alpha beta gamma: Direct cell in Å and degrees; alternative to -mat.
    - -img <file>: Read SMV header; may set fpixels, spixels, pixel size (mm), distance (mm), close
distance (mm), wavelength (Å), beam centers (mm), ORGX/ORGY (pixels), φ start (deg), oscillation
range (deg), 2θ (deg). Image data is read but not used.
    - -mask <file>: Read SMV mask; uses same headers to initialize geometry as -img. Zero-valued
[2025-10-07T19:05:23] tokens used: 55,429

[2025-10-07T19:05:26] thinking

**Assessing task complexity**
[2025-10-07T19:05:26] exec bash -lc 'cat specs/spec-a-parallel.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:27] bash -lc 'cat specs/spec-a-parallel.md' succeeded in 700ms:
# nanoBragg Spec A — Conformance & Parallel Tests

This shard enumerates the CLI profile acceptance tests, parallel validation suite, developer tooling expectations, and conformance profiles. Review [spec-a-core.md](spec-a-core.md) for base requirements and [spec-a-cli.md](spec-a-cli.md) for CLI semantics referenced here.

Parallel Validation Tests (Profile: C-PyTorch Equivalence) — Acceptance Tests (Normative)

References: ../docs/development/testing_strategy.md (parallel trace-driven validation), ../docs/debugging/debugging.md (trace SOP), ../docs/debugging/detector_geometry_checklist.md (detector geometry triage), ../docs/architecture/undocumented_conventions.md (hidden C behaviors)
Why: testing_strategy and debugging.md define the parallel trace methodology; the detector checklist accelerates geometry debugging; undocumented_conventions flags hidden C behaviors that often break equivalence.

These tests verify that PyTorch implementation produces outputs equivalent to the C reference implementation. They apply to implementations claiming the C-PyTorch Equivalence Profile. These are black-box behavioral tests comparing outputs without examining internal implementation details.

- AT-PARALLEL-001 Beam Center Scales with Detector Size
  - Setup: Test detector sizes 64x64, 128x128, 256x256, 512x512, 1024x1024 pixels with 0.1mm pixel size, cubic crystal 100Å N=3, λ=6.2Å
  - Expectation: Beam center (mm) SHALL equal detector_pixels/2 × pixel_size_mm; Peak SHALL appear at detector center ±2 pixels; Correlation between C and PyTorch ≥0.9999
  - Failure mode: Fixed beam center at 51.2mm regardless of detector size
  - Implementation:
    - Parity (canonical): `KMP_DUPLICATE_LIB_OK=TRUE NB_RUN_PARALLEL=1 NB_C_BIN=./golden_suite_generator/nanoBragg pytest -v tests/test_parity_matrix.py -k "AT-PARALLEL-001"`
    - Supplemental PyTorch-only regression: `pytest -v tests/test_at_parallel_001.py`

- AT-PARALLEL-002 Pixel Size Independence
[2025-10-07T19:05:27] tokens used: 61,865

[2025-10-07T19:05:28] thinking

**Continuing to read specification**
[2025-10-07T19:05:29] exec bash -lc "sed -n '200,400p' specs/spec-a-parallel.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:30] bash -lc "sed -n '200,400p' specs/spec-a-parallel.md" succeeded in 692ms:

- AT-TOOLS-001 Dual-Runner Comparison Script
  - Purpose: Run the C and PyTorch implementations with identical arguments; capture runtimes; compute comparison metrics; save preview images and a reproducible artifact bundle.
  - Scope: Optional developer tooling. This AT is normative for the script’s behavior and outputs, but it does NOT gate Core Engine or C–PyTorch Equivalence conformance and is not counted in AT-PARALLEL totals.
  - Invocation:
    - Script name SHOULD be exposed as a console entry `nb-compare` (preferred) or available at `scripts/nb_compare.py`.
    - Usage: `nb-compare [--outdir DIR] [--roi xmin xmax ymin ymax] [--threshold T] [--resample] [--png-scale PCTL] [--save-diff] [--c-bin PATH] [--py-bin PATH] -- ARGS...`
    - ARGS... are forwarded unchanged to both runners (C and PyTorch).
    - Binary resolution: C runner from `--c-bin` or `NB_C_BIN` env (default `./nanoBragg` in CWD); PyTorch runner from `--py-bin` or `NB_PY_BIN` env (default `nanoBragg` on PATH or `python -m nanobrag_torch`).
  - Behavior:
    - Preflight: verify both runners are executable; ensure any float outputs are captured even if caller did not pass `-floatfile` by adding separate temp paths per runner; preserve and log original stdout/stderr.
    - Runtime capture: run C first then PyTorch using identical ARGS; measure wall time using a monotonic clock; print `C runtime: X.XXX s` and `Py runtime: Y.YYY s`.
    - Load float outputs for metrics. If shapes differ: without `--resample` exit with error code 4; with `--resample`, resize PyTorch image to C’s shape via nearest-neighbor and note this in the summary.
    - ROI: if provided, compute metrics on the ROI, otherwise on the full frame.
  - Metrics (on float images after ROI/resample as applicable):
    - Pearson correlation coefficient (flattened ROI), MSE, RMSE, max absolute difference, total sums (C_sum, Py_sum) and their ratio.
    - Optional SSIM MAY be included.
    - Prints a one-line summary and a small table to stdout.
  - Outputs (unique artifact directory):
    - Directory: `comparisons/YYYYMMDD-HHMMSS-<short-hash>` where `<short-hash>` is a hash of canonicalized ARGS.
[2025-10-07T19:05:30] tokens used: 64,972

[2025-10-07T19:05:32] thinking

**Moving on to arch.md**
[2025-10-07T19:05:32] exec bash -lc 'cat arch.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:32] bash -lc 'cat arch.md' succeeded in 711ms:
# nanoBragg PyTorch — Implementation Architecture

Document version: 1.0 (aligned with specs/spec-a.md)
Target spec: specs/spec-a.md (single-file normative spec)
Implementation target: Python (>=3.11) + PyTorch (float32 default). Type blocks may use TypeScript-style for clarity; implement with Python dataclasses and torch tensors.

## Running The CLI

- Install (recommended):
  - `pip install -e .` from repo root (provides `nanoBragg` console script).
- Run (installed):
  - `nanoBragg -hkl P1.hkl -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -floatfile out.bin`
- Run (without install):
  - `PYTHONPATH=src python -m nanobrag_torch -hkl P1.hkl -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -floatfile out.bin`
- Minimal quick test (no HKL):
  - `nanoBragg -default_F 1 -cell 100 100 100 90 90 90 -lambda 1.0 -distance 100 -detpixels 128 -pgmfile test.pgm`

Notes
- Entry point: `src/nanobrag_torch/__main__.py` (module runner `python -m nanobrag_torch`).
- Required inputs: provide `-hkl` (or existing `Fdump.bin`) or set `-default_F > 0`, and either `-mat` (MOSFLM A*) or `-cell`.
[2025-10-07T19:05:32] tokens used: 72,991

[2025-10-07T19:05:34] thinking

**Preparing to review PyTorch config docs**
[2025-10-07T19:05:35] exec bash -lc 'cat docs/development/c_to_pytorch_config_map.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:36] bash -lc 'cat docs/development/c_to_pytorch_config_map.md' succeeded in 704ms:
# C-CLI to PyTorch Configuration Map

## Critical Importance Notice

**This document is the authoritative source of truth for configuration parity between nanoBragg.c and the PyTorch implementation.**

Before writing any test or implementation that involves C-code validation, you **MUST** consult this document. Failure to ensure 1:1 configuration parity is the most common source of bugs, particularly with:
- Implicit pivot mode logic
- Convention-dependent beam center calculations
- Rotation axis defaults
- Unit conversions

## Quick Reference Table

### Crystal Parameters

| C-CLI Flag | PyTorch Config Field | C Variable | Units/Convention | Critical Notes |
|------------|---------------------|------------|------------------|----------------|
| `-cell a b c al be ga` | `CrystalConfig.cell_a/b/c/alpha/beta/gamma` | `a[0], b[0], c[0], alpha, beta, gamma` | Å and degrees → radians | Must convert degrees to radians internally |
| `-N <val>` | `CrystalConfig.N_cells` | `Na, Nb, Nc` | Number of unit cells | Sets all three axes to same value |
[2025-10-07T19:05:36] tokens used: 77,111

[2025-10-07T19:05:37] thinking

**Locating debugging documentation**
[2025-10-07T19:05:38] exec bash -lc 'cat docs/debugging/debugging.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:38] bash -lc 'cat docs/debugging/debugging.md' succeeded in 694ms:
# nanoBragg PyTorch Debugging Guidelines

**Version:** 1.1  
**Date:** 2024-07-25  
**Owner:** PyTorch Development Team

## Overview

This document outlines the debugging methodology and tools for the nanoBragg PyTorch implementation. The debugging approach is built around a parallel trace comparison between the C code and the PyTorch implementation to ensure correctness and facilitate rapid issue resolution.

## Core Debugging Philosophy

### Parallel Trace Comparison Rule

**CRITICAL:** All debugging of physics discrepancies MUST begin with a parallel trace comparison. This involves:
1. Generating a detailed, step-by-step log of intermediate variables from the original C code for a specific pixel (the "Golden Trace").
2. Generating an identical log from the PyTorch implementation using `scripts/debug_pixel_trace.py`.
3. Comparing these two logs line-by-line to find the first point of divergence.

This methodology is mandatory to avoid guesswork and ensure bugs are found deterministically.
[2025-10-07T19:05:38] tokens used: 82,399

[2025-10-07T19:05:41] thinking

**Checking file size of fix_plan.md**
[2025-10-07T19:05:41] exec bash -lc 'wc -l docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:42] bash -lc 'wc -l docs/fix_plan.md' succeeded in 690ms:
    2353 docs/fix_plan.md
[2025-10-07T19:05:42] tokens used: 86,577

[2025-10-07T19:05:47] thinking

**Planning selective file reading**

I’m considering carefully how to handle this large 2353-line file—reading it all might be necessary but time-consuming. I’ll try to focus on sections that mention current goals or relevant IDs, maybe using tools like `sed` or `rg` to extract only the important parts. First, I want to scan the first 200 lines to get an overview and find any table of contents that can guide my reading.
[2025-10-07T19:05:49] exec bash -lc "sed -n '1,200p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:50] bash -lc "sed -n '1,200p' docs/fix_plan.md" succeeded in 679ms:
# Fix Plan Ledger

**Last Updated:** 2025-10-22 (ralph loop #103)
**Active Focus:**
- ROUTING: Close the reopened guard plan by capturing a fresh regression audit referencing commit `c49e3be` and re-confirming the guarded `loop.sh` flow (`plans/active/routing-loop-guard/plan.md` Phases A–C) before automation resumes.
- ROUTING-SUPERVISOR: Launch Phase A of `plans/active/supervisor-loop-guard/plan.md`, then drive Phase B guard work (B2–B4) and new task B5 to add `supervisor.sh` to docs/index.md so Protected-Asset policy covers the script before automation runs again.
- AT-012: Plan archived (`plans/archive/at-parallel-012-plateau-regression/plan.md`); monitor for regressions using `reports/2025-10-AT012-regression/phase_c_validation/` artifacts and re-open only if peak matches drop below spec.
- GRADIENT: Execute `plans/active/gradcheck-tier2-completion/plan.md` Phase A (A1–A3 baseline audit + env alignment) before adding misset/beam gradchecks from Phases B/C; once pass logs exist, close `[AT-TIER2-GRADCHECK]` with Phase D documentation updates.
- DTYPE: ✅ Complete. Plan archived to `plans/archive/dtype-default-fp32/`. All phases (A-D) finished; float32 defaults documented in arch.md, pytorch_runtime_checklist.md, CLAUDE.md, prompts/debug.md.
- PERF: Land plan task B7 (benchmark env toggle fix), rerun Phase B6 ten-process reproducibility with the new compile metadata, capture the weighted-source parity memo feeding C5, then execute Phase C diagnostics (C1/C2 plus C8/C9 pixel-grid & rotated-vector cost probes, and new C10 mosaic RNG timing) ahead of Phase D caching work (D5/D6/D7) and detector-scalar hoisting (D8).

## Index
| ID | Title | Priority | Status |
| --- | --- | --- | --- |
| [PROTECTED-ASSETS-001](#protected-assets-001-docsindexmd-safeguard) | Protect docs/index.md assets | Medium | in_progress |
| [REPO-HYGIENE-002](#repo-hygiene-002-restore-canonical-nanobraggc) | Restore canonical nanoBragg.c | Medium | in_progress |
| [PERF-PYTORCH-004](#perf-pytorch-004-fuse-physics-kernels) | Fuse physics kernels | High | in_progress |
| [AT-TIER2-GRADCHECK](#at-tier2-gradcheck-implement-tier-2-gradient-correctness-tests) | Implement Tier 2 gradient correctness tests | High | in_progress |
| [VECTOR-TRICUBIC-001](#vector-tricubic-001-vectorize-tricubic-interpolation-and-detector-absorption) | Vectorize tricubic interpolation and detector absorption | High | in_progress |
| [ABS-OVERSAMPLE-001](#abs-oversample-001-fix-oversample_thick-subpixel-absorption) | Fix -oversample_thick subpixel absorption | High | in_planning |
[2025-10-07T19:05:50] tokens used: 86,934

[2025-10-07T19:05:52] thinking

**Searching for CLI-FLAGS-003 in docs**
[2025-10-07T19:05:53] exec bash -lc 'rg -n "CLI-FLAGS-003" docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:54] bash -lc 'rg -n "CLI-FLAGS-003" docs/fix_plan.md' succeeded in 716ms:
22:| [CLI-FLAGS-003](#cli-flags-003-handle-nonoise-and-pix0_vector_mm) | Handle -nonoise and -pix0_vector_mm | High | in_progress |
450:## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
626:      - C trace evidence indicates state carryover within the reference implementation. Until we either patch the C code or emulate this behavior, PyTorch must conform to the reference output to unblock CLI-FLAGS-003.
[2025-10-07T19:05:54] tokens used: 90,024

[2025-10-07T19:05:56] thinking

**Continuing to read the file**
[2025-10-07T19:05:57] exec bash -lc "sed -n '450,700p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:05:57] bash -lc "sed -n '450,700p' docs/fix_plan.md" succeeded in 703ms:
## [CLI-FLAGS-003] Handle -nonoise and -pix0_vector_mm
- Spec/AT: specs/spec-a-cli.md flag catalogue, docs/architecture/detector.md §5 (pix0 workflow), docs/development/c_to_pytorch_config_map.md (pivot rules), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860
- Priority: High
- Status: in_progress (Phases A–H complete; K3a/K3b/K3d landed via Attempts #43–44, pending per-φ evidence + normalization closure)
- Owner/Date: ralph/2025-10-05
- Plan Reference: `plans/active/cli-noise-pix0/plan.md`
- Reproduction (C & PyTorch):
  * C: Run the supervisor command from `prompts/supervisor.md` (with and without `-nonoise`) using `NB_C_BIN=./golden_suite_generator/nanoBragg`; capture whether the noisefile is skipped and log `DETECTOR_PIX0_VECTOR`.
  * PyTorch: After implementation, `nanoBragg` CLI should parse the same command, respect the pix0 override, and skip noise writes when `-nonoise` is present.
- First Divergence (if known): Phase L2c comparison shows all scaling factors (ω, polarization, r_e², fluence, steps) match C within 0.2%, but `I_before_scaling` diverges because PyTorch reports `F_cell=0` at hkl≈(−7,−1,−14) while C's trace records `F_cell=190.27`. **Phase L3b (Attempt #76) proved the data exists (scaled.hkl contains F=190.27 for this reflection); root cause is configuration/loading, NOT missing coverage.**
- Next Actions (2025-11-22 refresh → galph):
1. Phase L3k.3b — Regenerate the C per-φ trace that pairs with the 20251123 PyTorch probe: rebuild the instrumented `golden_suite_generator/nanoBragg`, rerun the supervisor command with `TRACE_C_PHI` enabled, drop the output under `base_vector_debug/20251123/`, and rerun `scripts/compare_per_phi_traces.py` so `delta_metrics.json` and VG-1 entries show numeric deltas instead of `status="BLOCKED"`. If reuse of the 202510070839 trace is preferred, update the harness paths accordingly and record the decision in `diagnosis.md` and `commands.txt`.
2. Phase L3k.3c.2 — With both traces available, compute Δb_y and Δk_frac for φ=0/φ₉, update `diagnosis.md` plus `fix_checklist.md` VG-1.4 with the measured gaps, and outline the vectorized carryover remediation (e.g., φ==0 mask) before touching simulator code.
3. Phase L3k.3d — Resolve the nb-compare ROI anomaly (C sum≈0) before repeating VG-3/VG-4; capture the corrected summary.json/logs under `nb_compare_phi_fix/` once correlation ≥0.9995 and sum_ratio 0.99–1.01. After VG-1/VG-3/VG-4 pass, proceed to L3k.3e → L3k.4 documentation and fix_plan logging ahead of the Phase L4 supervisor-command rerun.
- Attempts History:
  * [2025-11-21] Attempt #95 (galph supervisor loop) — Result: **PLANNING UPDATE** (Phase L3k added). **No code changes.**
    Metrics: Planning-only (no tests executed).
    Artifacts:
      - `plans/active/cli-noise-pix0/plan.md` — New Phase L3k section outlining implementation gates.
      - `docs/fix_plan.md` — Next Actions retargeted to Phase L3k; checklist referenced.
[2025-10-07T19:05:57] tokens used: 95,929

[2025-10-07T19:05:59] thinking

**Preparing to review testing strategy**
[2025-10-07T19:06:00] exec bash -lc 'cat docs/development/testing_strategy.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:00] bash -lc 'cat docs/development/testing_strategy.md' succeeded in 726ms:
# nanoBragg PyTorch Testing Strategy

**Version:** 1.1  
**Date:** 2024-07-25  
**Owner:** [Your Name/Team]

## 1. Introduction & Philosophy

This document outlines the comprehensive testing strategy for the PyTorch implementation of nanoBragg. The primary goal is to ensure that the new application is a correct, verifiable, and trustworthy scientific tool.
Our testing philosophy is a three-tiered hybrid approach, designed to build confidence layer by layer:

1. **Tier 1: Translation Correctness:** We first prove that the PyTorch code is a faithful, numerically precise reimplementation of the original C code's physical model. The C code is treated as the "ground truth" specification.
2. **Tier 2: Gradient Correctness:** We then prove that the new differentiable capabilities are mathematically sound.
3. **Tier 3: Scientific Validation:** Finally, we validate the model against objective physical principles.

All tests will be implemented using the PyTest framework.

### 1.4 PyTorch Device & Dtype Discipline

- **Device-neutral code:** Every PyTorch path MUST operate correctly on both CPU and CUDA tensors and across supported dtypes. Do not hard-code `.cpu()`/`.cuda()` calls, create CPU-only constants, or assume float64 execution when the caller may supply float32/half tensors.
[2025-10-07T19:06:00] tokens used: 99,909

[2025-10-07T19:06:03] thinking

**Beginning detailed codebase analysis**
[2025-10-07T19:06:04] exec bash -lc 'cat plans/active/cli-noise-pix0/plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:04] bash -lc 'cat plans/active/cli-noise-pix0/plan.md' succeeded in 680ms:
## Context
- Initiative: CLI Parity for nanoBragg PyTorch vs C (supports long-term goal in prompts/supervisor.md)
- Phase Goal: Accept `-nonoise` and `-pix0_vector_mm` flags with C-equivalent semantics so the parallel comparison command in prompts/supervisor.md executes end-to-end.
- Dependencies: specs/spec-a-cli.md §§3.2–3.4, docs/architecture/detector.md §5, docs/development/c_to_pytorch_config_map.md (detector pivot + noise), golden_suite_generator/nanoBragg.c lines 720–1040 & 1730–1860 (flag behavior), docs/debugging/detector_geometry_checklist.md (pix0 validation), docs/development/testing_strategy.md §2 (CLI parity tests).
- Gap snapshot update (2025-11-23): Attempt #108 gathered fresh PyTorch φ=0 state probes (reports/.../20251123/) confirming the rotation fix keeps φ=0 identical to base vectors, but the per-φ comparison pipeline could not locate a coeval C trace. Phase L3k.3b must regenerate TRACE_C_PHI output (or retarget the script to the existing 202510070839 asset) before VG-1 deltas can be recomputed.
- Current gap snapshot (2025-10-18 refresh): Phase H4 parity landed (Attempt #25) with pix0 deltas < 2e-8 m and regression tolerances tightened; the remaining blocker before executing the supervisor command end-to-end is Phase I polarization alignment.
- Gap snapshot refresh (2025-10-07 08:41): Attempt #101 activated TRACE_C_PHI (C instrumentation) and captured matching Py per-φ traces. Divergence isolated to φ_tic=0 (Δk≈1.81e-2) while φ>0 steps remain within 3e-5. Phase L3k.3 moves to φ=0 initialization parity (L3k.3c) plus ROI/nb-compare follow-ups.
- Gap snapshot update (2025-10-19): Attempt #27 parity run reveals 1.24538e5× intensity scaling mismatch despite polarization fix; Phases J–L track the normalization diagnosis, fix, and closure required before long-term Goal #1 completes.
- Gap snapshot refresh (2025-10-22): Attempt #31 restored C precedence for custom detector vectors (pix0 override now gated again). Outstanding work: H5c PyTorch traces and Phase K normalization to eliminate the `F_latt`-driven intensity gap.
- Gap snapshot update (2025-10-24): Attempt #35 reran the PyTorch trace harness post-unit-fix; metrics still show |Δpix0| ≈ 1.145 mm, so a fresh diagnostics phase is required before resuming normalization work.
- Gap snapshot refresh (2025-10-26): Attempt #40 completed Phase H6f — custom detector vectors now force SAMPLE pivot parity, parity visuals relocated under `reports/2025-10-cli-flags/phase_h6/visuals/`, and targeted regression tests cover pivot selection. Outstanding work at that point: Phase H6g trace rerun to confirm |Δpix0| < 5e-5 m before returning to Phase K scalings.
- Gap snapshot update (2025-10-27): Attempt #41 validated Phase H6g — SAMPLE pivot parity holds with pix0 deltas ≤2.85 µm, beam center deltas 0.0, and supporting artifacts under `reports/2025-10-cli-flags/phase_h6/post_fix/`. Remaining blockers: rerun the scaling chain (Phase K2), execute the scaling regression + doc updates (Phase K3), then resume Phase L parity once normalization matches C.
- Gap snapshot refresh (2025-11-09): Attempt #49 closed Phase K3g3 — `tests/test_cli_scaling.py::test_f_latt_square_matches_c` now passes after isolating the HKL cache, but the full supervisor command still shows correlation ≈ 0.9965 and sum_ratio ≈ 1.26×10⁵. Need fresh HKL/normalization parity evidence (Phase L) before rerunning nb-compare.
- Gap snapshot refresh (2025-11-10): Attempt #56 (evidence loop) proved the existing `TRACE_PY` path prints placeholder scaling data (`capture_fraction 1`, `polar 1.0`, `steps`=φ-steps only). Without exposing the real per-pixel factors computed in `Simulator.run`, Phase L2b cannot produce a trustworthy PyTorch trace. Instrumentation must pull actual values from `_apply_detector_absorption`, polarization kernels, and total-step calculation before rerunning the harness.
- Gap snapshot update (2025-10-17): Attempt #53 (Phase L1c) realigned HKL Fdump I/O with C padding (`read_fdump`/`write_fdump`) and added regression coverage (`TestHKLFdumpParity::test_scaled_hkl_roundtrip`) with max |ΔF| = 0.0. Proceed to L1d to regenerate parity metrics before reviving scaling traces.
- Gap snapshot update (2025-11-11): Discovered the trace harness omitted `-beam_vector`, `-flux`, and `-beamsize`, forcing oversample=4 and a +Z beam; Py traces zeroed `F_cell` and inflated `steps`. Marked unresolved pending harness fix.
- Gap snapshot refresh (2025-11-12): Attempt #66 (commit 1d2e6ac) completed Phase L2b0 — the trace harness now feeds the full supervisor flag set, and the refreshed `trace_py_scaling.log` confirms `steps=10`, `fluence≈1.0e24`, and `r_e^2` parity with C. TRACE_PY still reports `I_before_scaling NOT_EXTRACTED`, `polar=0`, and `I_pixel_final=0`, so Phase L2b instrumentation must surface the real polarization/absorption tensors before we can quantify the K3e k_frac drift.
- Gap snapshot update (2025-11-13): Latest harness rerun aborted because `trace_harness.py` still expected the legacy `read_hkl_file` return tuple (see `trace_py_fullrun.log`). **Resolved in Attempt #74, which updated the harness to the `(F_grid, metadata)` signature.**
- Gap snapshot refresh (2025-11-14): Attempt #73 showed `Crystal.hkl_data` unset (leading to `F_cell=0`), keeping L2b open; **Attempt #74 fixed this by wiring the HKL tensor/metadata before Simulator construction.**
- Gap snapshot refresh (2025-11-15): Attempts #69/#71/#74 finished Phase L2 — TRACE_PY now reports real scaling factors, `scaling_audit_summary.md` flags `I_before_scaling` as the lone divergence, and C shows `F_cell=190.27` for hkl=(-7,-1,-14) while PyTorch remains at 0. Next phase focuses on understanding how C derives that amplitude (likely via generated `Fdump.bin`) before touching normalization code.
[2025-10-07T19:06:04] tokens used: 102,555

[2025-10-07T19:06:07] thinking

**Planning by reviewing vectorization.md**
[2025-10-07T19:06:07] exec bash -lc 'ls plans/active' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:08] bash -lc 'ls plans/active' succeeded in 707ms:
cli-noise-pix0
gradcheck-tier2-completion
oversample-thick-subpixel.md
perf-pytorch-compile-refactor
routing-loop-guard
source-weight-normalization.md
supervisor-loop-guard
unification.md
vectorization.md
[2025-10-07T19:06:08] tokens used: 111,154

[2025-10-07T19:06:11] thinking

**Reviewing vectorization plan**
[2025-10-07T19:06:12] exec bash -lc 'cat plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:12] bash -lc 'cat plans/active/vectorization.md' succeeded in 692ms:
## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.

### Phase A — Evidence & Baseline Capture
Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.
Prereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.
Exit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [D] | ✅ Completed 2025-10-06 (`reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`). Re-run only if dependencies change or new warnings appear. |
| A2 | Measure current tricubic runtime | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/tricubic_baseline.py` created; CPU & CUDA baselines captured in `phase_a/tricubic_baseline.md` and `phase_a/tricubic_baseline_results.json`). Key finding: scalar-only implementation @ ~1.4 ms/call (CPU), ~5.5 ms/call (CUDA). |
| A3 | Record detector absorption baseline | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/absorption_baseline.py` created; CPU & CUDA baselines captured in `phase_a/absorption_baseline.md` and `phase_a/absorption_baseline_results.json`). GPU shows 5.4× speedup for 512² detector. |

### Phase B — Tricubic Vectorization Design
Goal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.
[2025-10-07T19:06:12] tokens used: 114,302

[2025-10-07T19:06:15] thinking

**Reviewing remaining content**
[2025-10-07T19:06:17] exec bash -lc "sed -n '200,400p' plans/active/vectorization.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:18] bash -lc "sed -n '200,400p' plans/active/vectorization.md" succeeded in 718ms:

[2025-10-07T19:06:18] tokens used: 115,756

[2025-10-07T19:06:20] thinking

**Checking file length**
[2025-10-07T19:06:20] exec bash -lc 'wc -l plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:21] bash -lc 'wc -l plans/active/vectorization.md' succeeded in 699ms:
      90 plans/active/vectorization.md
[2025-10-07T19:06:21] tokens used: 115,891

[2025-10-07T19:06:23] thinking

**Checking for truncated output**
[2025-10-07T19:06:24] exec bash -lc "sed -n '90p' plans/active/vectorization.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:25] bash -lc "sed -n '90p' plans/active/vectorization.md" succeeded in 701ms:
| G2 | Close planning artifacts | [ ] | Move key reports to `reports/archive/` (retain relative paths), update docs/fix_plan.md Attempts with final metrics, and archive this plan per SOP. |
[2025-10-07T19:06:25] tokens used: 116,133

[2025-10-07T19:06:32] thinking

**Verifying full file output**
[2025-10-07T19:06:33] exec bash -lc 'cat plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:33] bash -lc 'cat plans/active/vectorization.md' succeeded in 689ms:
## Context
- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.

### Phase A — Evidence & Baseline Capture
Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.
Prereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.
Exit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| A1 | Re-run tricubic acceptance tests | [D] | ✅ Completed 2025-10-06 (`reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`). Re-run only if dependencies change or new warnings appear. |
| A2 | Measure current tricubic runtime | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/tricubic_baseline.py` created; CPU & CUDA baselines captured in `phase_a/tricubic_baseline.md` and `phase_a/tricubic_baseline_results.json`). Key finding: scalar-only implementation @ ~1.4 ms/call (CPU), ~5.5 ms/call (CUDA). |
| A3 | Record detector absorption baseline | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/absorption_baseline.py` created; CPU & CUDA baselines captured in `phase_a/absorption_baseline.md` and `phase_a/absorption_baseline_results.json`). GPU shows 5.4× speedup for 512² detector. |

### Phase B — Tricubic Vectorization Design
Goal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.
[2025-10-07T19:06:33] tokens used: 116,469

[2025-10-07T19:06:39] thinking

**Noticing output truncation**
[2025-10-07T19:06:40] exec bash -lc "sed -n '40,140p' plans/active/vectorization.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:41] bash -lc "sed -n '40,140p' plans/active/vectorization.md" succeeded in 711ms:
| C3 | Add shape assertions & cache hooks | [D] | ✅ Completed 2025-10-07 (Attempt #6). Shape assertions added for `(B, 4, 4, 4)` neighborhoods and output shapes; device consistency checks ensure tensors stay on input device. No explicit caching present in tricubic path. All targeted tests passing (5 gather + 1 acceptance). Artifacts: `reports/2025-10-vectorization/phase_c/{test_tricubic_vectorized.log, test_at_str_002_phi.log, implementation_notes.md}`. Code refs: `crystal.py:414-427` (shape/device assertions), `crystal.py:440-447` (scalar output assertions), `crystal.py:461-462` (batched fallback assertions). |

#### Phase C3 Verification Checklist
| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| C3.1 | Assertion coverage | [D] | ✅ Completed. Added `assert sub_Fhkl.shape == (B, 4, 4, 4)`, `assert h_indices.shape == (B, 4)` (k,l similar), plus output assertions `F_cell.numel() == 1` (scalar) and `result.shape == original_shape` (both paths). Code refs: `crystal.py:414-420, 440-447, 461-462`. Documented in `implementation_notes.md` Phase C3 section. |
| C3.2 | Device-aware caching audit | [D] | ✅ Completed. No caching exists in `_tricubic_interpolation`. Added device checks: `assert sub_Fhkl.device == h.device`, `assert h_indices.device == h.device`. Verified device propagation: offsets use `device=self.device`, grids inherit from inputs, `.to(dtype=)` preserves device. Code ref: `crystal.py:422-427`. Audit documented in `implementation_notes.md` §2. |
| C3.3 | Targeted pytest evidence | [D] | ✅ Completed. Ran `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Logs stored: `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log` and `test_at_str_002_phi.log`. Total 6/6 tests passed; CPU + CUDA paths validated. |

### Phase D — Implementation: Polynomial Evaluation
Goal: Vectorize `polint`, `polin2`, and `polin3` so they consume batches from Phase C without Python loops.
Prereqs: Phase C merged or staged with passing tests.
Exit Criteria: All polynomial helpers accept batched tensors, no Python loops over pixels remain, and helper-level unit tests exist.

| ID | Task Description | State | How/Why & Guidance |
| --- | --- | --- | --- |
| D1 | Vectorize `polint` | [ ] | Rewrite using tensor broadcasting; support trailing batch dims and ensure numerical stability matches C (consider Kahan-style compensation if necessary). Add regression test in `tests/test_tricubic_vectorized.py::test_polint_vectorized_matches_scalar`. |
| D2 | Vectorize `polin2`/`polin3` | [ ] | Stack vectorized `polint` results instead of looping; maintain compatibility with scalar callers (if any). Capture proof-of-equivalence logs in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`. |
| D3 | Audit differentiability | [ ] | Run `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_gradients.py::TestCrystal::test_tricubic_gradient -v` (add test if absent) to confirm gradients survive the refactor. |

[2025-10-07T19:06:41] tokens used: 174,151

[2025-10-07T19:06:53] thinking

**Reviewing long-term goals and plans**

I’m focusing on analyzing the codebase and plans related to running parallel PyTorch vs C tests and advancing vectorization work. I want to check the current progress, identify gaps—especially around CLI-FLAGS-003—and understand what instructions Ralph has for upcoming tasks by reviewing input and plan files. This will help me know what to update or delegate next.
[2025-10-07T19:06:56] exec bash -lc 'cat input.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:06:57] bash -lc 'cat input.md' succeeded in 883ms:
Summary: Regenerate the C per-φ trace and recompute VG-1 deltas so CLI-FLAGS-003 Phase L3k.3b is unblocked.
Mode: Parity
Focus: CLI-FLAGS-003 Phase L3k.3b TRACE_C_PHI rerun
Branch: feature/spec-based-2
Mapped tests: env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q
Artifacts: reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.json; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_stdout_20251123.txt; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/delta_metrics.json; reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md (L3k.3c.2 update); reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/sha256.txt
Do Now: CLI-FLAGS-003 (Handle -nonoise and -pix0_vector_mm) — execute Phase L3k.3b by rebuilding the instrumented C binary, rerunning the supervisor command with -trace_pixel 685 1039 to capture `c_trace_phi_20251123.log`, regenerating the PyTorch per-φ trace via `trace_harness.py`, and re-running `scripts/compare_per_phi_traces.py` so VG-1 deltas populate under the 20251123 timestamp before recording the updated metrics in diagnosis.md. Finish with env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q.
If Blocked: If the instrumented C binary is missing TRACE_C_PHI output, re-apply the instrumentation patch (see golden_suite_generator/nanoBragg.c:3156-3160), rerun `make -C golden_suite_generator`, and retry the command. If C still cannot be rebuilt on this machine, copy `c_trace_phi_202510070839.log` into the 20251123 directory, document the reuse decision in diagnosis.md, flag the delta computation as provisional inside delta_metrics.json, and stop after updating commands.txt + sha256.txt.
Priorities & Rationale:
- plans/active/cli-noise-pix0/plan.md:288 — L3k.3 requires a fresh TRACE_C_PHI run paired with the 20251123 PyTorch probe before VG-1 can progress.
- plans/active/cli-noise-pix0/plan.md:300 — L3k.3c.2 stays [P] until Δb_y/Δk_frac are measured and logged.
- docs/fix_plan.md:458 — Next actions explicitly call for regenerating the C per-φ trace and updating diagnosis.md before moving on to nb-compare.
- docs/development/c_to_pytorch_config_map.md — Confirms the supervisor spindle axis / detector parameters that must match when regenerating parity traces.
- docs/debugging/debugging.md §Parallel Trace Comparison Rule — Governs the trace capture workflow and artifact naming.
How-To Map:
- mkdir -p reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123
- date '+%F %T TRACE START' | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- make -C golden_suite_generator -j | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- NB_C_BIN=./golden_suite_generator/nanoBragg ./golden_suite_generator/nanoBragg \
  -mat A.mat -floatfile img.bin -hkl scaled.hkl -nonoise -nointerpolate -oversample 1 \
[2025-10-07T19:06:57] tokens used: 179,818

[2025-10-07T19:07:01] thinking

**Analyzing project context and planning next steps**
[2025-10-07T19:07:02] exec bash -lc "python - <<'PY'
import random
print('heads' if random.random() < 0.5 else 'tails')
PY" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:07:03] bash -lc "python - <<'PY'
import random
print('heads' if random.random() < 0.5 else 'tails')
PY" succeeded in 713ms:
heads
[2025-10-07T19:07:03] tokens used: 184,733

[2025-10-07T19:07:06] thinking

**Reviewing recent commits**
[2025-10-07T19:07:06] exec bash -lc 'git log --oneline -n 12' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:07:07] bash -lc 'git log --oneline -n 12' succeeded in 707ms:
c73da6a [SYNC i=108] actor=galph status=running
2160885 add third bug report on the C impl
1c4e6b1 [SYNC i=108] actor=galph status=fail galph_commit=4a74ca6
4a74ca6 SUPERVISOR: CLI-FLAGS-003 L3k.3b rerun plan - tests: not run
0da3a72 [SYNC i=108] actor=galph status=running
3b28849 [SYNC i=108] actor=ralph → next=galph status=ok ralph_commit=526f56d
526f56d CLI-FLAGS-003 Phase L3k.3c.2: φ=0 carryover evidence collection
4b73d1e document possible C cli bugs
15c57bb [SYNC i=107] actor=ralph status=running
2c6a9ca [SYNC i=107] actor=galph → next=ralph status=ok galph_commit=698c5c3
698c5c3 SUPERVISOR: CLI-FLAGS L3k.3c evidence plan - tests: not run
081fd8e document possible / likely bug in nanobragg C
[2025-10-07T19:07:07] tokens used: 184,958

[2025-10-07T19:07:15] thinking

**Reviewing recent commit changes**
[2025-10-07T19:07:17] exec bash -lc 'git show 526f56d' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:07:18] bash -lc 'git show 526f56d' succeeded in 718ms:
commit 526f56da3b8741ec245d5b8d41ded9b2d3e52b7f
Author: ollie <ohoidn>
Date:   Tue Oct 7 11:50:51 2025 -0700

    CLI-FLAGS-003 Phase L3k.3c.2: φ=0 carryover evidence collection
    
    Evidence-only loop (Mode: Parity) per input.md Do Now guidance.
    Captured PyTorch φ=0 state probe results. BLOCKED awaiting C trace
    generation (Phase L3k.3b) to compute deltas and complete carryover story.
    
    Key Findings:
    - φ=0 behavior correct: rot_b_phi0_y matches b_base_y exactly (0.7173197865486145 Å)
    - Rotation by 0° is identity operation as expected
    - φ₁ (0.01°) shows expected small deviation (Δb_y = -5.08e-3 Å from φ₀)
    - C reference trace missing; documented gap per input.md "If Blocked" guidance
    
    Artifacts:
    - reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/rot_vector_state_probe.log
    - reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/delta_metrics.json (status: BLOCKED)
    - reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/phi0_state_analysis.md
[2025-10-07T19:07:18] tokens used: 185,408

[2025-10-07T19:07:22] thinking

**Reviewing recent commits for context**

I'm looking over several recent commits by a contributor named ralph to understand the timeline and relevance, especially noting that some are documentation-only and others might relate to CLI bugs. I'll consider if it's necessary to review multiple commits to analyze productivity or regressions effectively.
[2025-10-07T19:07:23] exec bash -lc 'git show 4b73d1e' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:07:24] bash -lc 'git show 4b73d1e' succeeded in 705ms:
commit 4b73d1eecb1e915be472dbeced7562a0eb0f6efb
Author: ollie <ohoidn@slac.stanford.edu>
Date:   Tue Oct 7 11:47:07 2025 -0700

    document possible C cli bugs

diff --git a/docs/bugs/c-cli.md b/docs/bugs/c-cli.md
new file mode 100644
index 0000000..c29f469
--- /dev/null
+++ b/docs/bugs/c-cli.md
@@ -0,0 +1,64 @@
+### **Unified Bug Report: `nanoBragg` CLI Conventions**
+
+This report synthesizes findings from the `CLI-FLAGS-003` investigation, detailing two critical, related bugs in the `nanoBragg.c` command-line interface that lead to silent scientific invalidity and extreme difficulty in achieving parity.
+
+---
+
+### **Bug 1: NANO-C-BUG-001 - Silent Unit Mismatch in `-pix0_vector_mm` Flag**
+
[2025-10-07T19:07:24] tokens used: 188,676

[2025-10-07T19:07:26] thinking

**Checking for related commits**
[2025-10-07T19:07:27] exec bash -lc 'git show 081fd8e' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:07:27] bash -lc 'git show 081fd8e' succeeded in 713ms:
commit 081fd8ee920ac1e69fe5ffd59998927d41eaa1aa
Author: ollie <ohoidn@slac.stanford.edu>
Date:   Tue Oct 7 11:40:03 2025 -0700

    document possible / likely bug in nanobragg C

diff --git a/docs/bugs/c-parity-001.md b/docs/bugs/c-parity-001.md
new file mode 100644
index 0000000..2305ccf
--- /dev/null
+++ b/docs/bugs/c-parity-001.md
@@ -0,0 +1,90 @@
+### **Bug Report: `C-PARITY-001`**
+
+**Title:** Stale Crystal Vector State Carryover in `nanoBragg.c` at φ=0
+
+**Date Reported:** 2025-10-07
+
+**Discovered By:** Agent `ralph` (during `CLI-FLAGS-003` parity analysis, Attempt #101)
+
[2025-10-07T19:07:27] tokens used: 197,274

[2025-10-07T19:07:49] thinking

**Analyzing planning and instrumentation status**

I'm sorting through recent iterations where Ralph collected evidence but missed C trace data due to instrumentation steps not run; I need to verify if Ralph attempted capturing the C trace and correct course if needed. I'm reviewing existing plans for CLI-FLAGS and vectorization goals to assess if they need updates or if multi-turn planning is required, especially to manage long-term tasks like tricubic interpolation vectorization. Before deciding what to focus on next, I want to check current plans’ quality, outstanding tasks, and if adjustments like updating fix_plan or gathering more reports data are necessary.
[2025-10-07T19:07:51] exec bash -lc "sed -n '800,1100p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:07:52] bash -lc "sed -n '800,1100p' docs/fix_plan.md" succeeded in 673ms:
      - **F_cell still zero:** This is expected—pixel (685,1039) computes h=-7,k=-1,l=-14 but scaled.hkl only contains (1,12,3), so structure factor lookup correctly returns 0
      - **Scaling factors verified:** All intermediate scaling terms (r_e², fluence, steps, capture_fraction, polar, omega_pixel) match C within tolerance (Δ<0.002%)
      - **Test coverage maintained:** tests/test_trace_pixel.py::TestScalingTrace::test_scaling_trace_matches_physics passes all parametrized variants (4/4)
    Next Actions: Phase L2b complete; L2c evidence captured. Supervisor to proceed with Phase L3 structure-factor investigation based on comparison summary showing I_before_scaling as first divergence.
  * [2025-10-07] Attempt #79 (ralph loop) — Result: **SUCCESS** (Phase L3c device audit COMPLETE per supervisor "Do Now"). **Evidence-only loop; confirmed device handling gap: HKL tensor remains on CPU despite `-device cuda` flag.**
    Metrics: Pytest collection stable (2 tests from test_cli_scaling.py collected). No production code changes.
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/structure_factor/cli_hkl_device_probe.json` - Device probe showing HKL tensor on cpu for both cpu and cuda configs
      - `reports/2025-10-cli-flags/phase_l/structure_factor/cli_hkl_env.json` - Environment snapshot (SHA a91cb10, Python 3.13.0, Torch 2.5.1+cu124, cuda_available=true)
      - `reports/2025-10-cli-flags/phase_l/structure_factor/collect_cli_scaling_post_audit.log` - Pytest collection validation
      - `reports/2025-10-cli-flags/phase_l/structure_factor/cli_hkl_audit.md:3-44` - Updated audit documentation with device probe findings
    Observations/Hypotheses:
      - **Device gap confirmed:** CLI calls `.to(dtype=dtype)` without `.to(device=device)` when attaching HKL data (src/nanobrag_torch/__main__.py approx line 1068-1076)
      - **Impact scoped:** Will cause device mismatch when `-device cuda` runs reach structure factor lookup in compute_physics_for_position
      - **2025-11-17 galph audit cross-referenced:** Aligns with findings in docs/fix_plan.md:460-462 (galph previously identified the same gap)
    Next Actions: Supervisor to continue with Phase L3c harness audit (per plan.md:461 task 1) before implementing HKL device fix; document in fix_plan that HKL device transfer issue is now blocking CUDA parity and queue for L3d regression test.
  * [2025-10-18] Attempt #80 (ralph loop) — Result: **SUCCESS** (Phase L3c CLI HKL audit refresh COMPLETE per input.md "Do Now"). **Evidence-only loop; refreshed audit documentation with precise line references and confirmed device gap.**
    Metrics: Pytest collection stable (2 tests from test_cli_scaling.py collected). No production code changes.
    Artifacts:
      - `reports/2025-10-cli-flags/phase_l/structure_factor/cli_hkl_audit.md:3-72` - Refreshed 2025-10-18 audit section with exact line number (1073), code flow analysis, and required fix
[2025-10-07T19:07:52] tokens used: 202,652

[2025-10-07T19:07:59] thinking

**Verifying vectorization plan consistency**
[2025-10-07T19:08:00] exec bash -lc 'rg -n "VECTOR-TRICUBIC-001" -n docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:08:01] bash -lc 'rg -n "VECTOR-TRICUBIC-001" -n docs/fix_plan.md' succeeded in 698ms:
19:| [VECTOR-TRICUBIC-001](#vector-tricubic-001-vectorize-tricubic-interpolation-and-detector-absorption) | Vectorize tricubic interpolation and detector absorption | High | in_progress |
2065:## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
[2025-10-07T19:08:02] tokens used: 208,505

[2025-10-07T19:08:05] thinking

**Preparing to read more lines**
[2025-10-07T19:08:07] exec bash -lc "sed -n '2065,2353p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:08:08] bash -lc "sed -n '2065,2353p' docs/fix_plan.md" succeeded in 736ms:
## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
- Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
- Priority: High
- Status: in_progress (Phases A–B complete; Phase C implementation pending)
- Owner/Date: galph/2025-10-17
- Plan Reference: `plans/active/vectorization.md`
- Reproduction (C & PyTorch):
  * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
  * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
- First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
- Next Actions (2025-11-21 refresh):
 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
- Attempts History:
  * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
    Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
    Artifacts:
      - `reports/2025-10-vectorization/phase_a/test_at_str_002.collect.log` — Test collection output confirming 3 tests collected
[2025-10-07T19:08:08] tokens used: 211,714

[2025-10-07T19:08:42] thinking

**Analyzing plan and fix_plan inconsistencies**

I'm noticing that the fix_plan next actions are outdated because they still list Phase C3 tasks while the main plan marks Phase C3 as done. This means both fix_plan and the main plan need updating to align; specifically, the plan should be refreshed to reflect that Phase C3 is complete and that the next focus is Phase D. I’m piecing together that the appropriate focus issue would be updating the vectorization plan with an action type of Planning and mode Docs. It feels important to review related documentation thoroughly before finalizing the update.
[2025-10-07T19:08:45] exec bash -lc 'rg -n "Vectorization" docs/architecture/pytorch_design.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:08:45] bash -lc 'rg -n "Vectorization" docs/architecture/pytorch_design.md' exited 1 in 857ms:

[2025-10-07T19:08:45] tokens used: 216,334

[2025-10-07T19:08:48] thinking

**Checking documentation**
[2025-10-07T19:08:48] exec bash -lc "sed -n '1,200p' docs/architecture/pytorch_design.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:08:49] bash -lc "sed -n '1,200p' docs/architecture/pytorch_design.md" succeeded in 701ms:
# nanoBragg PyTorch Architecture Design (Addendum)

## 1.2 Differentiability vs Performance

Principle: Differentiability is required; over-hardening is not. Prefer the minimal change that passes gradcheck and preserves vectorization.

- Minimal Differentiability Contract
  - Return analytic limits at removable singularities only when the raw op produces NaN/Inf or unacceptable relative error in tests.
  - Keep the nominal fast path branch-free (or mask-based) and fully vectorized.
  - Avoid speculative guards and extra branches unless backed by (a) a reproduced gradient failure or (b) a measured numerical/perf improvement.

- Branching Budget (Hot Helpers)
  - Per-element branching inside hot helpers (e.g., `sincg`, `sinc3`, polarization) must be justified with numbers (gradcheck evidence or microbenchmark delta).

- Mask vs Guard
  - Masks gate analytic limits; a single epsilon guard may backstop tiny denominators. If the mask tolerance renders guards redundant, prefer the mask alone.

- Precision Guidance
  - Default dev dtype: float64; default prod dtype: float32. Tolerances must state dtype assumptions and be tested in both where relevant.

[2025-10-07T19:08:49] tokens used: 216,467

[2025-10-07T19:08:53] thinking

**Searching for vectorization section**
[2025-10-07T19:08:53] exec bash -lc 'rg -n "tricubic" docs/architecture/pytorch_design.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:08:54] bash -lc 'rg -n "tricubic" docs/architecture/pytorch_design.md' exited 1 in 706ms:

[2025-10-07T19:08:54] tokens used: 222,761

[2025-10-07T19:08:56] thinking

**Checking document size**
[2025-10-07T19:08:57] exec bash -lc 'cat docs/architecture/pytorch_design.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:08:58] bash -lc 'cat docs/architecture/pytorch_design.md' succeeded in 690ms:
# nanoBragg PyTorch Architecture Design (Addendum)

## 1.2 Differentiability vs Performance

Principle: Differentiability is required; over-hardening is not. Prefer the minimal change that passes gradcheck and preserves vectorization.

- Minimal Differentiability Contract
  - Return analytic limits at removable singularities only when the raw op produces NaN/Inf or unacceptable relative error in tests.
  - Keep the nominal fast path branch-free (or mask-based) and fully vectorized.
  - Avoid speculative guards and extra branches unless backed by (a) a reproduced gradient failure or (b) a measured numerical/perf improvement.

- Branching Budget (Hot Helpers)
  - Per-element branching inside hot helpers (e.g., `sincg`, `sinc3`, polarization) must be justified with numbers (gradcheck evidence or microbenchmark delta).

- Mask vs Guard
  - Masks gate analytic limits; a single epsilon guard may backstop tiny denominators. If the mask tolerance renders guards redundant, prefer the mask alone.

- Precision Guidance
  - Default dev dtype: float64; default prod dtype: float32. Tolerances must state dtype assumptions and be tested in both where relevant.

[2025-10-07T19:08:58] tokens used: 222,868

[2025-10-07T19:09:01] thinking

**Preparing to read PyTorch checklist**
[2025-10-07T19:09:02] exec bash -lc 'cat docs/development/pytorch_runtime_checklist.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:09:02] bash -lc 'cat docs/development/pytorch_runtime_checklist.md' succeeded in 690ms:
# PyTorch Runtime Checklist

Use this quick checklist before and after every PyTorch simulator edit. It distills the authoritative guidance from
`docs/architecture/pytorch_design.md`, `CLAUDE.md`, and the testing strategy.

1. **Vectorization**
   - Do not reintroduce Python loops that duplicate work already handled by batched tensor code.
   - When adding a new flow (sources, phi, mosaic, oversample), extend the existing broadcast shapes instead of looping.
   - Verify `_compute_physics_for_position` receives tensors with the expected batch dimensions.

2. **Device & Dtype Neutrality**
   - **Default dtype is float32** for performance and memory efficiency. Precision-critical operations (gradient checks, metric duality) explicitly override to float64 where required.
   - Materialize configuration tensors (beam, detector, crystal) on the execution device before the main loop.
   - Avoid per-iteration `.to()`, `.cpu()`, `.cuda()`, or tensor factories (`torch.tensor(...)`) inside compiled regions; cache constants once.
   - Run CPU **and** CUDA smoke commands (`pytest -v -m gpu_smoke`) when a GPU is available.

3. **torch.compile Hygiene**
   - Watch the console for Dynamo “graph break” warnings; treat them as blockers.
   - Benchmarks should reuse compiled functions; avoid changing shapes every call unless batching logic handles it.

[2025-10-07T19:09:02] tokens used: 223,902

[2025-10-07T19:09:25] thinking

**Organizing plan and documentation updates**

I'm preparing to update the vectorization plan and related documentation to reflect the completion of Phase C3 and to outline the next Phase D tasks. This includes carefully restructuring the plan file in a phased format, refreshing timelines, updating checklists, revising the fix_plan.md entry with accurate attempt numbering, and planning updates to galph_memory.md and input.md to guide the next steps focused on CLI-FLAGS continuation. I’ll also need to verify attempt numbering in fix_plan.md around line 2200-2300 to maintain consistency.
[2025-10-07T19:09:28] exec bash -lc "sed -n '2200,2320p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:09:29] bash -lc "sed -n '2200,2320p' docs/fix_plan.md" succeeded in 702ms:

---

### Archive
For additional historical entries (AT-PARALLEL-020, AT-PARALLEL-024 parity, early PERF fixes, routing escalation log), see `docs/fix_plan_archive.md`.

---

## [TEST-DTYPE-001] Fix dtype mismatches in test suite after DTYPE-DEFAULT-001 migration
- Spec/AT: arch.md lines 313, 361 (float32 default, precision-critical tests override to float64)
- Priority: High  
- Status: done
- Owner/Date: ralph/2025-10-01
- Reproduction (C & PyTorch):
  * C: n/a (test-suite issue, not C-parity)
  * PyTorch: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_geo_003.py::TestATGEO003RFactorAndBeamCenter::test_r_factor_calculation -v` (example failure before fix)
  * Shapes/ROI: n/a (dtype compatibility issue)
- First Divergence (if known): After DTYPE-DEFAULT-001 completed migration to float32 defaults, 31 tests failed with "RuntimeError: Float did not match Double" because tests create float64 tensors but compare against float32 Detector/Crystal outputs
- Attempts History:
  * [2025-10-01] Attempt #1 — Result: success. Fixed 27+ dtype mismatch tests by adding `dtype=torch.float64` parameter to Detector/Crystal/Simulator constructors in precision-critical tests.
[2025-10-07T19:09:29] tokens used: 225,495

[2025-10-07T19:09:44] thinking

**Verifying complete VECTOR-TRICUBIC-001 section**
[2025-10-07T19:09:44] exec bash -lc "sed -n '2120,2200p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:09:45] bash -lc "sed -n '2120,2200p' docs/fix_plan.md" succeeded in 691ms:
    Metrics: Test collection passed (`pytest --collect-only -q` succeeded with 463 tests discovered). No code changes; docs-only validation.
    Artifacts:
      - `reports/2025-10-vectorization/phase_b/design_notes.md` — Comprehensive 12-section design memo covering:
        * Section 2: Tensor shape design with `(B, 4, 4, 4)` neighborhood structure and memory footprint estimates
        * Section 3: C-code polynomial semantics mapping (polint/polin2/polin3 Lagrange basis functions → vectorized PyTorch ops)
        * Section 4: Gradient & device checklist (differentiability requirements, device neutrality, torch.compile compatibility)
        * Section 5: Failure modes & mitigation (OOB handling, memory pressure, numerical stability)
        * Section 6–7: Validation strategy and implementation roadmap (Phase C gather, Phase D polynomial evaluation, Phase E validation)
        * Sections 8–12: Glossary, dependencies, risk assessment, open questions, appendix with sample broadcast calculation
    Observations/Hypotheses:
      - Adopted two-stage vectorization: Phase C batched neighborhood gather to build `(B, 4, 4, 4)` subcubes; Phase D vectorize polint/polin2/polin3 to consume batched inputs
      - Key design decision: Flatten arbitrary leading dims `(S, F, oversample, ...)` into single batch `B` to simplify indexing and preserve flexibility
      - Memory footprint analysis: 1024² detector = ~268 MB for neighborhoods at float32; 1024² with oversample=2 = ~1.07 GB (acceptable)
      - Identified critical device harmonization requirement: HKL data (typically CPU) must move to query device (may be CUDA) at first call
      - Documented Lagrange basis vectorization strategy with explicit loop structure (4 terms, fixed iteration count, torch.compile-friendly)
      - Captured gradient flow requirements: avoid `.item()`, avoid `torch.linspace` with tensor endpoints, use `torch.floor(...).to(dtype=torch.long)` pattern
      - Outlined OOB mask approach: detect invalid neighborhoods, emit warning once, apply fallback `default_F` for invalid points
      - Established validation plan: AT-STR-002 parity, unit-level gradcheck, CPU/CUDA benchmarks with ≥10× speedup target vs scalar baseline
    Next Actions: Execute Phase C tasks (C1–C3) to implement batched neighborhood gather with OOB handling; then Phase D (D1–D3) to vectorize polynomial helpers; finally Phase E (E1–E3) validation suite. All implementation must reference this design memo for shape contracts and gradient requirements.
  * [2025-10-07] Attempt #4 (ralph loop) — Result: **Phase C1 COMPLETE** (batched neighborhood gather implemented and validated). All tests passing.
[2025-10-07T19:09:45] tokens used: 229,259

[2025-10-07T19:09:53] thinking

**Verifying Phase C3 completion status**
[2025-10-07T19:09:53] exec bash -lc 'rg "sub_Fhkl" -n src/nanobrag_torch/models/crystal.py' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:09:54] bash -lc 'rg "sub_Fhkl" -n src/nanobrag_torch/models/crystal.py' succeeded in 769ms:
302:        polin3(h_interp_d,k_interp_d,l_interp_d,sub_Fhkl,h,k,l,&F_cell);
384:            sub_Fhkl = torch.full((B, 4, 4, 4), self.config.default_F, dtype=self.dtype, device=self.device)
401:            sub_Fhkl = self.hkl_data[
414:        assert sub_Fhkl.shape == (B, 4, 4, 4), \
415:            f"Neighborhood shape mismatch: expected ({B}, 4, 4, 4), got {sub_Fhkl.shape}"
424:        assert sub_Fhkl.device == h.device, \
425:            f"Device mismatch: sub_Fhkl on {sub_Fhkl.device}, input on {h.device}"
436:                            sub_Fhkl.squeeze(0), h_flat.squeeze(0), k_flat.squeeze(0), l_flat.squeeze(0))
[2025-10-07T19:09:54] tokens used: 232,128

[2025-10-07T19:10:00] thinking

**Verifying assertion commit history**
[2025-10-07T19:10:01] exec bash -lc 'git log -S "Neighborhood shape mismatch" --pretty=oneline' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:10:04] bash -lc 'git log -S "Neighborhood shape mismatch" --pretty=oneline' succeeded in 3.36s:
12742e5d9b8a4d86f6df0c506e2f00eba515e15a [SYNC i=102] actor=ralph VECTOR-TRICUBIC-001 Phase C3: shape assertions + device checks - tests: 8 passed, 0 failed
[2025-10-07T19:10:04] tokens used: 233,076

[2025-10-07T19:10:07] thinking

**Verifying commit reference in fix_plan**
[2025-10-07T19:10:08] exec bash -lc 'rg "Phase C3" docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:10:09] bash -lc 'rg "Phase C3" docs/fix_plan.md' succeeded in 701ms:
    Next Actions: Mark ROUTING-LOOP-001 as done; archive plan to `plans/archive/routing-loop-guard/` per Phase C3 guidance.
 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
    Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
[2025-10-07T19:10:09] tokens used: 234,258

[2025-10-07T19:10:12] thinking

**Verifying commit consistency**
[2025-10-07T19:10:13] exec bash -lc 'git show 12742e5d9b8a4d86f6df0c506e2f00eba515e15a' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:10:14] bash -lc 'git show 12742e5d9b8a4d86f6df0c506e2f00eba515e15a' succeeded in 703ms:
commit 12742e5d9b8a4d86f6df0c506e2f00eba515e15a
Author: ollie <ohoidn>
Date:   Tue Oct 7 08:15:13 2025 -0700

    [SYNC i=102] actor=ralph VECTOR-TRICUBIC-001 Phase C3: shape assertions + device checks - tests: 8 passed, 0 failed

diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 65e4d42..1f3b1b2 100644
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -37,14 +37,14 @@ Implementation notes: capture all Phase C artifacts under `reports/2025-10-vecto
 | --- | --- | --- | --- |
 | C1 | Implement batched neighborhood gather | [D] | ✅ Completed 2025-10-17 (Attempt #5). Batched gather infrastructure validated; all tests passing. Artifacts: `reports/2025-10-vectorization/phase_c/{gather_notes.md, collect_log.txt, test_*.log, diff_snapshot.json, runtime_probe.json}`. Scalar path (B=1) uses existing polin3; batched path (B>1) falls back to nearest-neighbor pending Phase D. |
 | C2 | Preserve fallback semantics | [D] | ✅ Completed 2025-10-07 (Attempt #1). Authored `test_oob_warning_single_fire` capturing stdout to verify single-warning behavior; test asserts `_interpolation_warning_shown` flag state, `interpolate` disable, and `default_F` fallback on OOB queries. All tricubic tests pass (8/8). Artifacts: `reports/2025-10-vectorization/phase_c/{test_tricubic_vectorized.log, status_snapshot.txt}`; test code at `tests/test_tricubic_vectorized.py:199-314`. |
-| C3 | Add shape assertions & cache hooks | [ ] | Add runtime assertions for `(B, 4, 4, 4)` neighborhoods and `(B,)` outputs, audit cache invalidation to ensure tensors stay on the caller device/dtype (replace `.cpu()` with `.type_as` where needed), and document changes in `phase_c/implementation_notes.md` (new “C3 updates” section). Capture `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` plus `tests/test_at_str_002.py::test_tricubic_interpolation_enabled` logs under `phase_c/` once assertions land. |
+| C3 | Add shape assertions & cache hooks | [D] | ✅ Completed 2025-10-07 (Attempt #6). Shape assertions added for `(B, 4, 4, 4)` neighborhoods and output shapes; device consistency checks ensure tensors stay on input device. No explicit caching present in tricubic path. All targeted tests passing (5 gather + 1 acceptance). Artifacts: `reports/2025-10-vectorization/phase_c/{test_tricubic_vectorized.log, test_at_str_002_phi.log, implementation_notes.md}`. Code refs: `crystal.py:414-427` (shape/device assertions), `crystal.py:440-447` (scalar output assertions), `crystal.py:461-462` (batched fallback assertions). |
 
 #### Phase C3 Verification Checklist
 | ID | Task Description | State | How/Why & Guidance |
 | --- | --- | --- | --- |
[2025-10-07T19:10:14] tokens used: 240,906

[2025-10-07T19:10:18] thinking

**Checking commit for fix_plan updates**
[2025-10-07T19:10:19] exec bash -lc 'git show 12742e5d9b8a4d86f6df0c506e2f00eba515e15a -- docs/fix_plan.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:10:20] bash -lc 'git show 12742e5d9b8a4d86f6df0c506e2f00eba515e15a -- docs/fix_plan.md' succeeded in 709ms:

[2025-10-07T19:10:20] tokens used: 244,369

[2025-10-07T19:10:37] thinking

**Updating vectorization and fix_plan documents**

I need to revise the vectorization plan and fix_plan files to reflect completion of Phase C3 and shift focus to Phase D tasks. This includes adding a new attempt entry for Phase C3 linked to the shape assertion commit, updating gap snapshots with current statuses and dates, adjusting supervisory notes to emphasize Phase D, and correcting context about benchmark harness availability. I plan to use apply_patch to perform these structured updates while ensuring the plan stays consistent and thorough.
[2025-10-07T19:10:45] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/plans/active/vectorization.md
@@ -3,5 +3,5 @@
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
[2025-10-07T19:10:45] apply_patch(auto_approved=true) exited 0 in 8ms:
Success. Updated the following files:
M plans/active/vectorization.md
[2025-10-07T19:10:45] turn diff:
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

[2025-10-07T19:10:45] tokens used: 249,146
[2025-10-07T19:10:45] turn diff:
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:11:01] thinking

**Updating plan with Phase D details and attempts**

I’m planning to enhance the fix_plan.md by refining the Next Actions to reflect Phase D/E tasks and adding a new attempt entry (#7) for Phase C3 based on test results from commit 12742e5. I want to ensure proper sequencing, mention relevant logs and metrics, and optionally note new Phase D directories. I’ll locate the exact text range using sed before applying patches.
[2025-10-07T19:11:02] exec bash -lc "sed -n '2065,2140p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:11:03] bash -lc "sed -n '2065,2140p' docs/fix_plan.md" succeeded in 686ms:
## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
- Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
- Priority: High
- Status: in_progress (Phases A–B complete; Phase C implementation pending)
- Owner/Date: galph/2025-10-17
- Plan Reference: `plans/active/vectorization.md`
- Reproduction (C & PyTorch):
  * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
  * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
- First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
- Next Actions (2025-11-21 refresh):
 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
- Attempts History:
  * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
    Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
    Artifacts:
      - `reports/2025-10-vectorization/phase_a/test_at_str_002.collect.log` — Test collection output confirming 3 tests collected
[2025-10-07T19:11:03] tokens used: 251,130
[2025-10-07T19:11:03] turn diff:
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:11:08] thinking

**Preparing patch for status and actions update**
[2025-10-07T19:11:16] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/docs/fix_plan.md
@@ -2067,3 +2067,3 @@
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
@@ -2072,9 +2072,9 @@
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
[2025-10-07T19:11:16] apply_patch(auto_approved=true) exited 0 in 20ms:
Success. Updated the following files:
M docs/fix_plan.md
[2025-10-07T19:11:16] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..207e8caf258e34b8041cab6413375d46a01883ae
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

[2025-10-07T19:11:16] tokens used: 257,016
[2025-10-07T19:11:16] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..207e8caf258e34b8041cab6413375d46a01883ae
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:11:25] thinking

**Inserting new attempt entry for Phase C3**

I'm preparing to add a new Attempt #7 entry after attempt #6, using commit data from 2025-10-07. I’m gathering accurate test metrics, focusing on targeted test results like five gather tests passing, and will list artifacts such as updated implementation notes and test logs. I want to reflect observed code changes like shape assertions and plan next steps aligning with phase D before applying the patch insertion.
[2025-10-07T19:11:36] tokens used: 261,841
[2025-10-07T19:11:36] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..207e8caf258e34b8041cab6413375d46a01883ae
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:11:40] thinking

**Verifying patch application failure**
[2025-10-07T19:11:43] exec bash -lc "sed -n '2140,2185p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:11:44] bash -lc "sed -n '2140,2185p' docs/fix_plan.md" succeeded in 689ms:
    Metrics:
      - New test suite: 4/4 tests passed in test_tricubic_vectorized.py (test_vectorized_matches_scalar, test_neighborhood_gathering_internals, test_device_neutrality[cpu], test_device_neutrality[cuda])
      - Regression tests: 3/3 tests passed in test_at_str_002.py (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation)
      - Core suite: 38/38 tests passed (crystal geometry, detector geometry, vectorized gather)
      - Shape validation: Scalar (B=1) → (1,4,4,4), Batch (B=3) → (3,4,4,4), Grid (2×3) → (6,4,4,4) neighborhoods all correct
      - Device propagation: CPU and CUDA execution confirmed with correct device inheritance
    Artifacts:
      - `src/nanobrag_torch/models/crystal.py` lines 355–429 — Batched neighborhood gather implementation using advanced PyTorch indexing
      - `tests/test_tricubic_vectorized.py` — 4 new test cases validating gather infrastructure (white-box coordinate validation, device neutrality)
      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — Complete Phase C1 implementation documentation
      - Git commit: 88fd76a
    Observations/Hypotheses:
      - Successfully implemented `(B, 4, 4, 4)` neighborhood gather using broadcasting pattern from design_notes.md §2: `h_array_grid[:, :, None, None]`, `k_array_grid[:, None, :, None]`, `l_array_grid[:, None, None, :]`
      - Scalar path (B=1) preserved: continues to use existing `polin3` helper with correct interpolation
      - Batched path (B>1) falls back to nearest-neighbor pending Phase D polynomial vectorization (intentional staging per design)
      - OOB handling preserved: single warning emission, default_F fallback logic intact
      - No memory issues: 1024² detector (268 MB neighborhoods) well within GPU/CPU limits
      - Coordinate grid construction validated: `h=1.5` (floor=1) → grid `[0,1,2,3]` as expected (floor + offsets [-1,0,1,2])
      - Device comparison fix applied: use `.device.type` string comparison instead of direct `torch.device` object comparison to handle `cuda` vs `cuda:0` variants
      - Implementation follows all design contracts: no `.item()` calls, device-neutral offset construction, differentiability preserved
[2025-10-07T19:11:44] tokens used: 263,987
[2025-10-07T19:11:44] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..207e8caf258e34b8041cab6413375d46a01883ae
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:11:47] thinking

**Continuing to verify insertion point**
[2025-10-07T19:11:48] exec bash -lc "sed -n '2185,2225p' docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:11:49] bash -lc "sed -n '2185,2225p' docs/fix_plan.md" succeeded in 693ms:
      - `plans/active/vectorization.md` task C2 marked complete (state [D])
    Observations/Hypotheses:
      - Test successfully captures `_interpolation_warning_shown` flag behavior: first OOB prints warning, second OOB silent
      - Test validates `Crystal.interpolate` flag permanently disables after first OOB detection
      - Test verifies fallback to `default_F` on OOB queries (expected_default=100.0, got 100.0)
      - Test uses stdout capture (io.StringIO) to deterministically assert warning text presence/absence
      - Three-scenario validation: (1) first OOB → warning + disable, (2) second OOB → no warning + still default_F, (3) in-bounds post-disable → nearest-neighbor fallback
      - No code changes to production paths; test-only addition preserves existing behavior
      - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
    Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
- Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
- Exit Criteria (quote thresholds from spec):
  * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
  * Benchmarks demonstrate measurable runtime reduction vs Phase A baselines for both tricubic interpolation and detector absorption (documented in `phase_e/perf_results.json` & `phase_f/summary.md`).
  * `docs/architecture/pytorch_design.md` and `docs/development/testing_strategy.md` updated to describe the new vectorized paths; plan archived with artifacts promoted to `reports/archive/`.

---

### Archive
For additional historical entries (AT-PARALLEL-020, AT-PARALLEL-024 parity, early PERF fixes, routing escalation log), see `docs/fix_plan_archive.md`.
[2025-10-07T19:11:49] tokens used: 268,620
[2025-10-07T19:11:49] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..207e8caf258e34b8041cab6413375d46a01883ae
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:11:51] thinking

**Inserting new attempt before section**
[2025-10-07T19:12:02] tokens used: 272,469
[2025-10-07T19:12:02] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..207e8caf258e34b8041cab6413375d46a01883ae
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:12:11] thinking

**Strategizing precise patch insertion**
[2025-10-07T19:12:17] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/docs/fix_plan.md
@@ -2194,2 +2194,13 @@
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
[2025-10-07T19:12:17] apply_patch(auto_approved=true) exited 0 in 15ms:
Success. Updated the following files:
M docs/fix_plan.md
[2025-10-07T19:12:17] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

[2025-10-07T19:12:17] tokens used: 276,712
[2025-10-07T19:12:17] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:12:28] thinking

**Verifying plan consistency and preparing next steps**
[2025-10-07T19:12:30] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:12:30] bash -lc 'git status --short' succeeded in 716ms:
 M docs/fix_plan.md
 M plans/active/vectorization.md
[2025-10-07T19:12:30] tokens used: 278,429
[2025-10-07T19:12:30] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:12:44] thinking

**Planning input.md update for Ralph**

I'm figuring out how to rewrite `input.md` to keep Ralph focused on completing the CLI-FLAGS Phase L3k.3b C trace, since that remains the priority. I want to make sure the instructions reflect recent plan updates without changing Ralph's immediate tasks, and I'm considering how to reference the updated fix_plan document accurately.
[2025-10-07T19:12:50] exec bash -lc "rg -n \"Phase L3k\\.3b\" docs/fix_plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:12:51] bash -lc "rg -n \"Phase L3k\\.3b\" docs/fix_plan.md" succeeded in 684ms:
461:1. Phase L3k.3b — Regenerate the C per-φ trace that pairs with the 20251123 PyTorch probe: rebuild the instrumented `golden_suite_generator/nanoBragg`, rerun the supervisor command with `TRACE_C_PHI` enabled, drop the output under `base_vector_debug/20251123/`, and rerun `scripts/compare_per_phi_traces.py` so `delta_metrics.json` and VG-1 entries show numeric deltas instead of `status="BLOCKED"`. If reuse of the 202510070839 trace is preferred, update the harness paths accordingly and record the decision in `diagnosis.md` and `commands.txt`.
500:  * [2025-10-07] Attempt #98 (ralph loop i=107, Mode: Parity/Evidence) — Result: **EVIDENCE CAPTURED** (Phase L3k.3c.2 φ=0 carryover evidence collection COMPLETE). **BLOCKED** awaiting C trace generation (Phase L3k.3b).
515:    First Divergence (if known): C trace unavailable — delta computation deferred to Phase L3k.3b
517:      1. Execute Phase L3k.3b: Instrument golden_suite_generator/nanoBragg.c to emit TRACE_C_PHI for all φ steps, rebuild, run with supervisor command
594:  * [2025-10-07] Attempt #101 (ralph loop i=101) — Result: **SUCCESS** (Phase L3k.3b per-φ trace regeneration COMPLETE). **TRACE_C_PHI instrumentation confirmed active; per-φ comparison identifies φ=0 initialization bug.**
[2025-10-07T19:12:51] tokens used: 282,783
[2025-10-07T19:12:51] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:12:59] thinking

**Reviewing plan references and input details**
[2025-10-07T19:12:59] exec bash -lc "rg -n \"L3k\\.3\" plans/active/cli-noise-pix0/plan.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:13:00] bash -lc "rg -n \"L3k\\.3\" plans/active/cli-noise-pix0/plan.md" succeeded in 692ms:
5:- Gap snapshot update (2025-11-23): Attempt #108 gathered fresh PyTorch φ=0 state probes (reports/.../20251123/) confirming the rotation fix keeps φ=0 identical to base vectors, but the per-φ comparison pipeline could not locate a coeval C trace. Phase L3k.3b must regenerate TRACE_C_PHI output (or retarget the script to the existing 202510070839 asset) before VG-1 deltas can be recomputed.
7:- Gap snapshot refresh (2025-10-07 08:41): Attempt #101 activated TRACE_C_PHI (C instrumentation) and captured matching Py per-φ traces. Divergence isolated to φ_tic=0 (Δk≈1.81e-2) while φ>0 steps remain within 3e-5. Phase L3k.3 moves to φ=0 initialization parity (L3k.3c) plus ROI/nb-compare follow-ups.
21:- Gap snapshot update (2025-11-22): Attempt #101 (L3k.3b evidence loop) regenerated per-φ PyTorch traces and confirmed k_frac span=1.8088e-2. No matching `TRACE_C_PHI` lines exist in the current C trace, so the comparison tooling falsely reports "parity achieved." Phase L3k now requires explicit instrumentation of the golden C binary plus a guard that treats missing C data as a blocking failure before nb-compare/ROI work resumes.
288:| L3k.3 | Execute verification gates VG-1⇢VG-5 | [P] | Attempt #98 cleared VG-2, Attempt #99 exposed the remaining gaps (k_frac span 1.8e-2, correlation 0.985, sum_ratio 1.16e5), and Attempt #108 captured φ=0 PyTorch state probes while flagging the C trace dependency. Re-open VG-1 workflow: re-run TRACE_C_PHI under the 20251123 timestamp (or update the harness to consume the 202510070839 asset), regenerate per-φ comparisons, then continue through the nb-compare ROI repair and documentation gates. Artifacts live under `reports/2025-10-cli-flags/phase_l/rot_vector/` (base_vector_debug/, per_phi_postfix/) and `reports/2025-10-cli-flags/phase_l/nb_compare_phi_fix/`. |
290:#### L3k.3 Checklist — φ=0 Verification Recovery
294:| L3k.3a | Align φ=0 harness/tests with supervisor spindle axis | [D] | ✅ Attempt #100 updated `tests/test_cli_scaling_phi0.py` to set `spindle_axis=[-1,0,0]`, producing the expected red baseline (rot_b drift, k_frac delta). Keep these tests red until the physics fix lands; rerun `pytest tests/test_cli_scaling_phi0.py -k "phi0" -vv` after each patch. |
295:| L3k.3b | Restore C↔Py per-φ comparison pipeline | [P] | Attempt #101 captured the initial TRACE_C_PHI run, but Attempt #108's probe shows the current harness cannot locate a C trace under the new `base_vector_debug/20251123/` workspace. Regenerate TRACE_C_PHI output with the supervisor command (preferred: emit a fresh 20251123 log; acceptable fallback: update the script to consume `.../202510070839/c_trace_phi_202510070839.log`) and re-run `scripts/compare_per_phi_traces.py` so VG-1 deltas populate instead of returning "BLOCKED." Record the rerun under a new timestamp and update `delta_metrics.json` + `fix_checklist.md` accordingly. |
296:| L3k.3c | Patch φ rotation & confirm VG-1 thresholds | [ ] | **Regression alert:** Attempt #102 rewrote `tests/test_cli_scaling_phi0.py` to treat the PyTorch base-vector output as canonical, masking the failing VG-1 gate. Attempt #103 restored the C-aligned assertions; keep them red until VG-1 passes. With the C trace refreshed (L3k.3b), implement the carryover fix, rerun the per-φ harness, ensure k_frac span ≤1e-6 and rot_b_y relative error ≤1e-6, and update `comparison_summary.md` plus `per_phi_postfix/` artifacts before flipping VG-1 rows to ✅. |
297:| L3k.3d | Resolve nb-compare ROI parity (VG-3/VG-4) | [ ] | Investigate the C ROI zero-sum issue (ROI bounds, image loader, dtype). Once resolved, rerun `nb-compare --roi` to hit correlation ≥0.9995, sum_ratio 0.99–1.01, and component deltas meeting VG-4 thresholds. Record metrics in `vg3_metrics.txt` and update `fix_checklist.md`. |
298:| L3k.3e | Finalize documentation + checklist (VG-5) | [ ] | When VG-1/VG-3/VG-4 pass, mark remaining rows in `fix_checklist.md` ✅, append resolutions to `mosflm_matrix_correction.md`, and prep notes for the L3k.4 attempt log. |
299:| L3k.4 | Log Attempt + plan sync | [ ] | **BLOCKED on L3k.3 completion.** Append new Attempt entry in `docs/fix_plan.md` CLI-FLAGS-003 with metrics (correlation, sum_ratio, b_Y delta, k_frac delta from VG artifacts), reference all artifact paths (per-φ traces, pytest log, nb-compare summary, updated checklist), document observations (H5 confirmed, thresholds met), and flip L3k.1–L3k.4 rows to [D] in this plan. Update Next Actions to proceed to Phase L4 supervisor command parity rerun. |
301:#### L3k.3c Tasks — Restore φ=0 Parity with C Reference
305:| L3k.3c.1 | Reinstate C-aligned assertions | [D] | ✅ Attempt #103 (2025-10-07) restored the C expectations in `tests/test_cli_scaling_phi0.py`, leaving both φ=0 parity tests failing against the C reference. Artifact: `reports/.../pytest_phi0_regression.log`. Keep these assertions active so the fix cannot be masked. |
306:| L3k.3c.2 | Diagnose φ=0 state carryover | [P] | Attempt #108 logged the PyTorch φ=0 probe (`base_vector_debug/20251123/rot_vector_state_probe.log`) and documented that the rotation fix returns the base vector at φ=0 while φ₁ begins the expected drift. Finish the diagnosis by pairing this probe with a matching C TRACE_C_PHI run (L3k.3b), compute Δb_y/Δk_frac via `compare_per_phi_traces.py`, and update `diagnosis.md` with concrete deltas plus the chosen vectorized remediation (e.g., φ==0 mask preserving prior-state values). |
307:| L3k.3c.3 | Implement + validate fix | [ ] | After agreeing on the fix approach, run the per-φ harness and targeted pytest selector (`tests/test_cli_scaling_phi0.py::TestPhiZeroParity::test_rot_b_matches_c`). Store passing artifacts under a new timestamped directory in `base_vector_debug/` and update `fix_checklist.md` VG-1.4 to ✅ once thresholds are met. |
[2025-10-07T19:13:00] tokens used: 284,338
[2025-10-07T19:13:00] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:13:19] thinking

**Preparing updated input.md content**

I'm organizing all the details needed to rewrite input.md accurately, making sure to reflect updated plan references, line numbers, and task priorities. I'll include sections like summary, mode, focus, branch, tests, artifacts, Do Now, priorities with precise doc references, how-to map, pitfalls, pointers, and Next Up notes, staying consistent with previous formatting but adapted for the current plan state.
[2025-10-07T19:13:34] exec bash -lc "cat <<'EOF' > input.md
Summary: Regenerate the C per-φ trace and recompute VG-1 deltas so CLI-FLAGS-003 Phase L3k.3b is unblocked.
Mode: Parity
Focus: CLI-FLAGS-003 Phase L3k.3b TRACE_C_PHI rerun
Branch: feature/spec-based-2
Mapped tests: env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q
Artifacts: reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.json; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_stdout_20251123.txt; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/delta_metrics.json; reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md (L3k.3c.2 update); reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/sha256.txt
Do Now: CLI-FLAGS-003 (Handle -nonoise and -pix0_vector_mm) — execute Phase L3k.3b by rebuilding the instrumented C binary, rerunning the supervisor command with -trace_pixel 685 1039 to capture "'`c_trace_phi_20251123.log`, regenerating the PyTorch per-φ trace via `trace_harness.py`, and re-running `scripts/compare_per_phi_traces.py` so VG-1 deltas populate under the 20251123 timestamp before recording the updated metrics in diagnosis.md. Finish with env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q.
If Blocked: If the instrumented C binary is missing TRACE_C_PHI output, re-apply the instrumentation patch (see golden_suite_generator/nanoBragg.c:3156-3160), rerun `make -C golden_suite_generator`, and retry the command. If C still cannot be rebuilt on this machine, copy `c_trace_phi_202510070839.log` into the 20251123 directory, document the reuse decision in diagnosis.md, flag the delta computation as provisional inside delta_metrics.json, and stop after updating commands.txt + sha256.txt.
Priorities & Rationale:
- plans/active/cli-noise-pix0/plan.md:288-307 — L3k.3 checklist keeps VG-1 blocked until a fresh TRACE_C_PHI run pairs with the 20251123 Py probe.
- docs/fix_plan.md:461-517 — Active item Next Actions demand regenerated C trace + updated diagnosis before nb-compare resumes.
- reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md#L200 — Notes the missing C trace and pending Δb_y/Δk logging required for Phase L3k.3c.2.
- docs/development/testing_strategy.md:24-61 — Parallel trace workflow mandates C/Py logs before implementing physics fixes.
- specs/spec-a-cli.md:1-160 — Confirms -pix0_vector_mm semantics we must verify when capturing parity artifacts.
How-To Map:
- mkdir -p reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123
- date '"'+%F %T TRACE START' | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- make -C golden_suite_generator -j | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- NB_C_BIN=./golden_suite_generator/nanoBragg ./golden_suite_generator/nanoBragg \\
  -mat A.mat -floatfile img.bin -hkl scaled.hkl -nonoise -nointerpolate -oversample 1 \\
  -exposure 1 -flux 1e18 -beamsize 1.0 -spindle_axis -1 0 0 \\
  -Xbeam 217.742295 -Ybeam 213.907080 -distance 231.274660 -lambda 0.976800 \\
  -pixel 0.172 -detpixels_x 2463 -detpixels_y 2527 \\
  -odet_vector -0.000088 0.004914 -0.999988 \\
  -sdet_vector -0.005998 -0.999970 -0.004913 \\
  -fdet_vector 0.999982 -0.005998 -0.000118 \\
  -pix0_vector_mm -216.336293 215.205512 -230.200866 \\
  -beam_vector 0.00051387949 0.0 -0.99999986 \\
  -Na 36 -Nb 47 -Nc 29 -osc 0.1 -phi 0 -phisteps 10 \\
  -detector_rotx 0 -detector_roty 0 -detector_rotz 0 -twotheta 0 \\
  -trace_pixel 685 1039 \\
  2>&1 | tee reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \\
  reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \\
  --config supervisor --pixel 685 1039 \\
  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \\
  --device cpu --dtype float64 \\
  | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \\
  reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.json \\
  reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log \\
  | tee reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_stdout_20251123.txt
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python - <<'PY'
import json, pathlib
base = pathlib.Path('reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123')
py = json.load((base/'trace_py_rot_vector_20251123_per_phi.json').open())['per_phi_entries']
with (base/'c_trace_phi_20251123.log').open() as fh:
    cvals = [float(line.split()[3].split('=')[1]) for line in fh if line.startswith('TRACE_C_PHI')]
metrics = {
    'status': 'ok',
    'phi0': {
        'py_k_frac': py[0]['k_frac'],
        'c_k_frac': cvals[0],
        'delta_k': py[0]['k_frac'] - cvals[0]
    },
    'phi9': {
        'py_k_frac': py[9]['k_frac'],
        'c_k_frac': cvals[9],
        'delta_k': py[9]['k_frac'] - cvals[9]
    }
}
(base/'delta_metrics.json').write_text(json.dumps(metrics, indent=2) + '\\n')
PY
- sha256sum reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/* > reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/sha256.txt
- Update reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md with an L3k.3c.2 entry summarising the new Δk values, the command hashes, and the remediation path (φ==0 mask or equivalent vectorized carryover) before touching simulator code.
- env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
Pitfalls To Avoid:
- Do not edit simulator/crystal code this loop; evidence only.
- Keep all command transcripts in commands.txt with timestamps so the rerun is auditable.
- Ensure NB_C_BIN points at golden_suite_generator/nanoBragg; the root binary lacks TRACE_C_PHI instrumentation.
- Maintain device/dtype neutrality when running harness scripts (stay on cpu/float64 as specified).
- Do not overwrite older base_vector_debug directories; add the new timestamp alongside 202510070839/20251122.
- Preserve failing pytest expectations in tests/test_cli_scaling_phi0.py; no edits to mask the red baseline.
- Run compare_per_phi_traces.py after both traces exist; it will raise if paths are wrong.
- Append to diagnosis.md rather than replacing earlier sections so chronology is intact.
- Regenerate sha256.txt after all files are in place to avoid stale hashes.
- Keep delta_metrics.json formatted as JSON (no trailing comments) for future automation.
Pointers:
- plans/active/cli-noise-pix0/plan.md:288-307 — Current L3k.3 tasks and success criteria.
- docs/fix_plan.md:461-517 — Next Actions and recent attempts capturing the missing C trace.
- reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/202510070839/diagnosis.md — Reference C trace instrumentation commands from the earlier successful run.
- golden_suite_generator/nanoBragg.c:3156-3160 — TRACE_C_PHI instrumentation hook.
- docs/debugging/debugging.md:28-118 — Parallel trace SOP you must follow.
Next Up: After VG-1 deltas are recorded, move to Phase L3k.3d to repair the nb-compare ROI totals (focus docs/fix_plan.md:470, plan table rows L3k.3d/L3k.3e).
EOF
" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:13:35] bash -lc "cat <<'EOF' > input.md
Summary: Regenerate the C per-φ trace and recompute VG-1 deltas so CLI-FLAGS-003 Phase L3k.3b is unblocked.
Mode: Parity
Focus: CLI-FLAGS-003 Phase L3k.3b TRACE_C_PHI rerun
Branch: feature/spec-based-2
Mapped tests: env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q
Artifacts: reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.json; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_stdout_20251123.txt; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/delta_metrics.json; reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md (L3k.3c.2 update); reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt; reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/sha256.txt
Do Now: CLI-FLAGS-003 (Handle -nonoise and -pix0_vector_mm) — execute Phase L3k.3b by rebuilding the instrumented C binary, rerunning the supervisor command with -trace_pixel 685 1039 to capture "'`c_trace_phi_20251123.log`, regenerating the PyTorch per-φ trace via `trace_harness.py`, and re-running `scripts/compare_per_phi_traces.py` so VG-1 deltas populate under the 20251123 timestamp before recording the updated metrics in diagnosis.md. Finish with env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q.
If Blocked: If the instrumented C binary is missing TRACE_C_PHI output, re-apply the instrumentation patch (see golden_suite_generator/nanoBragg.c:3156-3160), rerun `make -C golden_suite_generator`, and retry the command. If C still cannot be rebuilt on this machine, copy `c_trace_phi_202510070839.log` into the 20251123 directory, document the reuse decision in diagnosis.md, flag the delta computation as provisional inside delta_metrics.json, and stop after updating commands.txt + sha256.txt.
Priorities & Rationale:
- plans/active/cli-noise-pix0/plan.md:288-307 — L3k.3 checklist keeps VG-1 blocked until a fresh TRACE_C_PHI run pairs with the 20251123 Py probe.
- docs/fix_plan.md:461-517 — Active item Next Actions demand regenerated C trace + updated diagnosis before nb-compare resumes.
- reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md#L200 — Notes the missing C trace and pending Δb_y/Δk logging required for Phase L3k.3c.2.
- docs/development/testing_strategy.md:24-61 — Parallel trace workflow mandates C/Py logs before implementing physics fixes.
- specs/spec-a-cli.md:1-160 — Confirms -pix0_vector_mm semantics we must verify when capturing parity artifacts.
How-To Map:
- mkdir -p reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123
- date '"'+%F %T TRACE START' | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- make -C golden_suite_generator -j | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- NB_C_BIN=./golden_suite_generator/nanoBragg ./golden_suite_generator/nanoBragg \\
  -mat A.mat -floatfile img.bin -hkl scaled.hkl -nonoise -nointerpolate -oversample 1 \\
  -exposure 1 -flux 1e18 -beamsize 1.0 -spindle_axis -1 0 0 \\
  -Xbeam 217.742295 -Ybeam 213.907080 -distance 231.274660 -lambda 0.976800 \\
  -pixel 0.172 -detpixels_x 2463 -detpixels_y 2527 \\
  -odet_vector -0.000088 0.004914 -0.999988 \\
  -sdet_vector -0.005998 -0.999970 -0.004913 \\
  -fdet_vector 0.999982 -0.005998 -0.000118 \\
  -pix0_vector_mm -216.336293 215.205512 -230.200866 \\
  -beam_vector 0.00051387949 0.0 -0.99999986 \\
  -Na 36 -Nb 47 -Nc 29 -osc 0.1 -phi 0 -phisteps 10 \\
  -detector_rotx 0 -detector_roty 0 -detector_rotz 0 -twotheta 0 \\
  -trace_pixel 685 1039 \\
  2>&1 | tee reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \\
  reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \\
  --config supervisor --pixel 685 1039 \\
  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \\
  --device cpu --dtype float64 \\
  | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \\
  reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.json \\
  reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log \\
  | tee reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_stdout_20251123.txt
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python - <<'PY'
import json, pathlib
base = pathlib.Path('reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123')
py = json.load((base/'trace_py_rot_vector_20251123_per_phi.json').open())['per_phi_entries']
with (base/'c_trace_phi_20251123.log').open() as fh:
    cvals = [float(line.split()[3].split('=')[1]) for line in fh if line.startswith('TRACE_C_PHI')]
metrics = {
    'status': 'ok',
    'phi0': {
        'py_k_frac': py[0]['k_frac'],
        'c_k_frac': cvals[0],
        'delta_k': py[0]['k_frac'] - cvals[0]
    },
    'phi9': {
        'py_k_frac': py[9]['k_frac'],
        'c_k_frac': cvals[9],
        'delta_k': py[9]['k_frac'] - cvals[9]
    }
}
(base/'delta_metrics.json').write_text(json.dumps(metrics, indent=2) + '\\n')
PY
- sha256sum reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/* > reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/sha256.txt
- Update reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md with an L3k.3c.2 entry summarising the new Δk values, the command hashes, and the remediation path (φ==0 mask or equivalent vectorized carryover) before touching simulator code.
- env KMP_DUPLICATE_LIB_OK=TRUE pytest --collect-only -q | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
Pitfalls To Avoid:
- Do not edit simulator/crystal code this loop; evidence only.
- Keep all command transcripts in commands.txt with timestamps so the rerun is auditable.
- Ensure NB_C_BIN points at golden_suite_generator/nanoBragg; the root binary lacks TRACE_C_PHI instrumentation.
- Maintain device/dtype neutrality when running harness scripts (stay on cpu/float64 as specified).
- Do not overwrite older base_vector_debug directories; add the new timestamp alongside 202510070839/20251122.
- Preserve failing pytest expectations in tests/test_cli_scaling_phi0.py; no edits to mask the red baseline.
- Run compare_per_phi_traces.py after both traces exist; it will raise if paths are wrong.
- Append to diagnosis.md rather than replacing earlier sections so chronology is intact.
- Regenerate sha256.txt after all files are in place to avoid stale hashes.
- Keep delta_metrics.json formatted as JSON (no trailing comments) for future automation.
Pointers:
- plans/active/cli-noise-pix0/plan.md:288-307 — Current L3k.3 tasks and success criteria.
- docs/fix_plan.md:461-517 — Next Actions and recent attempts capturing the missing C trace.
- reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/202510070839/diagnosis.md — Reference C trace instrumentation commands from the earlier successful run.
- golden_suite_generator/nanoBragg.c:3156-3160 — TRACE_C_PHI instrumentation hook.
- docs/debugging/debugging.md:28-118 — Parallel trace SOP you must follow.
Next Up: After VG-1 deltas are recorded, move to Phase L3k.3d to repair the nb-compare ROI totals (focus docs/fix_plan.md:470, plan table rows L3k.3d/L3k.3e).
EOF
" succeeded in 713ms:

[2025-10-07T19:13:35] tokens used: 290,395
[2025-10-07T19:13:35] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:13:41] thinking

**Correcting typo in command path**
[2025-10-07T19:13:42] exec bash -lc "sed -n '20,80p' input.md" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:13:43] bash -lc "sed -n '20,80p' input.md" succeeded in 712ms:
  -mat A.mat -floatfile img.bin -hkl scaled.hkl -nonoise -nointerpolate -oversample 1 \
  -exposure 1 -flux 1e18 -beamsize 1.0 -spindle_axis -1 0 0 \
  -Xbeam 217.742295 -Ybeam 213.907080 -distance 231.274660 -lambda 0.976800 \
  -pixel 0.172 -detpixels_x 2463 -detpixels_y 2527 \
  -odet_vector -0.000088 0.004914 -0.999988 \
  -sdet_vector -0.005998 -0.999970 -0.004913 \
  -fdet_vector 0.999982 -0.005998 -0.000118 \
  -pix0_vector_mm -216.336293 215.205512 -230.200866 \
  -beam_vector 0.00051387949 0.0 -0.99999986 \
  -Na 36 -Nb 47 -Nc 29 -osc 0.1 -phi 0 -phisteps 10 \
  -detector_rotx 0 -detector_roty 0 -detector_rotz 0 -twotheta 0 \
  -trace_pixel 685 1039 \
  2>&1 | tee reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
  reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
  --config supervisor --pixel 685 1039 \
  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
  --device cpu --dtype float64 \
  | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
- PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
[2025-10-07T19:13:43] tokens used: 293,801
[2025-10-07T19:13:43] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:13:45] thinking

**Correcting file path in patch**
[2025-10-07T19:13:59] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/input.md
@@ -35,3 +35,3 @@
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
[2025-10-07T19:13:59] apply_patch(auto_approved=true) exited 0 in 19ms:
Success. Updated the following files:
M input.md
[2025-10-07T19:13:59] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

[2025-10-07T19:13:59] tokens used: 295,477
[2025-10-07T19:13:59] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:14:06] thinking

**Preparing memory update with plan details**

I’m organizing a new entry for `galph_memory.md` that logs the recent plan refresh, including the vectorization update, fix_plan modifications, and relevant instructions; I’ll timestamp it and make sure it reference key events like the clean git pull and the pending test runs before appending it with `apply_patch`.
[2025-10-07T19:14:19] apply_patch auto_approved=true:
M /Users/ollie/Documents/nanoBragg3/galph_memory.md
@@ -1693 +1693,7 @@
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
[2025-10-07T19:14:19] apply_patch(auto_approved=true) exited 0 in 23ms:
Success. Updated the following files:
M galph_memory.md
[2025-10-07T19:14:19] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

[2025-10-07T19:14:19] tokens used: 297,107
[2025-10-07T19:14:19] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

[2025-10-07T19:14:22] stream error: stream disconnected before completion: Transport error: error decoding response body; retrying 1/5 in 191ms…

[2025-10-07T19:14:28] thinking

**Preparing to commit changes**
[2025-10-07T19:14:29] exec bash -lc 'git status --short' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:14:30] bash -lc 'git status --short' succeeded in 764ms:
 M docs/fix_plan.md
 M galph_memory.md
 M input.md
 M plans/active/vectorization.md
[2025-10-07T19:14:30] tokens used: 305,088
[2025-10-07T19:14:30] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:14:36] thinking

**Verifying and staging changes**
[2025-10-07T19:14:37] exec bash -lc 'git add docs/fix_plan.md galph_memory.md input.md plans/active/vectorization.md' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:14:38] bash -lc 'git add docs/fix_plan.md galph_memory.md input.md plans/active/vectorization.md' succeeded in 715ms:

[2025-10-07T19:14:38] tokens used: 305,308
[2025-10-07T19:14:38] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:14:42] thinking

**Preparing commit message**
[2025-10-07T19:14:43] exec bash -lc 'git commit -m "SUPERVISOR: vectorization plan sync - tests: not run"' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:14:44] bash -lc 'git commit -m "SUPERVISOR: vectorization plan sync - tests: not run"' succeeded in 732ms:
[feature/spec-based-2 6843e58] SUPERVISOR: vectorization plan sync - tests: not run
 4 files changed, 36 insertions(+), 19 deletions(-)
[2025-10-07T19:14:44] tokens used: 306,454
[2025-10-07T19:14:44] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:14:46] thinking

**Pushing committed changes**
[2025-10-07T19:14:47] exec bash -lc 'git push' in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:14:49] bash -lc 'git push' succeeded in 2.47s:
To github.com:hoidn/nanoBragg.git
   c73da6a..6843e58  feature/spec-based-2 -> feature/spec-based-2
[2025-10-07T19:14:49] tokens used: 306,713
[2025-10-07T19:14:49] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:14:59] thinking

**Summarizing response details**

I'll wrap up by outlining the plan updates, noting the fix_plan’s Next Actions revision, and referencing the new input for ralph. I'll also clarify that tests haven’t been run yet and highlight relevant file paths with approximate line numbers for context. This will help connect all the modifications and next instructions clearly.
[2025-10-07T19:15:02] exec bash -lc "nl -ba plans/active/vectorization.md | sed -n '1,40p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:15:03] bash -lc "nl -ba plans/active/vectorization.md | sed -n '1,40p'" succeeded in 725ms:
     1	## Context
     2	- Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
     3	- Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
     4	- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
     5	- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
     6	- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
     7	
     8	### Phase A — Evidence & Baseline Capture
     9	Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.
    10	Prereqs: Editable install (`pip install -e .`), C binary available for parity (when needed), environment variable `KMP_DUPLICATE_LIB_OK=TRUE`.
    11	Exit Criteria: Baseline pytest log, timing snippet results, and notes stored under `reports/2025-10-vectorization/phase_a/` with references in docs/fix_plan.md Attempt history.
    12	
    13	| ID | Task Description | State | How/Why & Guidance |
    14	| --- | --- | --- | --- |
    15	| A1 | Re-run tricubic acceptance tests | [D] | ✅ Completed 2025-10-06 (`reports/2025-10-vectorization/phase_a/test_at_str_002.log`, `.collect.log`, `test_at_abs_001.log`, `env.json`). Re-run only if dependencies change or new warnings appear. |
    16	| A2 | Measure current tricubic runtime | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/tricubic_baseline.py` created; CPU & CUDA baselines captured in `phase_a/tricubic_baseline.md` and `phase_a/tricubic_baseline_results.json`). Key finding: scalar-only implementation @ ~1.4 ms/call (CPU), ~5.5 ms/call (CUDA). |
    17	| A3 | Record detector absorption baseline | [D] | ✅ Completed 2025-10-07 (`scripts/benchmarks/absorption_baseline.py` created; CPU & CUDA baselines captured in `phase_a/absorption_baseline.md` and `phase_a/absorption_baseline_results.json`). GPU shows 5.4× speedup for 512² detector. |
    18	
    19	### Phase B — Tricubic Vectorization Design
    20	Goal: Lock the tensor-shape design, broadcasting plan, and gradient checks before code changes.
[2025-10-07T19:15:03] tokens used: 307,692
[2025-10-07T19:15:03] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:15:05] thinking

**Extracting specific lines from fix_plan.md**
[2025-10-07T19:15:05] exec bash -lc "nl -ba docs/fix_plan.md | sed -n '2060,2105p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:15:06] bash -lc "nl -ba docs/fix_plan.md | sed -n '2060,2105p'" succeeded in 706ms:
  2060	  * arch.md §15: "Use torch.autograd.gradcheck with dtype=torch.float64" (✅ existing tests honour float64; extend same discipline to new cases).
  2061	  * No regressions in existing test suite (✅ core geometry baseline 31/31 passed; gradient tests now can execute without C++ compilation errors).
  2062	
  2063	---
  2064	
  2065	## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
  2066	- Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
  2067	- Priority: High
  2068	- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
  2069	- Owner/Date: galph/2025-10-17
  2070	- Plan Reference: `plans/active/vectorization.md`
  2071	- Reproduction (C & PyTorch):
  2072	  * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
  2073	  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
  2074	  * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
  2075	- First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
  2076	- Next Actions (2025-11-23 refresh):
  2077	 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
  2078	 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
  2079	 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
[2025-10-07T19:15:06] tokens used: 310,337
[2025-10-07T19:15:06] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:15:09] thinking

**Continuing with line numbering**
[2025-10-07T19:15:09] exec bash -lc "nl -ba docs/fix_plan.md | sed -n '2140,2195p'" in /Users/ollie/Documents/nanoBragg3
[2025-10-07T19:15:10] bash -lc "nl -ba docs/fix_plan.md | sed -n '2140,2195p'" succeeded in 671ms:
  2140	    Metrics:
  2141	      - New test suite: 4/4 tests passed in test_tricubic_vectorized.py (test_vectorized_matches_scalar, test_neighborhood_gathering_internals, test_device_neutrality[cpu], test_device_neutrality[cuda])
  2142	      - Regression tests: 3/3 tests passed in test_at_str_002.py (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation)
  2143	      - Core suite: 38/38 tests passed (crystal geometry, detector geometry, vectorized gather)
  2144	      - Shape validation: Scalar (B=1) → (1,4,4,4), Batch (B=3) → (3,4,4,4), Grid (2×3) → (6,4,4,4) neighborhoods all correct
  2145	      - Device propagation: CPU and CUDA execution confirmed with correct device inheritance
  2146	    Artifacts:
  2147	      - `src/nanobrag_torch/models/crystal.py` lines 355–429 — Batched neighborhood gather implementation using advanced PyTorch indexing
  2148	      - `tests/test_tricubic_vectorized.py` — 4 new test cases validating gather infrastructure (white-box coordinate validation, device neutrality)
  2149	      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — Complete Phase C1 implementation documentation
  2150	      - Git commit: 88fd76a
  2151	    Observations/Hypotheses:
  2152	      - Successfully implemented `(B, 4, 4, 4)` neighborhood gather using broadcasting pattern from design_notes.md §2: `h_array_grid[:, :, None, None]`, `k_array_grid[:, None, :, None]`, `l_array_grid[:, None, None, :]`
  2153	      - Scalar path (B=1) preserved: continues to use existing `polin3` helper with correct interpolation
  2154	      - Batched path (B>1) falls back to nearest-neighbor pending Phase D polynomial vectorization (intentional staging per design)
  2155	      - OOB handling preserved: single warning emission, default_F fallback logic intact
  2156	      - No memory issues: 1024² detector (268 MB neighborhoods) well within GPU/CPU limits
  2157	      - Coordinate grid construction validated: `h=1.5` (floor=1) → grid `[0,1,2,3]` as expected (floor + offsets [-1,0,1,2])
  2158	      - Device comparison fix applied: use `.device.type` string comparison instead of direct `torch.device` object comparison to handle `cuda` vs `cuda:0` variants
  2159	      - Implementation follows all design contracts: no `.item()` calls, device-neutral offset construction, differentiability preserved
[2025-10-07T19:15:10] tokens used: 312,243
[2025-10-07T19:15:10] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.


[2025-10-07T19:15:18] thinking

**Preparing final summary and next steps**

I’m gathering relevant line references from the modified files like `plans/active/vectorization.md`, `docs/fix_plan.md`, and noting the `input.md` rewrite. I’ll include bullet points highlighting plan updates, the reissued input instructions, no tests run, and expectations for Ralph to follow the input. The summary will mention readiness for Phase D vectorization tasks and watchers before wrapping up.
[2025-10-07T19:15:19] codex

**Updates**
- Refresh `plans/active/vectorization.md:1-6` so the context snapshots Phase C as complete, calls out Phase D (`polint`/`polin2`/`polin3`) as the new gate, and adds supervisory guidance on capturing polynomial artifacts before touching detector absorption.
- Extend `docs/fix_plan.md:2065-2198` with Phase D-focused Next Actions and a new Attempt #7 entry documenting the Phase C3 assertion/device audit (linking artifacts and tests) so the vectorization backlog history is accurate.
- Reissued `input.md` directing Ralph to regenerate the 20251123 TRACE_C_PHI bundle, recompute VG‑1 deltas, and record results per the updated CLI-FLAGS-003 plan.
- Logged the planning decisions and expectations for Ralph in `galph_memory.md`.

**Next Steps**
- Ralph should follow the refreshed `input.md` instructions to capture the missing C trace, update diagnosis/delta metrics, and keep VG‑1 in the red until the physics fix lands; afterwards he can advance to L3k.3d per the plan.
[2025-10-07T19:15:21] tokens used: 314,721
[2025-10-07T19:15:21] turn diff:
diff --git a/docs/fix_plan.md b/docs/fix_plan.md
index 3c11a9b187c83b8849517cc2a482a565b5d53a1c..69dcc691a1ec4930f9e76e2d21b32eaa5d47d041
--- a/docs/fix_plan.md
+++ b/docs/fix_plan.md
@@ -2065,18 +2065,18 @@
 ## [VECTOR-TRICUBIC-001] Vectorize tricubic interpolation and detector absorption
 - Spec/AT: specs/spec-a-core.md §4 (structure factor sampling), specs/spec-a-parallel.md §2.3 (tricubic acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4 (vectorization strategy), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, nanoBragg.c lines 2604–3278 (polin3/polin2/polint) and 3375–3450 (detector absorption loop).
 - Priority: High
-- Status: in_progress (Phases A–B complete; Phase C implementation pending)
+- Status: in_progress (Phases A–C complete; Phase D polynomial vectorization pending)
 - Owner/Date: galph/2025-10-17
 - Plan Reference: `plans/active/vectorization.md`
 - Reproduction (C & PyTorch):
   * PyTorch baseline tests: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_at_str_002.py tests/test_at_abs_001.py -v`
-  * Optional microbenchmarks (to be created per plan Phase A): `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/sample_tricubic_baseline.py`
+  * Optional microbenchmarks: `PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/benchmarks/tricubic_baseline.py --sizes 256 512 --device cpu` (and `--device cuda`), plus `scripts/benchmarks/absorption_baseline.py` for detector absorption timing.
   * Shapes/ROI: 256² & 512² detectors for microbench; oversample 1; structure-factor grid enabling tricubic.
 - First Divergence (if known): Current tricubic path drops to nearest-neighbour fallback for batched pixel grids, emitting warnings and forfeiting accuracy/performance; detector absorption still loops over `thicksteps`, preventing full vectorization and creating hotspots in profiler traces (see reports/benchmarks/20250930-165726-compile-cache/analysis.md).
-- Next Actions (2025-11-21 refresh):
- 1. Phase C3 — implement the shape assertions + device-aware caching updates (see plan checklist C3.1/C3.2), recording line references in `reports/2025-10-vectorization/phase_c/implementation_notes.md`.
- 2. Phase C3 evidence — capture targeted pytest logs (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v`) under `reports/2025-10-vectorization/phase_c/`, then flip checklist items C3.1–C3.3 to ✅.
- 3. Phase C close-out — once C3 artifacts land, update this entry with Attempt # (include assertion/caching diff + log hashes) and coordinate Phase D kickoff via plan + input.md.
+- Next Actions (2025-11-23 refresh):
+ 1. Phase D1 — implement batched `polint` vectorization following design_notes §3; capture targeted regression proof (`pytest tests/test_tricubic_vectorized.py::TestTricubicPoly::test_polint_vectorized_matches_scalar`) on CPU + CUDA and document tensor-shape math in `reports/2025-10-vectorization/phase_d/polynomial_validation.md`.
+ 2. Phase D2 — extend the batched polynomial path to `polin2`/`polin3`, update gather fallback to consume vectorized outputs, and add unit tests covering multi-pixel batches plus OOB mask retention.
+ 3. Phase D3 — run gradient + device regression sweep (`env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py tests/test_at_str_002.py -v`) and update plan/fix_plan with metrics before proceeding to Phase E validation.
 - Attempts History:
   * [2025-10-06] Attempt #1 (ralph loop) — Result: **Phase A1 COMPLETE** (test collection & execution baseline captured). All tricubic and absorption tests passing.
     Metrics: AT-STR-002: 3/3 tests passed in 2.12s (test_tricubic_interpolation_enabled, test_tricubic_out_of_bounds_fallback, test_auto_enable_interpolation). AT-ABS-001: 5/5 tests passed in 5.88s. Collection: 3 tricubic tests found.
@@ -2192,6 +2192,17 @@
       - No code changes to production paths; test-only addition preserves existing behavior
       - All existing tricubic acceptance tests (AT-STR-002) remain passing after test addition
     Next Actions: Execute Phase C3 (shape assertions + device-aware caching) with implementation notes in `phase_c/implementation_notes.md`, then proceed to Phase D polynomial vectorization.
+  * [2025-10-07] Attempt #7 (ralph loop, Mode: Code) — Result: **Phase C3 COMPLETE** (shape assertions/device audit landed). Pipeline now ready for Phase D polynomial work.
+    Metrics: `env KMP_DUPLICATE_LIB_OK=TRUE pytest tests/test_tricubic_vectorized.py -k "gather" -v` (5/5 passed in 2.33s) and `pytest tests/test_at_str_002.py::test_tricubic_interpolation_enabled -v` (1/1 passed). Test collection: 653 tests.
+    Artifacts:
+      - `src/nanobrag_torch/models/crystal.py:414-462` — Added `(B,4,4,4)` neighborhood assertions, device consistency checks, and output-shape guards (scalar + batched paths).
+      - `reports/2025-10-vectorization/phase_c/implementation_notes.md` — New Phase C3 section detailing assertion rationale, device audit findings, and hand-off requirements for Phase D.
+      - `reports/2025-10-vectorization/phase_c/test_tricubic_vectorized.log`, `test_at_str_002_phi.log`, `status_snapshot.txt` — Targeted pytest evidence with hashes.
+    Observations/Hypotheses:
+      - Assertions guard against silent regressions once polynomial vectorization lands by enforcing `(B,4,4,4)` tensor layout and output shape parity.
+      - Device checks confirmed gather outputs stay on the caller’s device (CPU/CUDA), eliminating hidden host/device drift before Phase D.
+      - Audit verified `_tricubic_interpolation` performs no caching; notes instruct future caching layers to mirror the device assertions.
+    Next Actions: Advance to Phase D tasks (vectorize `polint`/`polin2`/`polin3`) and capture new artifacts under `reports/2025-10-vectorization/phase_d/` prior to executing Phase E validation.
 - Risks/Assumptions: Must maintain differentiability (no `.item()`, no `torch.linspace` with tensor bounds), preserve device/dtype neutrality (CPU/CUDA parity), and obey Protected Assets rule (all new scripts under `scripts/benchmarks/`). Large tensor indexing may increase memory pressure; ensure ROI caching still works.
 - Exit Criteria (quote thresholds from spec):
   * specs/spec-a-parallel.md §2.3 tricubic acceptance tests run without warnings and match C parity within documented tolerances (corr≥0.9995, ≤1e-12 structural duality where applicable).
diff --git a/galph_memory.md b/galph_memory.md
index d80aac9d1fe49ff39470c4586ccfb8b078e41ad2..d9b11ac572ef3cd56664c0ec8f8447a523092920
--- a/galph_memory.md
+++ b/galph_memory.md
@@ -1691,3 +1691,9 @@
 - Refreshed `docs/fix_plan.md` Next Actions to (1) rerun TRACE_C_PHI for 20251123, (2) compute Δb_y/Δk_frac, (3) then return to nb-compare repairs.
 - Authored new input.md steering Ralph to rebuild the C binary, rerun the supervisor command with `-trace_pixel 685 1039`, regenerate Py per-φ traces, run `scripts/compare_per_phi_traces.py`, update `delta_metrics.json`, and log the results before moving back to nb-compare.
 - Feedback on Ralph’s recent work: Attempt #103 correctly restored the red guard tests; Attempt #108 gathered Py-only data but stalled without the paired C trace. Next loop should focus on producing the coeval TRACE_C_PHI artifact so VG-1.4 can flip from ⚠️ to actionable metrics.
+
+## 2025-11-23 (galph loop — vectorization plan refresh)
+- Synced repo (no conflicts). Action type: Planning; refreshed `plans/active/vectorization.md` context to note Phase C completion and queued Phase D polynomial vectorization.
+- Updated `docs/fix_plan.md` › VECTOR-TRICUBIC-001: added Attempt #7 documenting Phase C3 assertions/device audit and rewrote Next Actions toward Phase D1–D3.
+- Reissued `input.md` (Parity mode) directing Ralph to rerun Phase L3k.3b TRACE_C_PHI with full artifact capture; command map mirrors previous loop with typo fixes.
+- Expect Ralph to produce the 20251123 C trace, update diagnosis + delta metrics, then proceed to L3k.3d per plan. Vectorization tasks now gate on new Phase D notes once CLI work unblocks.
diff --git a/input.md b/input.md
index a1ad59a222aaa10a09ce609f8219f7bbd1ec659f..17d4874b274c66d24c1c40a68eb7fea60e1451ab
--- a/input.md
+++ b/input.md
@@ -33,7 +33,7 @@
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python \
   reports/2025-10-cli-flags/phase_l/rot_vector/trace_harness.py \
   --config supervisor --pixel 685 1039 \
-  --out reports/2025-10-cliags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
+  --out reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log \
   --device cpu --dtype float64 \
   | tee -a reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/commands.txt
 - PYTHONPATH=src KMP_DUPLICATE_LIB_OK=TRUE python scripts/compare_per_phi_traces.py \
diff --git a/plans/active/vectorization.md b/plans/active/vectorization.md
index 1f3b1b2b98f4b6b4c7e64d9e80c5cd03502c2fdc..3bfbb6c1afc5adff6dacc54cc5b1eda8d0fdbc2f
--- a/plans/active/vectorization.md
+++ b/plans/active/vectorization.md
@@ -1,9 +1,9 @@
 ## Context
 - Initiative: PERF-PYTORCH-004 vectorization backlog; supports long-term goal "Parallel parity + performance" from docs/fix_plan.md.
 - Phase Goal: Deliver a production-ready, fully vectorized tricubic interpolation pipeline (gather + polynomial evaluation) and follow with detector absorption vectorization without regressing physics, gradients, or device neutrality.
-- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). No dedicated tricubic/absorption microbenchmarks exist yet; Phase A will author reusable harnesses under `scripts/benchmarks/` so future loops can rerun baselines without ad-hoc snippets.
-- Gap Snapshot (2025-11-21 refresh): Phase C1 (batched gather) and C2 (OOB fallback validation) are COMPLETE with artifacts under `reports/2025-10-vectorization/phase_c/`. Outstanding blocker before engaging Phase D polynomial work is C3 (shape assertions + device/device-aware caching) so the gather path cannot regress silently.
-- Supervisory note (2025-11-21): Guard C3 deliverables with explicit evidence: update `phase_c/implementation_notes.md` with the new assertion/caching strategy, capture the targeted pytest log, and record the tensor-shape/caching checklist below before advancing to Phase D.
+- Dependencies: specs/spec-a-core.md §4 (Structure factors), specs/spec-a-parallel.md §2.3 (Interpolation acceptance tests), docs/architecture/pytorch_design.md §§2.2–2.4, docs/architecture/c_code_overview.md (tricubic routines), docs/development/testing_strategy.md §§2–4, docs/development/pytorch_runtime_checklist.md, `nanoBragg.c` lines 2604–3278 (polin3/polin2/polint + detector absorption), `tests/test_at_str_002.py`, `tests/test_at_abs_001.py`, `reports/benchmarks/20250930-165726-compile-cache/` (current performance references). Reusable tricubic and absorption harnesses now live under `scripts/benchmarks/` (see Phase A artifacts) for ongoing baseline comparisons.
+- Gap Snapshot (2025-11-23 refresh): Phase C1–C3 are COMPLETE with logs in `reports/2025-10-vectorization/phase_c/`; assertions and device checks landed in commit 12742e5. The next gating work is Phase D (vectorize `polint`/`polin2`/`polin3`) followed by Phase E validation before touching detector absorption (Phase F).
+- Supervisory note (2025-11-23): Before coding Phase D, ensure the polynomial vectorization tasks record explicit tensor-shape math, gradient expectations, and targeted regression selectors in `phase_d/` notes. Capture proof (CPU+CUDA) for each helper as it is batched, then roll those artifacts into the Phase E parity/perf sweep prior to resuming absorption work.
 
 ### Phase A — Evidence & Baseline Capture
 Goal: Document the current (non-vectorized) behavior, warnings, and performance so we can prove the impact of the refactor.

Reading prompt from stdin...
To github.com:hoidn/nanoBragg.git
   6843e58..79c3a96  HEAD -> feature/spec-based-2
Waiting for Ralph to complete i=108...
Already up to date.
[sync] state: actor=ralph status=waiting-ralph iter=108
Updating 79c3a96..b8ca822
Fast-forward
 sync/state.json | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
From github.com:hoidn/nanoBragg
   79c3a96..b8ca822  feature/spec-based-2 -> origin/feature/spec-based-2
[sync] state: actor=ralph status=running-ralph iter=108
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating b8ca822..7191978
Fast-forward
 docs/fix_plan.md                                   |  27 ++
 .../20251123/comparison_summary.md                 |  49 +++
 .../trace_py_rot_vector_20251123_per_phi.json      |  82 +++++
 .../trace_py_rot_vector_20251123_per_phi.log       |  10 +
 .../20251123/c_trace_phi_20251123.log              | 342 +++++++++++++++++++++
 .../base_vector_debug/20251123/commands.txt        |  29 +-
 .../20251123/comparison_stdout_20251123.txt        |  44 +++
 .../base_vector_debug/20251123/delta_metrics.json  |  20 +-
 .../base_vector_debug/20251123/commands.txt        |   2 +
 .../phase_l/rot_vector/diagnosis.md                |  93 ++++++
 .../base_vector_debug/20251123/sha256.txt          |   7 +-
 .../20251123/trace_py_rot_vector_20251123.log      |  43 +++
 .../phase_l/rot_vector/trace_py_env.json           |   4 +-
 13 files changed, 734 insertions(+), 18 deletions(-)
 create mode 100644 reports/2025-10-cli-flags/phase_l/per_phi/reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_summary.md
 create mode 100644 reports/2025-10-cli-flags/phase_l/per_phi/reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.json
 create mode 100644 reports/2025-10-cli-flags/phase_l/per_phi/reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123_per_phi.log
 create mode 100644 reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/c_trace_phi_20251123.log
 create mode 100644 reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/comparison_stdout_20251123.txt
 create mode 100644 reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/reports/2025-10-cli-flags/phase_l/rot_vector/diagnosis.md
 create mode 100644 reports/2025-10-cli-flags/phase_l/rot_vector/base_vector_debug/20251123/trace_py_rot_vector_20251123.log
From github.com:hoidn/nanoBragg
   b8ca822..7191978  feature/spec-based-2 -> origin/feature/spec-based-2
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Already up to date.
Updating 7191978..7a6dc15
Fast-forward
 sync/state.json | 12 ++++++------
 1 file changed, 6 insertions(+), 6 deletions(-)
From github.com:hoidn/nanoBragg
   7191978..7a6dc15  feature/spec-based-2 -> origin/feature/spec-based-2
[sync] state: actor=galph status=complete iter=109
Ralph completed iteration 108; proceeding to 109
